<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science (cs) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2021-11-02T20:30:00-05:00</dc:date>
<dc:publisher>www-admin@arxiv.org</dc:publisher>
<dc:subject>Computer Science</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01127" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01131" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01136" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01137" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01166" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01181" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01186" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01196" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01203" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01207" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01210" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01213" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01222" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01228" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01233" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01235" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01236" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01254" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01256" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01261" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01263" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01266" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01271" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01273" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01275" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01297" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01302" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01312" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01315" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01321" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01326" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01334" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01338" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01340" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01342" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01351" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01356" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01359" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01366" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01371" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01383" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01387" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01391" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01392" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01393" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01413" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01414" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01418" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01419" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01440" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01455" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01465" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01470" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01471" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01480" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01481" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01482" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01484" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01485" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01496" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01501" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01504" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01510" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01515" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01528" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01531" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01533" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01537" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01540" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01543" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01551" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01555" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01556" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01557" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01562" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01570" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01576" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01582" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01590" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01592" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01593" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01594" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01602" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01604" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01616" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01619" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01622" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01625" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01628" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01633" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01634" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01638" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01645" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01652" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01654" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01657" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01662" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01663" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01665" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01667" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01673" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01676" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01677" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01683" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01684" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01689" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01692" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01694" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01697" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01701" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01706" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01710" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01714" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01715" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01717" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01723" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01730" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01732" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01740" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01743" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01761" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01767" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01768" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01777" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01778" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01780" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.01786" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.09719" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.03855" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.00715" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1906.05799" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1908.08384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.03438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.05384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.05674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1911.04853" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2001.04385" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2002.02051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2003.08904" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2005.11290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.04202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.06555" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.06721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.09647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.14841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.06319" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.07053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.08792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.10174" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.05208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.07773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.00300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.01748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.04030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.05178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.08572" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.13363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.02609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.11201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.12635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.00517" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.10496" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.01484" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.01768" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.06536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.08862" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.11427" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.03336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.03988" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.07092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.09759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.09775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.09808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.10090" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.11137" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.11903" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.00091" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.01242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.03991" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.04804" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.11351" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.12347" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.13530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.01065" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.02040" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.05119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.07149" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.09330" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.12820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.01924" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.02716" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.06742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.07608" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.09680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.11066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.11367" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.12122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.13133" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.02383" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.02473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.03632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.03898" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.04031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.04169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.04537" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.04627" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.05378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.05386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.06306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.06308" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.07085" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.07504" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.08208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.09012" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.09779" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.13008" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.14564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.14568" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.15916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.16122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.16187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.00820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.02071" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.02397" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.02909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.03461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.03955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.07451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.07994" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.09834" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.11786" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.12922" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.13875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.00238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.00376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.00559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.01192" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.01598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.02430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.02842" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.03272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.03458" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.07931" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.07945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.08282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.10629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.11224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.12188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.12486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.01135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.03100" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.05112" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.05466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.06610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.07103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.07950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.08113" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.09010" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.09390" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.10187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.11808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.11999" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.00318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.00841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.01445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.01705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.01895" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.02473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.03083" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.03469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.03485" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.05076" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.07067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.07554" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.08642" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.09113" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.09469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.10332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.10349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.10394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.10572" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.11061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.11283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.11661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.12246" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.12616" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.13067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.13746" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14124" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14389" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14864" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15444" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15715" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15720" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00082" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00116" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00660" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00772" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00801" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00826" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00868" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00947" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.00459" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2111.01127">
<title>NSS-VAEs: Generative Scene Decomposition for Visual Navigable Space Construction. (arXiv:2111.01127v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01127</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting navigable space is the first and also a critical step for
successful robot navigation. In this work, we treat the visual navigable space
segmentation as a scene decomposition problem and propose a new network,
NSS-VAEs (Navigable Space Segmentation Variational AutoEncoders), a
representation-learning-based framework to enable robots to learn the navigable
space segmentation in an unsupervised manner. Different from prevalent
segmentation techniques which heavily rely on supervised learning strategies
and typically demand immense pixel-level annotated images, the proposed
framework leverages a generative model - Variational Auto-Encoder (VAE) - to
learn a probabilistic polyline representation that compactly outlines the
desired navigable space boundary. Uniquely, our method also assesses the
prediction uncertainty related to the unstructuredness of the scenes, which is
important for robot navigation in unstructured environments. Through extensive
experiments, we have validated that our proposed method can achieve remarkably
high accuracy (&amp;gt;90%) even without a single label. We also show that the
prediction of NSS-VAEs can be further improved using few labels with results
significantly outperforming the SOTA fully supervised-learning-based method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lantao Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01131">
<title>Hierarchical Decision Ensembles- An inferential framework for uncertain Human-AI collaboration in forensic examinations. (arXiv:2111.01131v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2111.01131</link>
<description rdf:parseType="Literal">&lt;p&gt;Forensic examination of evidence like firearms and toolmarks, traditionally
involves a visual and therefore subjective assessment of similarity of two
questioned items. Statistical models are used to overcome this subjectivity and
allow specification of error rates. These models are generally quite complex
and produce abstract results at different levels of the analysis. Presenting
such metrics and complicated results to examiners is challenging, as examiners
generally do not have substantial statistical training to accurately interpret
results. This creates distrust in statistical modelling and lowers the rate of
acceptance of more objective measures that the discipline at large is striving
for. We present an inferential framework for assessing the model and its
output. The framework is designed to calibrate trust in forensic experts by
bridging the gap between domain specific knowledge and predictive model
results, allowing forensic examiners to validate the claims of the predictive
model while critically assessing results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnan_G/0/1/0/all/0/1&quot;&gt;Ganesh Krishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_H/0/1/0/all/0/1&quot;&gt;Heike Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01134">
<title>Comparing Bayesian Models for Organ Contouring in Headand Neck Radiotherapy. (arXiv:2111.01134v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01134</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models for organ contouring in radiotherapy are poised for
clinical usage, but currently, there exist few tools for automated quality
assessment (QA) of the predicted contours. Using Bayesian models and their
associated uncertainty, one can potentially automate the process of detecting
inaccurate predictions. We investigate two Bayesian models for auto-contouring,
DropOut and FlipOut, using a quantitative measure - expected calibration error
(ECE) and a qualitative measure - region-based accuracy-vs-uncertainty (R-AvU)
graphs. It is well understood that a model should have low ECE to be considered
trustworthy. However, in a QA context, a model should also have high
uncertainty in inaccurate regions and low uncertainty in accurate regions. Such
behaviour could direct visual attention of expert users to potentially
inaccurate regions, leading to a speed up in the QA process. Using R-AvU
graphs, we qualitatively compare the behaviour of different models in accurate
and inaccurate regions. Experiments are conducted on the MICCAI2015 Head and
Neck Segmentation Challenge and on the DeepMindTCIA CT dataset using three
models: DropOut-DICE, Dropout-CE (Cross Entropy) and FlipOut-CE. Quantitative
results show that DropOut-DICE has the highest ECE, while Dropout-CE and
FlipOut-CE have the lowest ECE. To better understand the difference between
DropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE
has better uncertainty coverage in inaccurate regions than DropOut-CE. Such a
combination of quantitative and qualitative metrics explores a new approach
that helps to select which model can be deployed as a QA tool in clinical
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mody_P/0/1/0/all/0/1&quot;&gt;Prerak Mody&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chaves_de_Plaza_N/0/1/0/all/0/1&quot;&gt;Nicolas Chaves-de-Plaza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hildebrandt_K/0/1/0/all/0/1&quot;&gt;Klaus Hildebrandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Egmond_R/0/1/0/all/0/1&quot;&gt;Rene van Egmond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ridder_H/0/1/0/all/0/1&quot;&gt;Huib de Ridder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Staring_M/0/1/0/all/0/1&quot;&gt;Marius Staring&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01135">
<title>Arch-Net: Model Distillation for Architecture Agnostic Model Deployment. (arXiv:2111.01135v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01135</link>
<description rdf:parseType="Literal">&lt;p&gt;Vast requirement of computation power of Deep Neural Networks is a major
hurdle to their real world applications. Many recent Application Specific
Integrated Circuit (ASIC) chips feature dedicated hardware support for Neural
Network Acceleration. However, as ASICs take multiple years to develop, they
are inevitably out-paced by the latest development in Neural Architecture
Research. For example, Transformer Networks do not have native support on many
popular chips, and hence are difficult to deploy. In this paper, we propose
Arch-Net, a family of Neural Networks made up of only operators efficiently
supported across most architectures of ASICs. When a Arch-Net is produced, less
common network constructs, like Layer Normalization and Embedding Layers, are
eliminated in a progressive manner through label-free Blockwise Model
Distillation, while performing sub-eight bit quantization at the same time to
maximize performance. Empirical results on machine translation and image
classification tasks confirm that we can transform latest developed Neural
Architectures into fast running and as-accurate Arch-Net, ready for deployment
on multiple mass-produced ASIC chips. The code will be available at
https://github.com/megvii-research/Arch-Net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weixin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zipeng Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1&quot;&gt;Shuangkang Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1&quot;&gt;Song Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuchang Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01136">
<title>ASMDD: Arabic Speech Mispronunciation Detection Dataset. (arXiv:2111.01136v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01136</link>
<description rdf:parseType="Literal">&lt;p&gt;The largest dataset of Arabic speech mispronunciation detections in Egyptian
dialogues is introduced. The dataset is composed of annotated audio files
representing the top 100 words that are most frequently used in the Arabic
language, pronounced by 100 Egyptian children (aged between 2 and 8 years old).
The dataset is collected and annotated on segmental pronunciation error
detections by expert listeners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aly_S/0/1/0/all/0/1&quot;&gt;Salah A. Aly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salah_A/0/1/0/all/0/1&quot;&gt;Abdelrahman Salah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eraqi_H/0/1/0/all/0/1&quot;&gt;Hesham M. Eraqi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01137">
<title>Stock Price Prediction Using Time Series, Econometric, Machine Learning, and Deep Learning Models. (arXiv:2111.01137v1 [q-fin.ST])</title>
<link>http://arxiv.org/abs/2111.01137</link>
<description rdf:parseType="Literal">&lt;p&gt;For a long-time, researchers have been developing a reliable and accurate
predictive model for stock price prediction. According to the literature, if
predictive models are correctly designed and refined, they can painstakingly
and faithfully estimate future stock values. This paper demonstrates a set of
time series, econometric, and various learning-based models for stock price
prediction. The data of Infosys, ICICI, and SUN PHARMA from the period of
January 2004 to December 2019 was used here for training and testing the models
to know which model performs best in which sector. One time series model
(Holt-Winters Exponential Smoothing), one econometric model (ARIMA), two
machine Learning models (Random Forest and MARS), and two deep learning-based
models (simple RNN and LSTM) have been included in this paper. MARS has been
proved to be the best performing machine learning model, while LSTM has proved
to be the best performing deep learning model. But overall, for all three
sectors - IT (on Infosys data), Banking (on ICICI data), and Health (on SUN
PHARMA data), MARS has proved to be the best performing model in sales
forecasting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Chatterjee_A/0/1/0/all/0/1&quot;&gt;Ananda Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Bhowmick_H/0/1/0/all/0/1&quot;&gt;Hrisav Bhowmick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Sen_J/0/1/0/all/0/1&quot;&gt;Jaydip Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01166">
<title>Investigating the locality of neural network training dynamics. (arXiv:2111.01166v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01166</link>
<description rdf:parseType="Literal">&lt;p&gt;A fundamental quest in the theory of deep-learning is to understand the
properties of the trajectories in the weight space that a learning algorithm
takes. One such property that had very recently been isolated is that of &quot;local
elasticity&quot; ($S_{\rm rel}$), which quantifies the propagation of influence of a
sampled data point on the prediction at another data point. In this work, we
perform a comprehensive study of local elasticity by providing new theoretical
insights and more careful empirical evidence of this property in a variety of
settings. Firstly, specific to the classification setting, we suggest a new
definition of the original idea of $S_{\rm rel}$. Via experiments on
state-of-the-art neural networks training on SVHN, CIFAR-10 and CIFAR-100 we
demonstrate how our new $S_{\rm rel}$ detects the property of the weight
updates preferring to make changes in predictions within the same class of the
sampled data. Next, we demonstrate via examples of neural nets doing regression
that the original $S_{\rm rel}$ reveals a $2-$phase behaviour: that their
training proceeds via an initial elastic phase when $S_{\rm rel}$ changes
rapidly and an eventual inelastic phase when $S_{\rm rel}$ remains large.
Lastly, we give multiple examples of learning via gradient flows for which one
can get a closed-form expression of the original $S_{\rm rel}$ function. By
studying the plots of these derived formulas we given a theoretical
demonstration of some of the experimentally detected properties of $S_{\rm
rel}$ in the regression setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1&quot;&gt;Soham Dan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gampa_P/0/1/0/all/0/1&quot;&gt;Phanideep Gampa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Anirbit Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01177">
<title>Don&apos;t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence. (arXiv:2111.01177v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01177</link>
<description rdf:parseType="Literal">&lt;p&gt;Although machine learning models trained on massive data have led to
break-throughs in several areas, their deployment in privacy-sensitive domains
remains limited due to restricted access to data. Generative models trained
with privacy constraints on private data can sidestep this challenge, providing
indirect access to private data instead. We propose DP-Sinkhorn, a novel
optimal transport-based generative method for learning data distributions from
private data with differential privacy. DP-Sinkhorn minimizes the Sinkhorn
divergence, a computationally efficient approximation to the exact optimal
transport distance, between the model and data in a differentially private
manner and uses a novel technique for control-ling the bias-variance trade-off
of gradient estimates. Unlike existing approaches for training differentially
private generative models, which are mostly based on generative adversarial
networks, we do not rely on adversarial objectives, which are notoriously
difficult to optimize, especially in the presence of noise imposed by privacy
constraints. Hence, DP-Sinkhorn is easy to train and deploy. Experimentally, we
improve upon the state-of-the-art on multiple image modeling benchmarks and
show differentially private synthesis of informative RGB images. Project
page:https://nv-tlabs.github.io/DP-Sinkhorn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1&quot;&gt;Tianshi Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bie_A/0/1/0/all/0/1&quot;&gt;Alex Bie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vahdat_A/0/1/0/all/0/1&quot;&gt;Arash Vahdat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1&quot;&gt;Sanja Fidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreis_K/0/1/0/all/0/1&quot;&gt;Karsten Kreis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01181">
<title>Convergent adaptive hybrid higher-order schemes for convex minimization. (arXiv:2111.01181v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01181</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes two convergent adaptive mesh-refining algorithms for the
hybrid high-order method in convex minimization problems with two-sided
p-growth. Examples include the p-Laplacian, an optimal design problem in
topology optimization, and the convexified double-well problem. The hybrid
high-order method utilizes a gradient reconstruction in the space of piecewise
Raviart-Thomas finite element functions without stabilization on triangulations
into simplices or in the space of piecewise polynomials with stabilization on
polytopal meshes. The main results imply the convergence of the energy and,
under further convexity properties, of the approximations of the primal resp.
dual variable. Numerical experiments illustrate an efficient approximation of
singular minimizers and improved convergence rates for higher polynomial
degrees. Computer simulations provide striking numerical evidence that an
adopted adaptive HHO algorithm can overcome the Lavrentiev gap phenomenon even
with empirical higher convergence rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Carstensen_C/0/1/0/all/0/1&quot;&gt;Carsten Carstensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tran_N/0/1/0/all/0/1&quot;&gt;Ngoc Tien Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01186">
<title>Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces. (arXiv:2111.01186v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of optimizing combinatorial spaces (e.g., sequences,
trees, and graphs) using expensive black-box function evaluations. For example,
optimizing molecules for drug design using physical lab experiments. Bayesian
optimization (BO) is an efficient framework for solving such problems by
intelligently selecting the inputs with high utility guided by a learned
surrogate model. A recent BO approach for combinatorial spaces is through a
reduction to BO over continuous spaces by learning a latent representation of
structures using deep generative models (DGMs). The selected input from the
continuous space is decoded into a discrete structure for performing function
evaluation. However, the surrogate model over the latent space only uses the
information learned by the DGM, which may not have the desired inductive bias
to approximate the target black-box function. To overcome this drawback, this
paper proposes a principled approach referred as LADDER. The key idea is to
define a novel structure-coupled kernel that explicitly integrates the
structural information from decoded structures with the learned latent space
representation for better surrogate modeling. Our experiments on real-world
benchmarks show that LADDER significantly improves over the BO over latent
space method, and performs better or similar to state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshwal_A/0/1/0/all/0/1&quot;&gt;Aryan Deshwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1&quot;&gt;Janardhan Rao Doppa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01187">
<title>Safe PDE Backstepping QP Control with High Relative Degree CBFs: Stefan Model with Actuator Dynamics. (arXiv:2111.01187v1 [math.OC])</title>
<link>http://arxiv.org/abs/2111.01187</link>
<description rdf:parseType="Literal">&lt;p&gt;High-relative-degree control barrier functions (hi-rel-deg CBFs) play a
prominent role in automotive safety and in robotics. In this paper we launch a
generalization of this concept for PDE control, treating a specific,
physically-relevant model of thermal dynamics where the boundary of the PDE
moves due to a liquid-solid phase change -- the so-called Stefan model. The
familiar QP design is employed to ensure safety but with CBFs that are
infinite-dimensional (including one control barrier &quot;functional&quot;) and with safe
sets that are infinite-dimensional as well. Since, in the presence of actuator
dynamics, at the boundary of the Stefan system, this system&apos;s main CBF is of
relative degree two, an additional CBF is constructed, by backstepping design,
which ensures the positivity of all the CBFs without any additional
restrictions on the initial conditions. It is shown that the &quot;safety filter&quot;
designed in the paper guarantees safety in the presence of an arbitrary
operator input. This is similar to an automotive system in which a safety
feedback law overrides -- but only when necessary -- the possibly unsafe
steering, acceleration, or braking by a vigorous but inexperienced driver.
Simulations have been performed for a process in metal additive manufacturing,
which show that the operator&apos;s heat-and-cool commands to the Stefan model are
being obeyed but without the liquid ever freezing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Koga_S/0/1/0/all/0/1&quot;&gt;Shumon Koga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Krstic_M/0/1/0/all/0/1&quot;&gt;Miroslav Krstic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01193">
<title>Transformers for prompt-level EMA non-response prediction. (arXiv:2111.01193v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01193</link>
<description rdf:parseType="Literal">&lt;p&gt;Ecological Momentary Assessments (EMAs) are an important psychological data
source for measuring current cognitive states, affect, behavior, and
environmental factors from participants in mobile health (mHealth) studies and
treatment programs. Non-response, in which participants fail to respond to EMA
prompts, is an endemic problem. The ability to accurately predict non-response
could be utilized to improve EMA delivery and develop compliance interventions.
Prior work has explored classical machine learning models for predicting
non-response. However, as increasingly large EMA datasets become available,
there is the potential to leverage deep learning models that have been
effective in other fields. Recently, transformer models have shown
state-of-the-art performance in NLP and other domains. This work is the first
to explore the use of transformers for EMA data analysis. We address three key
questions in applying transformers to EMA data: 1. Input representation, 2.
encoding temporal information, 3. utility of pre-training on improving
downstream prediction task performance. The transformer model achieves a
non-response prediction AUC of 0.77 and is significantly better than classical
ML and LSTM-based deep learning models. We will make our a predictive model
trained on a corpus of 40K EMA samples freely-available to the research
community, in order to facilitate the development of future transformer-based
EMA analysis works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagesh_S/0/1/0/all/0/1&quot;&gt;Supriya Nagesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Alexander Moreno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carpenter_S/0/1/0/all/0/1&quot;&gt;Stephanie M. Carpenter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yap_J/0/1/0/all/0/1&quot;&gt;Jamie Yap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1&quot;&gt;Soujanya Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lizotte_S/0/1/0/all/0/1&quot;&gt;Steven Lloyd Lizotte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_N/0/1/0/all/0/1&quot;&gt;Neng Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Santosh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_C/0/1/0/all/0/1&quot;&gt;Cho Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wetter_D/0/1/0/all/0/1&quot;&gt;David W. Wetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nahum_Shani_I/0/1/0/all/0/1&quot;&gt;Inbal Nahum-Shani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1&quot;&gt;James M. Rehg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01195">
<title>A Tool for Reliability Assessment of Smart and Active Distribution Systems -- RELSAD. (arXiv:2111.01195v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01195</link>
<description rdf:parseType="Literal">&lt;p&gt;With increased penetration of new technology in the distribution systems such
as renewable energy resources, flexible resources, and information and
communication technology, the distribution systems become more complex and
dynamic. The traditional reliability analysis methods do not consider the new
components and technology and new considerations need to be taken to address
these new changes in the distribution system. This paper presents an
open-source reliability assessment tool for smart and active distribution
systems (RELSAD). The tool aims to function as a foundation for reliability
calculation in the smart and active distribution systems, where these new
components and technologies are included. The tool is made as a Python package
built up based on an object-oriented programming approach. The method will be
illustrated on the IEEE 33-bus system with the inclusion of generation,
battery, and ICT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Myhre_S/0/1/0/all/0/1&quot;&gt;Stine Fleischer Myhre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fosso_O/0/1/0/all/0/1&quot;&gt;Olav Bjarte Fosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heegaard_P/0/1/0/all/0/1&quot;&gt;Poul Einar Heegaard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gjerde_O/0/1/0/all/0/1&quot;&gt;Oddbj&amp;#xf8;rn Gjerde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01196">
<title>Dynamic Geometric Set Cover, Revisited. (arXiv:2111.01196v1 [cs.CG])</title>
<link>http://arxiv.org/abs/2111.01196</link>
<description rdf:parseType="Literal">&lt;p&gt;Geometric set cover is a classical problem in computational geometry, which
has been extensively studied in the past. In the dynamic version of the
problem, points and ranges may be inserted and deleted, and our goal is to
efficiently maintain a set cover solution (satisfying certain quality
requirement). In this paper, we give a plethora of new dynamic geometric set
cover data structures in 1D and 2D, which significantly improve and extend the
previous results:
&lt;/p&gt;
&lt;p&gt;1. The first data structure for $(1+\varepsilon)$-approximate dynamic
interval set cover with polylogarithmic amortized update time. Specifically, we
achieve an update time of $O(\log^3 n/\varepsilon)$, improving the
$O(n^\delta/\varepsilon)$ bound of Agarwal et al. [SoCG&apos;20], where $\delta&amp;gt;0$
denotes an arbitrarily small constant.
&lt;/p&gt;
&lt;p&gt;2. A data structure for $O(1)$-approximate dynamic unit-square set cover with
$2^{O(\sqrt{\log n})}$ amortized update time, substantially improving the
$O(n^{1/2+\delta})$ update time of Agarwal et al. [SoCG&apos;20].
&lt;/p&gt;
&lt;p&gt;3. A data structure for $O(1)$-approximate dynamic square set cover with
$O(n^{1/2+\delta})$ randomized amortized update time, improving the
$O(n^{2/3+\delta})$ update time of Chan and He [SoCG&apos;21].
&lt;/p&gt;
&lt;p&gt;4. A data structure for $O(1)$-approximate dynamic 2D halfplane set cover
with $O(n^{17/23+\delta})$ randomized amortized update time. The previous
solution for halfplane set cover by Chan and He [SoCG&apos;21] is slower and can
only report the size of the approximate solution.
&lt;/p&gt;
&lt;p&gt;5. The first sublinear results for the \textit{weighted} version of dynamic
geometric set cover. Specifically, we give a data structure for
$(3+o(1))$-approximate dynamic weighted interval set cover with
$2^{O(\sqrt{\log n \log\log n})}$ amortized update time and a data structure
for $O(1)$-approximate dynamic weighted unit-square set cover with
$O(n^\delta)$ amortized update time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Timothy M. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qizheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suri_S/0/1/0/all/0/1&quot;&gt;Subhash Suri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1&quot;&gt;Jie Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01201">
<title>Unintended Selection: Persistent Qualification Rate Disparities and Interventions. (arXiv:2111.01201v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01201</link>
<description rdf:parseType="Literal">&lt;p&gt;Realistically -- and equitably -- modeling the dynamics of group-level
disparities in machine learning remains an open problem. In particular, we
desire models that do not suppose inherent differences between artificial
groups of people -- but rather endogenize disparities by appeal to unequal
initial conditions of insular subpopulations. In this paper, agents each have a
real-valued feature $X$ (e.g., credit score) informed by a &quot;true&quot; binary label
$Y$ representing qualification (e.g., for a loan). Each agent alternately (1)
receives a binary classification label $\hat{Y}$ (e.g., loan approval) from a
Bayes-optimal machine learning classifier observing $X$ and (2) may update
their qualification $Y$ by imitating successful strategies (e.g., seek a raise)
within an isolated group $G$ of agents to which they belong. We consider the
disparity of qualification rates $\Pr(Y=1)$ between different groups and how
this disparity changes subject to a sequence of Bayes-optimal classifiers
repeatedly retrained on the global population. We model the evolving
qualification rates of each subpopulation (group) using the replicator
equation, which derives from a class of imitation processes. We show that
differences in qualification rates between subpopulations can persist
indefinitely for a set of non-trivial equilibrium states due to uniformed
classifier deployments, even when groups are identical in all aspects except
initial qualification densities. We next simulate the effects of commonly
proposed fairness interventions on this dynamical system along with a new
feedback control mechanism capable of permanently eliminating group-level
qualification rate disparities. We conclude by discussing the limitations of
our model and findings and by outlining potential future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raab_R/0/1/0/all/0/1&quot;&gt;Reilly Raab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01203">
<title>One Proxy Device Is Enough for Hardware-Aware Neural Architecture Search. (arXiv:2111.01203v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01203</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNNs) are used in numerous real-world
applications such as vision-based autonomous driving and video content
analysis. To run CNN inference on various target devices, hardware-aware neural
architecture search (NAS) is crucial. A key requirement of efficient
hardware-aware NAS is the fast evaluation of inference latencies in order to
rank different architectures. While building a latency predictor for each
target device has been commonly used in state of the art, this is a very
time-consuming process, lacking scalability in the presence of extremely
diverse devices. In this work, we address the scalability challenge by
exploiting latency monotonicity -- the architecture latency rankings on
different devices are often correlated. When strong latency monotonicity
exists, we can re-use architectures searched for one proxy device on new target
devices, without losing optimality. In the absence of strong latency
monotonicity, we propose an efficient proxy adaptation technique to
significantly boost the latency monotonicity. Finally, we validate our approach
and conduct experiments with devices of different platforms on multiple
mainstream search spaces, including MobileNet-V2, MobileNet-V3, NAS-Bench-201,
ProxylessNAS and FBNet. Our results highlight that, by using just one proxy
device, we can find almost the same Pareto-optimal architectures as the
existing per-device NAS, while avoiding the prohibitive cost of building a
latency predictor for each device.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_B/0/1/0/all/0/1&quot;&gt;Bingqian Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Weiwen Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yiyu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1&quot;&gt;Shaolei Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01205">
<title>Evaluating robustness of You Only Hear Once(YOHO) Algorithm on noisy audios in the VOICe Dataset. (arXiv:2111.01205v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2111.01205</link>
<description rdf:parseType="Literal">&lt;p&gt;Sound event detection (SED) in machine listening entails identifying the
different sounds in an audio file and identifying the start and end time of a
particular sound event in the audio. SED finds use in various applications such
as audio surveillance, speech recognition, and context-based indexing and
retrieval of data in a multimedia database. However, in real-life scenarios,
the audios from various sources are seldom devoid of any interfering noise or
disturbance. In this paper, we test the performance of the You Only Hear Once
(YOHO) algorithm on noisy audio data. Inspired by the You Only Look Once (YOLO)
algorithm in computer vision, the YOHO algorithm can match the performance of
the various state-of-the-art algorithms on datasets such as Music Speech
Detection Dataset, TUT Sound Event, and Urban-SED datasets but at lower
inference times. In this paper, we explore the performance of the YOHO
algorithm on the VOICe dataset containing audio files with noise at different
sound-to-noise ratios (SNR). YOHO could outperform or at least match the best
performing SED algorithms reported in the VOICe dataset paper and make
inferences in less time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1&quot;&gt;Soham Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1&quot;&gt;Kshitiz Lakhotia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulimani_M/0/1/0/all/0/1&quot;&gt;Manjunath Mulimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01207">
<title>Sig-Wasserstein GANs for Time Series Generation. (arXiv:2111.01207v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01207</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthetic data is an emerging technology that can significantly accelerate
the development and deployment of AI machine learning pipelines. In this work,
we develop high-fidelity time-series generators, the SigWGAN, by combining
continuous-time stochastic models with the newly proposed signature $W_1$
metric. The former are the Logsig-RNN models based on the stochastic
differential equations, whereas the latter originates from the universal and
principled mathematical features to characterize the measure induced by time
series. SigWGAN allows turning computationally challenging GAN min-max problem
into supervised learning while generating high fidelity samples. We validate
the proposed model on both synthetic data generated by popular quantitative
risk models and empirical financial data. Codes are available at
https://github.com/SigCGANs/Sig-Wasserstein-GANs.git.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1&quot;&gt;Hao Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1&quot;&gt;Lukasz Szpruch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabate_Vidales_M/0/1/0/all/0/1&quot;&gt;Marc Sabate-Vidales&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1&quot;&gt;Baoren Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiese_M/0/1/0/all/0/1&quot;&gt;Magnus Wiese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1&quot;&gt;Shujian Liao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01210">
<title>Understanding the Use of Voice Assistants by Older Adults. (arXiv:2111.01210v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2111.01210</link>
<description rdf:parseType="Literal">&lt;p&gt;Older adults are using voice-based technologies in a variety of different
contexts and are uniquely positioned to benefit from smart speakers&apos; handsfree,
voice-based interface. In order to better understand the ways in which older
adults engage with and learn how to use smart speakers, we conducted
qualitative, semi-structured interviews with four older adults who own smart
speakers. Emerging findings indicate that older adults benefit from smart
speakers as both an assistive and a social technology. Findings also suggest
that when older adults learn new technologies in a formal, communal environment
there is successful adoption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanley_M/0/1/0/all/0/1&quot;&gt;Margot Hanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azenkot_S/0/1/0/all/0/1&quot;&gt;Shiri Azenkot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01213">
<title>Finite Representation Property for Relation Algebra Reducts. (arXiv:2111.01213v1 [math.LO])</title>
<link>http://arxiv.org/abs/2111.01213</link>
<description rdf:parseType="Literal">&lt;p&gt;The decision problem of membership in the Representation Class of Relation
Algebras (RRA) for finite structures is undecidable. However, this does not
hold for many Relation Algebra reduct languages. Two well known properties that
are sufficient for decidability are the Finite Axiomatisability (FA) of the
representation class and the Finite Representation Property (FRP). Furthermore,
neither of the properties is stronger that the other, and thus, neither is also
a necessary condition. Although many results are known in the area of FA, the
FRP remains unknown for the majority of the reduct languages. Here we
conjecture that the FRP fails for a Relation Algebra reduct if and only if it
contains both composition and negation, or both composition and meet. We then
show the right-to-left implication of the conjecture holds and present
preliminary results that suggest the left-to-right implication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Semrl_J/0/1/0/all/0/1&quot;&gt;Ja&amp;#x161; &amp;#x160;emrl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01215">
<title>Gradient Frequency Modulation for Visually Explaining Video Understanding Models. (arXiv:2111.01215v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01215</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications, it is essential to understand why a machine learning
model makes the decisions it does, but this is inhibited by the black-box
nature of state-of-the-art neural networks. Because of this, increasing
attention has been paid to explainability in deep learning, including in the
area of video understanding. Due to the temporal dimension of video data, the
main challenge of explaining a video action recognition model is to produce
spatiotemporally consistent visual explanations, which has been ignored in the
existing literature. In this paper, we propose Frequency-based Extremal
Perturbation (F-EP) to explain a video understanding model&apos;s decisions. Because
the explanations given by perturbation methods are noisy and non-smooth both
spatially and temporally, we propose to modulate the frequencies of gradient
maps from the neural network model with a Discrete Cosine Transform (DCT). We
show in a range of experiments that F-EP provides more spatiotemporally
consistent explanations that more faithfully represent the model&apos;s decisions
compared to the existing state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xinmiao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1&quot;&gt;Wentao Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wright_M/0/1/0/all/0/1&quot;&gt;Matthew Wright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1&quot;&gt;Yu Kong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01216">
<title>Learning To Generate Piano Music With Sustain Pedals. (arXiv:2111.01216v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2111.01216</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed a growing interest in research related to the
detection of piano pedals from audio signals in the music information retrieval
community. However, to our best knowledge, recent generative models for
symbolic music have rarely taken piano pedals into account. In this work, we
employ the transcription model proposed by Kong et al. to get pedal information
from the audio recordings of piano performance in the AILabs1k7 dataset, and
then modify the Compound Word Transformer proposed by Hsiao et al. to build a
Transformer decoder that generates pedal-related tokens along with other
musical tokens. While the work is done by using inferred sustain pedal
information as training data, the result shows hope for further improvement and
the importance of the involvement of sustain pedal in tasks of piano
performance generations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ching_J/0/1/0/all/0/1&quot;&gt;Joann Ching&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01218">
<title>Confidentiality and Integrity Mechanisms for Microservices Communication. (arXiv:2111.01218v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2111.01218</link>
<description rdf:parseType="Literal">&lt;p&gt;The microservices architecture tries to deal with the challenges posed by
distributed systems, such as scalability, availability, and system deployment;
by means of highly cohesive, heterogeneous, and independent microservices.
However, this architecture also brings new security challenges related to
communication, system design, development, and operation. The literature
contains spread information regarding security related solutions for
microservices-based systems, but this spread makes difficult for practitioners
to adopt novel security related solutions. In this study, we aim to present a
catalogue of security solutions based on algorithms, protocols, standards, or
implementations; supporting principles or characteristics of information
security, also considering the three possible states of data, according to the
McCumber Cube. Our research follows a Systematic Literature Review,
synthesizing the results with a meta-aggregation process. We identified a total
of 30 primary studies, yielding 71 security solutions for the communication of
microservices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leines_Vite_L/0/1/0/all/0/1&quot;&gt;Lenin Leines-Vite&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Arriaga_J/0/1/0/all/0/1&quot;&gt;Juan Carlos P&amp;#xe9;rez-Arriaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Limon_X/0/1/0/all/0/1&quot;&gt;Xavier Lim&amp;#xf3;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01221">
<title>Robust Federated Learning via Over-The-Air Computation. (arXiv:2111.01221v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01221</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the robustness of over-the-air federated learning to
Byzantine attacks. The simple averaging of the model updates via over-the-air
computation makes the learning task vulnerable to random or intended
modifications of the local model updates of some malicious clients. We propose
a robust transmission and aggregation framework to such attacks while
preserving the benefits of over-the-air computation for federated learning. For
the proposed robust federated learning, the participating clients are randomly
divided into groups and a transmission time slot is allocated to each group.
The parameter server aggregates the results of the different groups using a
robust aggregation technique and conveys the result to the clients for another
training round. We also analyze the convergence of the proposed algorithm.
Numerical simulations confirm the robustness of the proposed approach to
Byzantine attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sifaou_H/0/1/0/all/0/1&quot;&gt;Houssem Sifaou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Geoffrey Ye Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01222">
<title>Kernel Deformed Exponential Families for Sparse Continuous Attention. (arXiv:2111.01222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01222</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanisms take an expectation of a data representation with
respect to probability weights. This creates summary statistics that focus on
important features. Recently, (Martins et al. 2020, 2021) proposed continuous
attention mechanisms, focusing on unimodal attention densities from the
exponential and deformed exponential families: the latter has sparse support.
(Farinhas et al. 2021) extended this to use Gaussian mixture attention
densities, which are a flexible class with dense support. In this paper, we
extend this to two general flexible classes: kernel exponential families and
our new sparse counterpart kernel deformed exponential families. Theoretically,
we show new existence results for both kernel exponential and deformed
exponential families, and that the deformed case has similar approximation
capabilities to kernel exponential families. Experiments show that kernel
deformed exponential families can attend to multiple compact regions of the
data domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Alexander Moreno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagesh_S/0/1/0/all/0/1&quot;&gt;Supriya Nagesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhenke Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dempsey_W/0/1/0/all/0/1&quot;&gt;Walter Dempsey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1&quot;&gt;James M. Rehg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01223">
<title>A framework for causal segmentation analysis with machine learning in large-scale digital experiments. (arXiv:2111.01223v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2111.01223</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end methodological framework for causal segment
discovery that aims to uncover differential impacts of treatments across
subgroups of users in large-scale digital experiments. Building on recent
developments in causal inference and non/semi-parametric statistics, our
approach unifies two objectives: (1) the discovery of user segments that stand
to benefit from a candidate treatment based on subgroup-specific treatment
effects, and (2) the evaluation of causal impacts of dynamically assigning
units to a study&apos;s treatment arm based on their predicted segment-specific
benefit or harm. Our proposal is model-agnostic, capable of incorporating
state-of-the-art machine learning algorithms into the estimation procedure, and
is applicable in randomized A/B tests and quasi-experiments. An open source R
package implementation, sherlock, is introduced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hejazi_N/0/1/0/all/0/1&quot;&gt;Nima S. Hejazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Wenjing Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anand_S/0/1/0/all/0/1&quot;&gt;Sathya Anand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01225">
<title>Identifying causal associations in tweets using deep learning: Use case on diabetes-related tweets from 2017-2021. (arXiv:2111.01225v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01225</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: Leveraging machine learning methods, we aim to extract both
explicit and implicit cause-effect associations in patient-reported,
diabetes-related tweets and provide a tool to better understand opinion,
feelings and observations shared within the diabetes online community from a
causality perspective. Materials and Methods: More than 30 million
diabetes-related tweets in English were collected between April 2017 and
January 2021. Deep learning and natural language processing methods were
applied to focus on tweets with personal and emotional content. A
cause-effect-tweet dataset was manually labeled and used to train 1) a
fine-tuned Bertweet model to detect causal sentences containing a causal
association 2) a CRF model with BERT based features to extract possible
cause-effect associations. Causes and effects were clustered in a
semi-supervised approach and visualised in an interactive cause-effect-network.
Results: Causal sentences were detected with a recall of 68% in an imbalanced
dataset. A CRF model with BERT based features outperformed a fine-tuned BERT
model for cause-effect detection with a macro recall of 68%. This led to 96,676
sentences with cause-effect associations. &quot;Diabetes&quot; was identified as the
central cluster followed by &quot;Death&quot; and &quot;Insulin&quot;. Insulin pricing related
causes were frequently associated with &quot;Death&quot;. Conclusions: A novel
methodology was developed to detect causal sentences and identify both explicit
and implicit, single and multi-word cause and corresponding effect as expressed
in diabetes-related tweets leveraging BERT-based architectures and visualised
as cause-effect-network. Extracting causal associations on real-life, patient
reported outcomes in social media data provides a useful complementary source
of information in diabetes research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahne_A/0/1/0/all/0/1&quot;&gt;Adrian Ahne&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khetan_V/0/1/0/all/0/1&quot;&gt;Vivek Khetan&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tannier_X/0/1/0/all/0/1&quot;&gt;Xavier Tannier&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizvi_M/0/1/0/all/0/1&quot;&gt;Md Imbessat Hassan Rizvi&lt;/a&gt; (5), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czernichow_T/0/1/0/all/0/1&quot;&gt;Thomas Czernichow&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orchard_F/0/1/0/all/0/1&quot;&gt;Francisco Orchard&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bour_C/0/1/0/all/0/1&quot;&gt;Charline Bour&lt;/a&gt; (6), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fano_A/0/1/0/all/0/1&quot;&gt;Andrew Fano&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fagherazzi_G/0/1/0/all/0/1&quot;&gt;Guy Fagherazzi&lt;/a&gt; (6) ((1) Paris-Saclay University, UVSQ, Inserm, Gustave Roussy, Exposome and Heredity team, CESP, F-94805, Villejuif, France, (2) Epiconcept, Paris, France, (3) Accenture Labs, San Francisco, USA, (4) Sorbonne University, Inserm, University Sorbonne Paris Nord, Laboratoire d&amp;#x27;Informatique Medicale et d&amp;#x27;Ingenierie des Connaissances pour la e-Sante, LIMICS, Paris, France, (5) Indian Institute of Science, Bengaluru, India, (6) Deep Digital Phenotyping Research Unit, Department of Precision Health, Luxembourg Institute of Health, Strassen, Luxembourg)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01228">
<title>OPF-Learn: An Open-Source Framework for Creating Representative AC Optimal Power Flow Datasets. (arXiv:2111.01228v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01228</link>
<description rdf:parseType="Literal">&lt;p&gt;Increasing levels of renewable generation motivate a growing interest in
data-driven approaches for AC optimal power flow (AC OPF) to manage
uncertainty; however, a lack of disciplined dataset creation and benchmarking
prohibits useful comparison among approaches in the literature. To instill
confidence, models must be able to reliably predict solutions across a wide
range of operating conditions. This paper develops the OPF-Learn package for
Julia and Python, which uses a computationally efficient approach to create
representative datasets that span a wide spectrum of the AC OPF feasible
region. Load profiles are uniformly sampled from a convex set that contains the
AC OPF feasible set. For each infeasible point found, the convex set is reduced
using infeasibility certificates, found by using properties of a relaxed
formulation. The framework is shown to generate datasets that are more
representative of the entire feasible space versus traditional techniques seen
in the literature, improving machine learning model performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Joswig_Jones_T/0/1/0/all/0/1&quot;&gt;Trager Joswig-Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zamzam_A/0/1/0/all/0/1&quot;&gt;Ahmed S. Zamzam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baker_K/0/1/0/all/0/1&quot;&gt;Kyri Baker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01229">
<title>Impact of network topology on efficiency of proximity measures for community detection. (arXiv:2111.01229v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01229</link>
<description rdf:parseType="Literal">&lt;p&gt;Many community detection algorithms require the introduction of a measure on
the set of nodes. Previously, a lot of efforts have been made to find the
top-performing measures. In most cases, experiments were conducted on several
datasets or random graphs. However, graphs representing real systems can be
completely different in topology: the difference can be in the size of the
network, the structure of clusters, the distribution of degrees, the density of
edges, and so on. Therefore, it is necessary to explicitly check whether the
advantage of one measure over another is preserved for different network
topologies. In this paper, we consider the efficiency of several proximity
measures for clustering networks with different structures. The results show
that the efficiency of measures really depends on the network topology in some
cases. However, it is possible to find measures that behave well for most
topologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aynulin_R/0/1/0/all/0/1&quot;&gt;Rinat Aynulin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01231">
<title>Switch Point biased Self-Training: Re-purposing Pretrained Models for Code-Switching. (arXiv:2111.01231v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01231</link>
<description rdf:parseType="Literal">&lt;p&gt;Code-switching (CS), a ubiquitous phenomenon due to the ease of communication
it offers in multilingual communities still remains an understudied problem in
language processing. The primary reasons behind this are: (1) minimal efforts
in leveraging large pretrained multilingual models, and (2) the lack of
annotated data. The distinguishing case of low performance of multilingual
models in CS is the intra-sentence mixing of languages leading to switch
points. We first benchmark two sequence labeling tasks -- POS and NER on 4
different language pairs with a suite of pretrained models to identify the
problems and select the best performing model, char-BERT, among them
(addressing (1)). We then propose a self training method to repurpose the
existing pretrained models using a switch-point bias by leveraging unannotated
data (addressing (2)). We finally demonstrate that our approach performs well
on both tasks by reducing the gap between the switch point performance while
retaining the overall performance on two distinct language pairs in both the
tasks. Our code is available here:
https://github.com/PC09/EMNLP2021-Switch-Point-biased-Self-Training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chopra_P/0/1/0/all/0/1&quot;&gt;Parul Chopra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1&quot;&gt;Sai Krishna Rallabandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1&quot;&gt;Alan W Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1&quot;&gt;Khyathi Raghavi Chandu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01233">
<title>Conservative Integrators for Vortex Blob Methods. (arXiv:2111.01233v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01233</link>
<description rdf:parseType="Literal">&lt;p&gt;Conservative symmetric second-order one-step integrators are derived using
the Discrete Multiplier Method for a family of vortex-blob models approximating
the incompressible Euler&apos;s equations on the plane. Conservative properties and
second order convergence are proved. A rational function approximation was used
to approximate the exponential integral that appears in the Hamiltonian.
Numerical experiments are shown to verify the conservative property of these
integrators, their second-order accuracy, and as well as the resulting spatial
and temporal accuracy of the vortex blob method. Moreover, the derived implicit
conservative integrators are shown to be better at preserving conserved
quantities than standard higher-order explicit integrators on comparable
computation times.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gormezano_C/0/1/0/all/0/1&quot;&gt;Cem Gormezano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nave_J/0/1/0/all/0/1&quot;&gt;Jean-Christophe Nave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wan_A/0/1/0/all/0/1&quot;&gt;Andy T. S. Wan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01235">
<title>Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions. (arXiv:2111.01235v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01235</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of identifying algorithmic recourse for people affected by
machine learning model decisions has received much attention recently. Some
recent works model user-incurred cost, which is directly linked to user
satisfaction. But they assume a single global cost function that is shared
across all users. This is an unrealistic assumption when users have dissimilar
preferences about their willingness to act upon a feature and different costs
associated with changing that feature. In this work, we formalize the notion of
user-specific cost functions and introduce a new method for identifying
actionable recourses for users. By default, we assume that users&apos; cost
functions are hidden from the recourse method, though our framework allows
users to partially or completely specify their preferences or cost function. We
propose an objective function, Expected Minimum Cost (EMC), based on two key
ideas: (1) when presenting a set of options to a user, it is vital that there
is at least one low-cost solution the user could adopt; (2) when we do not know
the user&apos;s true cost function, we can approximately optimize for user
satisfaction by first sampling plausible cost functions, then finding a set
that achieves a good cost for the user in expectation. We optimize EMC with a
novel discrete optimization algorithm, Cost-Optimized Local Search (COLS),
which is guaranteed to improve the recourse set quality over iterations.
Experimental evaluation on popular real-world datasets with simulated user
costs demonstrates that our method satisfies up to 25.89 percentage points more
users compared to strong baseline methods. Using standard fairness metrics, we
also show that our method can provide more fair solutions across demographic
groups than comparable methods, and we verify that our method is robust to
misspecification of the cost function distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1&quot;&gt;Prateek Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1&quot;&gt;Peter Hase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01236">
<title>HRViT: Multi-Scale High-Resolution Vision Transformer. (arXiv:2111.01236v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01236</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision transformers (ViTs) have attracted much attention for their superior
performance on computer vision tasks. To address their limitations of
single-scale low-resolution representations, prior work adapts ViTs to
high-resolution dense prediction tasks with hierarchical architectures to
generate pyramid features. However, multi-scale representation learning is
still under-explored on ViTs, given their classification-like sequential
topology. To enhance ViTs with more capability to learn semantically-rich and
spatially-precise multi-scale representations, in this work, we present an
efficient integration of high-resolution multi-branch architectures with vision
transformers, dubbed HRViT, pushing the Pareto front of dense prediction tasks
to a new level. We explore heterogeneous branch design, reduce the redundancy
in linear layers, and augment the model nonlinearity to balance the model
performance and hardware efficiency. The proposed HRViT achieves 50.20% mIoU on
ADE20K and 83.16% mIoU on Cityscapes for semantic segmentation tasks,
surpassing state-of-the-art MiT and CSWin with an average of +1.78 mIoU
improvement, 28% parameter reduction, and 21% FLOPs reduction, demonstrating
the potential of HRViT as strong vision backbones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1&quot;&gt;Hyoukjun Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dilin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Meng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu-Hsin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_D/0/1/0/all/0/1&quot;&gt;David Z. Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01243">
<title>Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. (arXiv:2111.01243v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01243</link>
<description rdf:parseType="Literal">&lt;p&gt;Large, pre-trained transformer-based language models such as BERT have
drastically changed the Natural Language Processing (NLP) field. We present a
survey of recent work that uses these large language models to solve NLP tasks
via pre-training then fine-tuning, prompting, or text generation approaches. We
also present approaches that use pre-trained language models to generate data
for training augmentation or other purposes. We conclude with discussions on
limitations and suggested directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_B/0/1/0/all/0/1&quot;&gt;Bonan Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_H/0/1/0/all/0/1&quot;&gt;Hayley Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sulem_E/0/1/0/all/0/1&quot;&gt;Elior Sulem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veyseh_A/0/1/0/all/0/1&quot;&gt;Amir Pouran Ben Veyseh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thien Huu Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainz_O/0/1/0/all/0/1&quot;&gt;Oscar Sainz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;Eneko Agirre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinz_I/0/1/0/all/0/1&quot;&gt;Ilana Heinz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01245">
<title>Learning Eye-in-Hand Camera Calibration from a Single Image. (arXiv:2111.01245v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01245</link>
<description rdf:parseType="Literal">&lt;p&gt;Eye-in-hand camera calibration is a fundamental and long-studied problem in
robotics. We present a study on using learning-based methods for solving this
problem online from a single RGB image, whilst training our models with
entirely synthetic data. We study three main approaches: one direct regression
model that directly predicts the extrinsic matrix from an image, one sparse
correspondence model that regresses 2D keypoints and then uses PnP, and one
dense correspondence model that uses regressed depth and segmentation maps to
enable ICP pose estimation. In our experiments, we benchmark these methods
against each other and against well-established classical methods, to find the
surprising result that direct regression outperforms other approaches, and we
perform noise-sensitivity analysis to gain further insights into these results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valassakis_E/0/1/0/all/0/1&quot;&gt;Eugene Valassakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dreczkowski_K/0/1/0/all/0/1&quot;&gt;Kamil Dreczkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1&quot;&gt;Edward Johns&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01253">
<title>Neural Scene Flow Prior. (arXiv:2111.01253v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01253</link>
<description rdf:parseType="Literal">&lt;p&gt;Before the deep learning revolution, many perception algorithms were based on
runtime optimization in conjunction with a strong prior/regularization penalty.
A prime example of this in computer vision is optical and scene flow.
Supervised learning has largely displaced the need for explicit regularization.
Instead, they rely on large amounts of labeled data to capture prior
statistics, which are not always readily available for many problems. Although
optimization is employed to learn the neural network, the weights of this
network are frozen at runtime. As a result, these learning solutions are
domain-specific and do not generalize well to other statistically different
scenarios. This paper revisits the scene flow problem that relies predominantly
on runtime optimization and strong regularization. A central innovation here is
the inclusion of a neural scene flow prior, which uses the architecture of
neural networks as a new type of implicit regularizer. Unlike learning-based
scene flow methods, optimization occurs at runtime, and our approach needs no
offline datasets -- making it ideal for deployment in new environments such as
autonomous driving. We show that an architecture based exclusively on
multilayer perceptrons (MLPs) can be used as a scene flow prior. Our method
attains competitive -- if not better -- results on scene flow benchmarks. Also,
our neural prior&apos;s implicit and continuous scene flow representation allows us
to estimate dense long-term correspondences across a sequence of point clouds.
The dense motion information is represented by scene flow fields where points
can be propagated through time by integrating motion vectors. We demonstrate
such a capability by accumulating a sequence of lidar point clouds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xueqian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontes_J/0/1/0/all/0/1&quot;&gt;Jhony Kaesemodel Pontes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1&quot;&gt;Simon Lucey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01254">
<title>Unique Games hardness of Quantum Max-Cut, and a vector-valued Borell&apos;s inequality. (arXiv:2111.01254v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2111.01254</link>
<description rdf:parseType="Literal">&lt;p&gt;The Gaussian noise stability of a function $f:\mathbb{R}^n \to \{-1, 1\}$ is
the expected value of $f(\boldsymbol{x}) \cdot f(\boldsymbol{y})$ over
$\rho$-correlated Gaussian random variables $\boldsymbol{x}$ and
$\boldsymbol{y}$. Borell&apos;s inequality states that for $-1 \leq \rho \leq 0$,
this is minimized by the halfspace $f(x) = \mathrm{sign}(x_1)$. In this work,
we generalize this result to hold for functions $f:\mathbb{R}^n \to S^{k-1}$
which output $k$-dimensional unit vectors. Our main result shows that the
expected value of $\langle f(\boldsymbol{x}), f(\boldsymbol{y})\rangle$ over
$\rho$-correlated Gaussians $\boldsymbol{x}$ and $\boldsymbol{y}$ is minimized
by the function $f(x) = x_{\leq k} / \Vert x_{\leq k} \Vert$, where $x_{\leq k}
= (x_1, \ldots, x_k)$.
&lt;/p&gt;
&lt;p&gt;As an application, we show several hardness of approximation results for
Quantum Max-Cut, a special case of the local Hamiltonian problem related to the
anti-ferromagnetic Heisenberg model. Quantum Max-Cut is a natural quantum
analogue of classical Max-Cut and has become testbed for designing quantum
approximation algorithms. We show the following:
&lt;/p&gt;
&lt;p&gt;1. The integrality gap of the basic SDP is $0.498$, matching an existing
rounding algorithm. Combined with existing approximation results for Quantum
Max-Cut, this shows that the basic SDP does not achieve the optimal
approximation ratio.
&lt;/p&gt;
&lt;p&gt;2. It is Unique Games-hard (UG-hard) to compute a
$(0.956+\varepsilon)$-approximation to the value of the best product state,
matching an existing approximation algorithm. This result may be viewed as
applying to a generalization of Max-Cut where one seeks to assign
$3$-dimensional unit vectors to each vertex; we also give tight hardness
results for the analogous $k$-dimensional generalization of Max-Cut.
&lt;/p&gt;
&lt;p&gt;3. It is UG-hard to compute a $(0.956+\varepsilon)$-approximation to the
value of the best (possibly entangled) state.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hwang_Y/0/1/0/all/0/1&quot;&gt;Yeongwoo Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Neeman_J/0/1/0/all/0/1&quot;&gt;Joe Neeman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Parekh_O/0/1/0/all/0/1&quot;&gt;Ojas Parekh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Thompson_K/0/1/0/all/0/1&quot;&gt;Kevin Thompson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wright_J/0/1/0/all/0/1&quot;&gt;John Wright&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01256">
<title>Reverse engineering recurrent neural networks with Jacobian switching linear dynamical systems. (arXiv:2111.01256v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01256</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are powerful models for processing
time-series data, but it remains challenging to understand how they function.
Improving this understanding is of substantial interest to both the machine
learning and neuroscience communities. The framework of reverse engineering a
trained RNN by linearizing around its fixed points has provided insight, but
the approach has significant challenges. These include difficulty choosing
which fixed point to expand around when studying RNN dynamics and error
accumulation when reconstructing the nonlinear dynamics with the linearized
dynamics. We present a new model that overcomes these limitations by
co-training an RNN with a novel switching linear dynamical system (SLDS)
formulation. A first-order Taylor series expansion of the co-trained RNN and an
auxiliary function trained to pick out the RNN&apos;s fixed points govern the SLDS
dynamics. The results are a trained SLDS variant that closely approximates the
RNN, an auxiliary function that can produce a fixed point for each point in
state-space, and a trained nonlinear RNN whose dynamics have been regularized
such that its first-order terms perform the computation, if possible. This
model removes the post-training fixed point optimization and allows us to
unambiguously study the learned dynamics of the SLDS at any point in
state-space. It also generalizes SLDS models to continuous manifolds of
switching points while sharing parameters across switches. We validate the
utility of the model on two synthetic tasks relevant to previous work reverse
engineering RNNs. We then show that our model can be used as a drop-in in more
complex architectures, such as LFADS, and apply this LFADS hybrid to analyze
single-trial spiking activity from the motor system of a non-human primate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1&quot;&gt;Jimmy T.H. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linderman_S/0/1/0/all/0/1&quot;&gt;Scott W. Linderman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sussillo_D/0/1/0/all/0/1&quot;&gt;David Sussillo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01257">
<title>Implicit Model Specialization through DAG-based Decentralized Federated Learning. (arXiv:2111.01257v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2111.01257</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning allows a group of distributed clients to train a common
machine learning model on private data. The exchange of model updates is
managed either by a central entity or in a decentralized way, e.g. by a
blockchain. However, the strong generalization across all clients makes these
approaches unsuited for non-independent and identically distributed (non-IID)
data.
&lt;/p&gt;
&lt;p&gt;We propose a unified approach to decentralization and personalization in
federated learning that is based on a directed acyclic graph (DAG) of model
updates. Instead of training a single global model, clients specialize on their
local data while using the model updates from other clients dependent on the
similarity of their respective data. This specialization implicitly emerges
from the DAG-based communication and selection of model updates. Thus, we
enable the evolution of specialized models, which focus on a subset of the data
and therefore cover non-IID data better than federated learning in a
centralized or blockchain-based setup.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the proposed solution is the first to unite
personalization and poisoning robustness in fully decentralized federated
learning. Our evaluation shows that the specialization of models emerges
directly from the DAG-based communication of model updates on three different
datasets. Furthermore, we show stable model accuracy and less variance across
clients when compared to federated averaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beilharz_J/0/1/0/all/0/1&quot;&gt;Jossekin Beilharz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfitzner_B/0/1/0/all/0/1&quot;&gt;Bjarne Pfitzner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_R/0/1/0/all/0/1&quot;&gt;Robert Schmid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geppert_P/0/1/0/all/0/1&quot;&gt;Paul Geppert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnrich_B/0/1/0/all/0/1&quot;&gt;Bernd Arnrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polze_A/0/1/0/all/0/1&quot;&gt;Andreas Polze&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01258">
<title>Safe Online Gain Optimization for Variable Impedance Control. (arXiv:2111.01258v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;Smooth behaviors are preferable for many contact-rich manipulation tasks.
Impedance control arises as an effective way to regulate robot movements by
mimicking a mass-spring-damping system. Consequently, the robot behavior can be
determined by the impedance gains. However, tuning the impedance gains for
different tasks is tricky, especially for unstructured environments. Moreover,
online adapting the optimal gains to meet the time-varying performance index is
even more challenging. In this paper, we present Safe Online Gain Optimization
for Variable Impedance Control (Safe OnGO-VIC). By reformulating the dynamics
of impedance control as a control-affine system, in which the impedance gains
are the inputs, we provide a novel perspective to understand variable impedance
control. Additionally, we innovatively formulate an optimization problem with
online collected force information to obtain the optimal impedance gains in
real-time. Safety constraints are also embedded in the proposed framework to
avoid unwanted collisions. We experimentally validated the proposed algorithm
on three manipulation tasks. Comparison results with a constant gain baseline
and an adaptive control method prove that the proposed algorithm is effective
and generalizable to different scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Changhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1&quot;&gt;Zhian Kuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1&quot;&gt;Masayoshi Tomizuka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01259">
<title>Verifying Contracts for Perturbed Control Systems using Linear Programming. (arXiv:2111.01259v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01259</link>
<description rdf:parseType="Literal">&lt;p&gt;Verifying specifications for large-scale control systems is of utmost
importance, but can be hard in practice as most formal verification methods can
not handle high-dimensional dynamics. Contract theory has been proposed as a
modular alternative to formal verification in which specifications are defined
by assumptions on the inputs to a component and guarantees on its outputs. In
this paper, we present linear-programming-based tools for verifying contracts
for control systems. We first consider the problem of verifying contracts
defined by time-invariant inequalities for unperturbed systems. We use
$k$-induction to show that contract verification can be achieved by considering
a collection of implications between inequalities, which are then recast as
linear programs. We then move our attention to perturbed systems. We present a
comparison-based framework, verifying that a perturbed system satisfies a
contract by checking that the corresponding unperturbed system satisfies a
robustified (and $\epsilon$-approximated) contract. In both cases, we present
explicit algorithms for contract verification, proving their correctness and
analyzing their complexity. We also demonstrate the verification process for
two case studies, one considering a two-vehicle autonomous driving scenario,
and one considering formation control of a multi-agent system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sharf_M/0/1/0/all/0/1&quot;&gt;Miel Sharf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Besselink_B/0/1/0/all/0/1&quot;&gt;Bart Besselink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Johansson_K/0/1/0/all/0/1&quot;&gt;Karl Henrik Johansson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01261">
<title>Joint Detection of Motion Boundaries and Occlusions. (arXiv:2111.01261v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01261</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose MONet, a convolutional neural network that jointly detects motion
boundaries (MBs) and occlusion regions (Occs) in video both forward and
backward in time. Detection is difficult because optical flow is discontinuous
along MBs and undefined in Occs, while many flow estimators assume smoothness
and a flow defined everywhere. To reason in the two time directions
simultaneously, we direct-warp the estimated maps between the two frames. Since
appearance mismatches between frames often signal vicinity to MBs or Occs, we
construct a cost block that for each feature in one frame records the lowest
discrepancy with matching features in a search range. This cost block is
two-dimensional, and much less expensive than the four-dimensional cost volumes
used in flow analysis. Cost-block features are computed by an encoder, and MB
and Occ estimates are computed by a decoder. We found that arranging decoder
layers fine-to-coarse, rather than coarse-to-fine, improves performance. MONet
outperforms the prior state of the art for both tasks on the Sintel and
FlyingChairsOcc benchmarks without any fine-tuning on them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hannah Halin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shuzhi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomasi_C/0/1/0/all/0/1&quot;&gt;Carlo Tomasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01262">
<title>Minimax Optimization: The Case of Convex-Submodular. (arXiv:2111.01262v1 [math.OC])</title>
<link>http://arxiv.org/abs/2111.01262</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimax optimization has been central in addressing various applications in
machine learning, game theory, and control theory. Prior literature has thus
far mainly focused on studying such problems in the continuous domain, e.g.,
convex-concave minimax optimization is now understood to a significant extent.
Nevertheless, minimax problems extend far beyond the continuous domain to mixed
continuous-discrete domains or even fully discrete domains. In this paper, we
study mixed continuous-discrete minimax problems where the minimization is over
a continuous variable belonging to Euclidean space and the maximization is over
subsets of a given ground set. We introduce the class of convex-submodular
minimax problems, where the objective is convex with respect to the continuous
variable and submodular with respect to the discrete variable. Even though such
problems appear frequently in machine learning applications, little is known
about how to address them from algorithmic and theoretical perspectives. For
such problems, we first show that obtaining saddle points are hard up to any
approximation, and thus introduce new notions of (near-) optimality. We then
provide several algorithmic procedures for solving convex and
monotone-submodular minimax problems and characterize their convergence rates,
computational complexity, and quality of the final solution according to our
notions of optimally. Our proposed algorithms are iterative and combine tools
from both discrete and continuous optimization. Finally, we provide numerical
experiments to showcase the effectiveness of our purposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Adibi_A/0/1/0/all/0/1&quot;&gt;Arman Adibi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1&quot;&gt;Aryan Mokhtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01263">
<title>Optimized Passive Optical Networks with Cascaded-AWGRs for Data Centers. (arXiv:2111.01263v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2111.01263</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of Passive Optical Networks (PONs) in modern and future data centers
can provide energy efficiency, high capacity, low cost, scalability, and
elasticity. This paper introduces a passive optical network design with 2-tier
cascaded Arrayed Waveguide Grating Routers (AWGRs) to connect groups of racks
(i.e. cells) within a data center. This design employs a Software-Defined
Networking (SDN) controller to manage the routing and assignment of the
networking resource while introducing multiple paths between any two cells to
improve routing, load balancing and resilience. We provide benchmarking results
for the power consumption to compare the energy efficiency of this design to
state-of-the-art data centers. The results indicate that the cascaded AWGRs
architecture can achieve up to 43% saving in the networking power consumption
compared to Fat-Tree data center architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alharthi_M/0/1/0/all/0/1&quot;&gt;Mohammed Alharthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Sanaa H. Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosuf_B/0/1/0/all/0/1&quot;&gt;Barzan Yosuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Gorashi_T/0/1/0/all/0/1&quot;&gt;Taisir E. H. El-Gorashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmirghani_J/0/1/0/all/0/1&quot;&gt;Jaafar M. H. Elmirghani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01264">
<title>Human-Level Control without Server-Grade Hardware. (arXiv:2111.01264v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01264</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Q-Network (DQN) marked a major milestone for reinforcement learning,
demonstrating for the first time that human-level control policies could be
learned directly from raw visual inputs via reward maximization. Even years
after its introduction, DQN remains highly relevant to the research community
since many of its innovations have been adopted by successor methods.
Nevertheless, despite significant hardware advances in the interim, DQN&apos;s
original Atari 2600 experiments remain costly to replicate in full. This poses
an immense barrier to researchers who cannot afford state-of-the-art hardware
or lack access to large-scale cloud computing resources. To facilitate improved
access to deep reinforcement learning research, we introduce a DQN
implementation that leverages a novel concurrent and synchronized execution
framework designed to maximally utilize a heterogeneous CPU-GPU desktop system.
With just one NVIDIA GeForce GTX 1080 GPU, our implementation reduces the
training time of a 200-million-frame Atari experiment from 25 hours to just 9
hours. The ideas introduced in our paper should be generalizable to a large
number of off-policy deep reinforcement learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daley_B/0/1/0/all/0/1&quot;&gt;Brett Daley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Christopher Amato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01266">
<title>Quantifying Shareability in Transportation Networks: The Maximum Network Flow Overlap Problem. (arXiv:2111.01266v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/2111.01266</link>
<description rdf:parseType="Literal">&lt;p&gt;Cities across the world vary in terms of their urban forms, transportation
networks, and travel demand patterns with the variation affecting the viability
of different shared mobility modes ranging from mass transit to ridesharing.
This study proposes a modeling framework to quantify the shareability of person
flows in any city as a function of two inputs--the underlying transportation
(street) network and origin-destination (OD) travel demand in the network--as a
first step toward a deeper understanding of the joint influence of these
factors on the viability of shared mobility modes. This study conceptualizes
flow overlap to denote, for a person trip traversing a given path, the weighted
(by link distance) average number of other travelers sharing the links along
the person&apos;s path. The study extends this concept and formulates the Maximum
Network Flow Overlap Problem (MNFLOP) to assign all O-D person flows to the
network paths that maximize flow overlap in the region. The study also proposes
an MNFLOP variant with a second objective function term, OD flow detours, to
capture the trade-off between minimizing travel distance/time and increasing
shareability. The study utilizes the MNFLOP output to calculate measures of
shareability at various levels of aggregation, including, single location,
single and multiple ODs, individual links, and network level. The study applies
the MNFLOP to networks in Sioux Falls and Chicago. Results show that with minor
increases in traveler detour, it is possible to significantly increase flow
overlap relative to assigning all OD flows to their shortest paths. Origin
level measures of flow overlap indicate potential to share trips even from
locations with low demand, as long as the trips can be concentrated onto a few
paths, showing that critical demand assessment for operating shared mobility
modes is guided by both magnitude and directionality of demand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+JS_N/0/1/0/all/0/1&quot;&gt;Navjyoth Sarma JS&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hyland_M/0/1/0/all/0/1&quot;&gt;Michael F Hyland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01270">
<title>Deep learning of multi-resolution X-Ray micro-CT images for multi-scale modelling. (arXiv:2111.01270v1 [physics.geo-ph])</title>
<link>http://arxiv.org/abs/2111.01270</link>
<description rdf:parseType="Literal">&lt;p&gt;There are inherent field-of-view and resolution trade-offs in X-Ray
micro-computed tomography imaging, which limit the characterization, analysis
and model development of multi-scale porous systems. In this paper, we overcome
these tradeoffs by developing a 3D Enhanced Deep Super Resolution (EDSR)
convolutional neural network to create enhanced, high-resolution data over
large spatial scales from low-resolution data. Paired high-resolution (HR,
2$\mu$m) and low resolution (LR, 6$\mu$m) image data from a Bentheimer rock
sample are used to train the network. Unseen LR and HR data from the training
sample, and another sample with a distinct micro-structure, are used to
validate the network with various metrics: textual analysis, segmentation
behaviour and pore-network model (PNM) multiphase flow simulations. The
validated EDSR network is used to generate ~1000 high-resolution REV subvolume
images for each full core sample of length 6-7cm (total image sizes are
~6000x6000x32000 voxels). Each subvolume has distinct petrophysical properties
predicted from PNMs, which are combined to create a 3D continuum-scale model of
each sample. Drainage immiscible flow at low capillary number is simulated
across a range of fractional flows and compared directly to experimental
pressures and 3D saturations on a 1:1 basis. The EDSR generated model is more
accurate than the base LR model at predicting experimental behaviour in the
presence of heterogeneities, especially in flow regimes where a wide
distribution of pore-sizes are encountered. The models are generally accurate
at predicting saturations to within the experimental repeatability and relative
permeability across three orders of magnitude. The demonstrated workflow is a
fully predictive, without calibration, and opens up the possibility to image,
simulate and analyse flow in truly multi-scale heterogeneous systems that are
otherwise intractable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jackson_S/0/1/0/all/0/1&quot;&gt;Samuel J. Jackson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Niu_Y/0/1/0/all/0/1&quot;&gt;Yufu Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Manoorkar_S/0/1/0/all/0/1&quot;&gt;Sojwal Manoorkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mostaghimi_P/0/1/0/all/0/1&quot;&gt;Peyman Mostaghimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Armstrong_R/0/1/0/all/0/1&quot;&gt;Ryan T. Armstrong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01271">
<title>Brain dynamics via Cumulative Auto-Regressive Self-Attention. (arXiv:2111.01271v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01271</link>
<description rdf:parseType="Literal">&lt;p&gt;Multivariate dynamical processes can often be intuitively described by a
weighted connectivity graph between components representing each individual
time-series. Even a simple representation of this graph as a Pearson
correlation matrix may be informative and predictive as demonstrated in the
brain imaging literature. However, there is a consensus expectation that
powerful graph neural networks (GNNs) should perform better in similar
settings. In this work, we present a model that is considerably shallow than
deep GNNs, yet outperforms them in predictive accuracy in a brain imaging
application. Our model learns the autoregressive structure of individual time
series and estimates directed connectivity graphs between the learned
representations via a self-attention mechanism in an end-to-end fashion. The
supervised training of the model as a classifier between patients and controls
results in a model that generates directed connectivity graphs and highlights
the components of the time-series that are predictive for each subject. We
demonstrate our results on a functional neuroimaging dataset classifying
schizophrenia patients and controls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_U/0/1/0/all/0/1&quot;&gt;Usman Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zening Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1&quot;&gt;Vince Calhoun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1&quot;&gt;Sergey Plis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01272">
<title>Sequence Transduction with Graph-based Supervision. (arXiv:2111.01272v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01272</link>
<description rdf:parseType="Literal">&lt;p&gt;The recurrent neural network transducer (RNN-T) objective plays a major role
in building today&apos;s best automatic speech recognition (ASR) systems for
production. Similarly to the connectionist temporal classification (CTC)
objective, the RNN-T loss uses specific rules that define how a set of
alignments is generated to form a lattice for the full-sum training. However,
it is yet largely unknown if these rules are optimal and do lead to the best
possible ASR results. In this work, we present a new transducer objective
function that generalizes the RNN-T loss to accept a graph representation of
the labels, thus providing a flexible and efficient framework to manipulate
training lattices, for example for restricting alignments or studying different
transition rules. We demonstrate that transducer-based ASR with CTC-like
lattice achieves better results compared to standard RNN-T, while also ensuring
a strictly monotonic alignment, which will allow better optimization of the
decoding procedure. For example, the proposed CTC-like transducer system
achieves a word error rate of 5.9% for the test-other condition of LibriSpeech,
corresponding to an improvement of 4.8% relative to an equivalent RNN-T based
system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moritz_N/0/1/0/all/0/1&quot;&gt;Niko Moritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hori_T/0/1/0/all/0/1&quot;&gt;Takaaki Hori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1&quot;&gt;Shinji Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1&quot;&gt;Jonathan Le Roux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01273">
<title>Network Clustering for Latent State and Changepoint Detection. (arXiv:2111.01273v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01273</link>
<description rdf:parseType="Literal">&lt;p&gt;Network models provide a powerful and flexible framework for analyzing a wide
range of structured data sources. In many situations of interest, however,
multiple networks can be constructed to capture different aspects of an
underlying phenomenon or to capture changing behavior over time. In such
settings, it is often useful to cluster together related networks in attempt to
identify patterns of common structure. In this paper, we propose a convex
approach for the task of network clustering. Our approach uses a convex fusion
penalty to induce a smoothly-varying tree-like cluster structure, eliminating
the need to select the number of clusters a priori. We provide an efficient
algorithm for convex network clustering and demonstrate its effectiveness on
synthetic examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navarro_M/0/1/0/all/0/1&quot;&gt;Madeline Navarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_G/0/1/0/all/0/1&quot;&gt;Genevera I. Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weylandt_M/0/1/0/all/0/1&quot;&gt;Michael Weylandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01275">
<title>Recurrent neural network models for working memory of continuous variables: activity manifolds, connectivity patterns, and dynamic codes. (arXiv:2111.01275v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2111.01275</link>
<description rdf:parseType="Literal">&lt;p&gt;Many daily activities and psychophysical experiments involve keeping multiple
items in working memory. When items take continuous values (e.g., orientation,
contrast, length, loudness) they must be stored in a continuous structure of
appropriate dimensions. We investigate how this structure is represented in
neural circuits by training recurrent networks to report two previously shown
stimulus orientations. We find the activity manifold for the two orientations
resembles a Clifford torus. Although a Clifford and standard torus (the surface
of a donut) are topologically equivalent, they have important functional
differences. A Clifford torus treats the two orientations equally and keeps
them in orthogonal subspaces, as demanded by the task, whereas a standard torus
does not. We find and characterize the connectivity patterns that support the
Clifford torus. Moreover, in addition to attractors that store information via
persistent activity, our networks also use a dynamic code where units change
their tuning to prevent new sensory input from overwriting the previously
stored one. We argue that such dynamic codes are generally required whenever
multiple inputs enter a memory system via shared connections. Finally, we apply
our framework to a human psychophysics experiment in which subjects reported
two remembered orientations. By varying the training conditions of the RNNs, we
test and support the hypothesis that human behavior is a product of both neural
noise and reliance on the more stable and behaviorally relevant memory of the
ordinal relationship between the two orientations. This suggests that suitable
inductive biases in RNNs are important for uncovering how the human brain
implements working memory. Together, these results offer an understanding of
the neural computations underlying a class of visual decoding tasks, bridging
the scales from human behavior to synaptic connectivity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cueva_C/0/1/0/all/0/1&quot;&gt;Christopher J. Cueva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ardalan_A/0/1/0/all/0/1&quot;&gt;Adel Ardalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tsodyks_M/0/1/0/all/0/1&quot;&gt;Misha Tsodyks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Qian_N/0/1/0/all/0/1&quot;&gt;Ning Qian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01276">
<title>Multi network InfoMax: A pre-training method involving graph convolutional networks. (arXiv:2111.01276v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01276</link>
<description rdf:parseType="Literal">&lt;p&gt;Discovering distinct features and their relations from data can help us
uncover valuable knowledge crucial for various tasks, e.g., classification. In
neuroimaging, these features could help to understand, classify, and possibly
prevent brain disorders. Model introspection of highly performant
overparameterized deep learning (DL) models could help find these features and
relations. However, to achieve high-performance level DL models require
numerous labeled training samples ($n$) rarely available in many fields. This
paper presents a pre-training method involving graph convolutional/neural
networks (GCNs/GNNs), based on maximizing mutual information between two
high-level embeddings of an input sample. Many of the recently proposed
pre-training methods pre-train one of many possible networks of an
architecture. Since almost every DL model is an ensemble of multiple networks,
we take our high-level embeddings from two different networks of a model --a
convolutional and a graph network--. The learned high-level graph latent
representations help increase performance for downstream graph classification
tasks and bypass the need for a high number of labeled data samples. We apply
our method to a neuroimaging dataset for classifying subjects into healthy
control (HC) and schizophrenia (SZ) groups. Our experiments show that the
pre-trained model significantly outperforms the non-pre-trained model and
requires $50\%$ less data for similar performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_U/0/1/0/all/0/1&quot;&gt;Usman Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zening Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1&quot;&gt;Vince Calhoun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1&quot;&gt;Sergey Plis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01294">
<title>Learning to Operate an Electric Vehicle Charging Station Considering Vehicle-grid Integration. (arXiv:2111.01294v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01294</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid adoption of electric vehicles (EVs) calls for the widespread
installation of EV charging stations. To maximize the profitability of charging
stations, intelligent controllers that provide both charging and electric grid
services are in great need. However, it is challenging to determine the optimal
charging schedule due to the uncertain arrival time and charging demands of
EVs. In this paper, we propose a novel centralized allocation and decentralized
execution (CADE) reinforcement learning (RL) framework to maximize the charging
station&apos;s profit. In the centralized allocation process, EVs are allocated to
either the waiting or charging spots. In the decentralized execution process,
each charger makes its own charging/discharging decision while learning the
action-value functions from a shared replay memory. This CADE framework
significantly improves the scalability and sample efficiency of the RL
algorithm. Numerical results show that the proposed CADE framework is both
computationally efficient and scalable, and significantly outperforms the
baseline model predictive control (MPC). We also provide an in-depth analysis
of the learned action-value function to explain the inner working of the
reinforcement learning agent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zuzhao Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yuanqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1&quot;&gt;Nanpeng Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01297">
<title>Deep neural networks as nested dynamical systems. (arXiv:2111.01297v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01297</link>
<description rdf:parseType="Literal">&lt;p&gt;There is an analogy that is often made between deep neural networks and
actual brains, suggested by the nomenclature itself: the &quot;neurons&quot; in deep
neural networks should correspond to neurons (or nerve cells, to avoid
confusion) in the brain. We claim, however, that this analogy doesn&apos;t even type
check: it is structurally flawed. In agreement with the slightly glib summary
of Hebbian learning as &quot;cells that fire together wire together&quot;, this article
makes the case that the analogy should be different. Since the &quot;neurons&quot; in
deep neural networks are managing the changing weights, they are more akin to
the synapses in the brain; instead, it is the wires in deep neural networks
that are more like nerve cells, in that they are what cause the information to
flow. An intuition that nerve cells seem like more than mere wires is exactly
right, and is justified by a precise category-theoretic analogy which we will
explore in this article. Throughout, we will continue to highlight the error in
equating artificial neurons with nerve cells by leaving &quot;neuron&quot; in quotes or
by calling them artificial neurons.
&lt;/p&gt;
&lt;p&gt;We will first explain how to view deep neural networks as nested dynamical
systems with a very restricted sort of interaction pattern, and then explain a
more general sort of interaction for dynamical systems that is useful
throughout engineering, but which fails to adapt to changing circumstances. As
mentioned, an analogy is then forced upon us by the mathematical formalism in
which they are both embedded. We call the resulting encompassing generalization
deeply interacting learning systems: they have complex interaction as in
control theory, but adaptation to circumstances as in deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spivak_D/0/1/0/all/0/1&quot;&gt;David I. Spivak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosgood_T/0/1/0/all/0/1&quot;&gt;Timothy Hosgood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01300">
<title>Masking Modalities for Cross-modal Video Retrieval. (arXiv:2111.01300v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01300</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-training on large scale unlabelled datasets has shown impressive
performance improvements in the fields of computer vision and natural language
processing. Given the advent of large-scale instructional video datasets, a
common strategy for pre-training video encoders is to use the accompanying
speech as weak supervision. However, as speech is used to supervise the
pre-training, it is never seen by the video encoder, which does not learn to
process that modality. We address this drawback of current pre-training
methods, which fail to exploit the rich cues in spoken language. Our proposal
is to pre-train a video encoder using all the available video modalities as
supervision, namely, appearance, sound, and transcribed speech. We mask an
entire modality in the input and predict it using the other two modalities.
This encourages each modality to collaborate with the others, and our video
encoder learns to process appearance and audio as well as speech. We show the
superior performance of our &quot;modality masking&quot; pre-training approach for video
retrieval on the How2R, YouCook2 and Condensed Movies datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabeur_V/0/1/0/all/0/1&quot;&gt;Valentin Gabeur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagrani_A/0/1/0/all/0/1&quot;&gt;Arsha Nagrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Chen Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alahari_K/0/1/0/all/0/1&quot;&gt;Karteek Alahari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1&quot;&gt;Cordelia Schmid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01302">
<title>Differential Flatness and Flatness Inspired Control of Aerial Manipulators based on Lagrangian Reduction. (arXiv:2111.01302v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01302</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper shows that the dynamics of a general class of aerial manipulators,
consist of an underactuated multi-rotor base with an arbitrary k-linked
articulated manipulator, are differentially flat. Methods of Lagrangian
Reduction under broken symmetries produce reduced equations of motion whose key
variables: center-of-mass linear momentum, vehicle yaw angle, and manipulator
relative joint angles become the flat outputs. Utilizing flatness theory and a
second-order dynamic extension of the thrust input, we transform the mechanics
of aerial manipulators to their equivalent trivial form with a valid relative
degree. Using this flatness transformation, a quadratic programming-based
controller is proposed within a Control Lyapunov Function (CLF-QP) framework,
and its performance is verified in simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Skylar X. Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harderup_P/0/1/0/all/0/1&quot;&gt;Peder Harderup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burdick_J/0/1/0/all/0/1&quot;&gt;Joel Burdick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01306">
<title>On the Current and Emerging Challenges of Developing Fair and Ethical AI Solutions in Financial Services. (arXiv:2111.01306v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2111.01306</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) continues to find more numerous and more
critical applications in the financial services industry, giving rise to fair
and ethical AI as an industry-wide objective. While many ethical principles and
guidelines have been published in recent years, they fall short of addressing
the serious challenges that model developers face when building ethical AI
solutions. We survey the practical and overarching issues surrounding model
development, from design and implementation complexities, to the shortage of
tools, and the lack of organizational constructs. We show how practical
considerations reveal the gaps between high-level principles and concrete,
deployed AI applications, with the aim of starting industry-wide conversations
toward solution approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurshan_E/0/1/0/all/0/1&quot;&gt;Eren Kurshan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiahao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Storchan_V/0/1/0/all/0/1&quot;&gt;Victor Storchan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Hongda Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01312">
<title>DaDRA: A Python Library for Data-Driven Reachability Analysis. (arXiv:2111.01312v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01312</link>
<description rdf:parseType="Literal">&lt;p&gt;Reachability analysis is used to determine all possible states that a system
acting under uncertainty may reach. It is a critical component to obtain
guarantees of various safety-critical systems both for safety verification and
controller synthesis. Though traditional approaches to reachability analysis
provide formal guarantees of the reachable set, they involve complex algorithms
that require full system information, which is impractical for use in real
world settings. We present DaDRA, a Python library that allows for data-driven
reachability analysis with arbitrarily robust probabilistic guarantees. We
demonstrate the practical functionality of DaDRA on various systems including:
an analytically intractable chaotic system, benchmarks for systems with
nonlinear dynamics, and a realistic system acting under complex disturbance
signals and controlled with an intricate controller across multiple dimensions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mejia_J/0/1/0/all/0/1&quot;&gt;Jared Mejia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Devonport_A/0/1/0/all/0/1&quot;&gt;Alex Devonport&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Arcak_M/0/1/0/all/0/1&quot;&gt;Murat Arcak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01314">
<title>Explaining Documents&apos; Relevance to Search Queries. (arXiv:2111.01314v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2111.01314</link>
<description rdf:parseType="Literal">&lt;p&gt;We present GenEx, a generative model to explain search results to users
beyond just showing matches between query and document words. Adding GenEx
explanations to search results greatly impacts user satisfaction and search
performance. Search engines mostly provide document titles, URLs, and snippets
for each result. Existing model-agnostic explanation methods similarly focus on
word matching or content-based features. However, a recent user study shows
that word matching features are quite obvious to users and thus of slight
value. GenEx explains a search result by providing a terse description for the
query aspect covered by that result. We cast the task as a sequence
transduction problem and propose a novel model based on the Transformer
architecture. To represent documents with respect to the given queries and yet
not generate the queries themselves as explanations, two query-attention layers
and masked-query decoding are added to the Transformer architecture. The model
is trained without using any human-generated explanations. Training data are
instead automatically constructed to ensure a tolerable noise level and a
generalizable learned model. Experimental evaluation shows that our explanation
models significantly outperform the baseline models. Evaluation through user
studies also demonstrates that our explanation model generates short yet useful
explanations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahimi_R/0/1/0/all/0/1&quot;&gt;Razieh Rahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Youngwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1&quot;&gt;Hamed Zamani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allan_J/0/1/0/all/0/1&quot;&gt;James Allan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01315">
<title>FC-based shock-dynamics solver with neural-network localized artificial-viscosity assignment. (arXiv:2111.01315v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01315</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a spectral scheme for the numerical solution of nonlinear
conservation laws in non-periodic domains under arbitrary boundary conditions.
The approach relies on the use of the Fourier Continuation (FC) method for
spectral representation of non-periodic functions in conjunction with smooth
localized artificial viscosity assignments produced by means of a
Shock-Detecting Neural Network (SDNN). Like previous shock capturing schemes
and artificial viscosity techniques, the combined FC-SDNN strategy effectively
controls spurious oscillations in the proximity of discontinuities. Thanks to
its use of a localized but smooth artificial viscosity term, whose support is
restricted to a vicinity of flow-discontinuity points, the algorithm enjoys
spectral accuracy and low dissipation away from flow discontinuities, and, in
such regions, it produces smooth numerical solutions -- as evidenced by an
essential absence of spurious oscillations in level set lines. The FC-SDNN
viscosity assignment, which does not require use of problem-dependent
algorithmic parameters, induces a significantly lower overall dissipation than
other methods, including the Fourier-spectral versions of the previous entropy
viscosity method. The character of the proposed algorithm is illustrated with a
variety of numerical results for the linear advection, Burgers and Euler
equations in one and two-dimensional non-periodic spatial domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bruno_O/0/1/0/all/0/1&quot;&gt;Oscar P. Bruno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hesthaven_J/0/1/0/all/0/1&quot;&gt;Jan S. Hesthaven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Leibovici_D/0/1/0/all/0/1&quot;&gt;Daniel V. Leibovici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01320">
<title>AVASpeech-SMAD: A Strongly Labelled Speech and Music Activity Detection Dataset with Label Co-Occurrence. (arXiv:2111.01320v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2111.01320</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a dataset, AVASpeech-SMAD, to assist speech and music activity
detection research. With frame-level music labels, the proposed dataset extends
the existing AVASpeech dataset, which originally consists of 45 hours of audio
and speech activity labels. To the best of our knowledge, the proposed
AVASpeech-SMAD is the first open-source dataset that features strong polyphonic
labels for both music and speech. The dataset was manually annotated and
verified via an iterative cross-checking process. A simple automatic
examination was also implemented to further improve the quality of the labels.
Evaluation results from two state-of-the-art SMAD systems are also provided as
a benchmark for future reference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hung_Y/0/1/0/all/0/1&quot;&gt;Yun-Ning Hung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Watcharasupat_K/0/1/0/all/0/1&quot;&gt;Karn N. Watcharasupat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chih-Wei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Orife_I/0/1/0/all/0/1&quot;&gt;Iroro Orife&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kelian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Seshadri_P/0/1/0/all/0/1&quot;&gt;Pavan Seshadri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Junyoung Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01321">
<title>A Network Science Perspective to Personalized Learning. (arXiv:2111.01321v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01321</link>
<description rdf:parseType="Literal">&lt;p&gt;The modern educational ecosystem is not one-size fits all. Scholars are
accustomed to personalization in their everyday life and expect the same from
education systems. Additionally, the COVID-19 pandemic placed us all in an
acute teaching and learning laboratory experimentation which now creates
expectations of self-paced learning and interactions with focused educational
materials. Consequently, we examine how learning objectives can be achieved
through a learning platform that offers content choices and multiple modalities
of engagement to support self-paced learning, and propose an approach to
personalized education based on network science. This framework brings the
attention to learning experiences, rather than teaching experiences, by
providing the learner engagement and content choices supported by a network of
knowledge, based on and driven by individual skills and goals. We conclude with
a discussion of a prototype of such a learning platform, called CHUNK Learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gera_R/0/1/0/all/0/1&quot;&gt;Ralucca Gera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1&quot;&gt;Akrati Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartolf_D/0/1/0/all/0/1&quot;&gt;D&amp;#x27;Marie Bartolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tick_S/0/1/0/all/0/1&quot;&gt;Simona Tick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01322">
<title>Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP. (arXiv:2111.01322v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01322</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning considers the problem of learning an efficient learning process
that can leverage its past experience to accurately solve new tasks. However,
the efficacy of meta-learning crucially depends on the distribution of tasks
available for training, and this is often assumed to be known a priori or
constructed from limited supervised datasets. In this work, we aim to provide
task distributions for meta-learning by considering self-supervised tasks
automatically proposed from unlabeled text, to enable large-scale meta-learning
in NLP. We design multiple distributions of self-supervised tasks by
considering important aspects of task diversity, difficulty, type, domain, and
curriculum, and investigate how they affect meta-learning performance. Our
analysis shows that all these factors meaningfully alter the task distribution,
some inducing significant improvements in downstream few-shot accuracy of the
meta-learned models. Empirically, results on 20 downstream tasks show
significant improvements in few-shot learning -- adding up to +4.2% absolute
accuracy (on average) to the previous unsupervised meta-learning method, and
perform comparably to supervised methods on the FewRel 2.0 benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_T/0/1/0/all/0/1&quot;&gt;Trapit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunasekaran_K/0/1/0/all/0/1&quot;&gt;Karthick Gunasekaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munkhdalai_T/0/1/0/all/0/1&quot;&gt;Tsendsuren Munkhdalai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1&quot;&gt;Andrew McCallum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01323">
<title>Exploring the Semi-supervised Video Object Segmentation Problem from a Cyclic Perspective. (arXiv:2111.01323v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01323</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern video object segmentation (VOS) algorithms have achieved remarkably
high performance in a sequential processing order, while most of currently
prevailing pipelines still show some obvious inadequacy like accumulative
error, unknown robustness or lack of proper interpretation tools. In this
paper, we place the semi-supervised video object segmentation problem into a
cyclic workflow and find the defects above can be collectively addressed via
the inherent cyclic property of semi-supervised VOS systems. Firstly, a cyclic
mechanism incorporated to the standard sequential flow can produce more
consistent representations for pixel-wise correspondance. Relying on the
accurate reference mask in the starting frame, we show that the error
propagation problem can be mitigated. Next, a simple gradient correction
module, which naturally extends the offline cyclic pipeline to an online
manner, can highlight the high-frequent and detailed part of results to further
improve the segmentation quality while keeping feasible computation cost.
Meanwhile such correction can protect the network from severe performance
degration resulted from interference signals. Finally we develop cycle
effective receptive field (cycle-ERF) based on gradient correction process to
provide a new perspective into analyzing object-specific regions of interests.
We conduct comprehensive comparison and detailed analysis on challenging
benchmarks of DAVIS16, DAVIS17 and Youtube-VOS, demonstrating that the cyclic
mechanism is helpful to enhance segmentation quality, improve the robustness of
VOS systems, and further provide qualitative comparison and interpretation on
how different VOS algorithms work. The code of this project can be found at
https://github.com/lyxok1/STM-Training
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1&quot;&gt;John See&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Weiyao Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01325">
<title>Attribute-Based Deep Periocular Recognition: Leveraging Soft Biometrics to Improve Periocular Recognition. (arXiv:2111.01325v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01325</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, periocular recognition has been developed as a valuable
biometric identification approach, especially in wild environments (for
example, masked faces due to COVID-19 pandemic) where facial recognition may
not be applicable. This paper presents a new deep periocular recognition
framework called attribute-based deep periocular recognition (ADPR), which
predicts soft biometrics and incorporates the prediction into a periocular
recognition algorithm to determine identity from periocular images with high
accuracy. We propose an end-to-end framework, which uses several shared
convolutional neural network (CNN)layers (a common network) whose output feeds
two separate dedicated branches (modality dedicated layers); the first branch
classifies periocular images while the second branch predicts softn biometrics.
Next, the features from these two branches are fused together for a final
periocular recognition. The proposed method is different from existing methods
as it not only uses a shared CNN feature space to train these two tasks
jointly, but it also fuses predicted soft biometric features with the
periocular features in the training step to improve the overall periocular
recognition performance. Our proposed model is extensively evaluated using four
different publicly available datasets. Experimental results indicate that our
soft biometric based periocular recognition approach outperforms other
state-of-the-art methods for periocular recognition in wild environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talreja_V/0/1/0/all/0/1&quot;&gt;Veeru Talreja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1&quot;&gt;Nasser M. Nasrabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valenti_M/0/1/0/all/0/1&quot;&gt;Matthew C. Valenti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01326">
<title>Cross-lingual Transfer for Speech Processing using Acoustic Language Similarity. (arXiv:2111.01326v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2111.01326</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech processing systems currently do not support the vast majority of
languages, in part due to the lack of data in low-resource languages.
Cross-lingual transfer offers a compelling way to help bridge this digital
divide by incorporating high-resource data into low-resource systems. Current
cross-lingual algorithms have shown success in text-based tasks and
speech-related tasks over some low-resource languages. However, scaling up
speech systems to support hundreds of low-resource languages remains unsolved.
To help bridge this gap, we propose a language similarity approach that can
efficiently identify acoustic cross-lingual transfer pairs across hundreds of
languages. We demonstrate the effectiveness of our approach in language family
classification, speech recognition, and speech synthesis tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_P/0/1/0/all/0/1&quot;&gt;Peter Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiatong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yifan Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1&quot;&gt;Shinji Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Black_A/0/1/0/all/0/1&quot;&gt;Alan W Black&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01334">
<title>Measuring and utilizing temporal network dissimilarity. (arXiv:2111.01334v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01334</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantifying the structural and functional differences of temporal networks is
a fundamental and challenging problem in the era of big data. This work
proposes a temporal dissimilarity measure for temporal network comparison based
on the fastest arrival distance distribution and spectral entropy based
Jensen-Shannon divergence. Experimental results on both synthetic and empirical
temporal networks show that the proposed measure could discriminate diverse
temporal networks with different structures by capturing various topological
and temporal properties. Moreover, the proposed measure can discern the
functional distinctions and is found effective applications in temporal network
classification and spreadability discrimination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1&quot;&gt;Xiu-Xiu Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chuang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huijuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holme_P/0/1/0/all/0/1&quot;&gt;Petter Holme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zi-Ke Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01338">
<title>Federated Split Vision Transformer for COVID-19CXR Diagnosis using Task-Agnostic Training. (arXiv:2111.01338v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01338</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning, which shares the weights of the neural network across
clients, is gaining attention in the healthcare sector as it enables training
on a large corpus of decentralized data while maintaining data privacy. For
example, this enables neural network training for COVID-19 diagnosis on chest
X-ray (CXR) images without collecting patient CXR data across multiple
hospitals. Unfortunately, the exchange of the weights quickly consumes the
network bandwidth if highly expressive network architecture is employed.
So-called split learning partially solves this problem by dividing a neural
network into a client and a server part, so that the client part of the network
takes up less extensive computation resources and bandwidth. However, it is not
clear how to find the optimal split without sacrificing the overall network
performance. To amalgamate these methods and thereby maximize their distinct
strengths, here we show that the Vision Transformer, a recently developed deep
learning architecture with straightforward decomposable configuration, is
ideally suitable for split learning without sacrificing performance. Even under
the non-independent and identically distributed data distribution which
emulates a real collaboration between hospitals using CXR datasets from
multiple sources, the proposed framework was able to attain performance
comparable to data-centralized training. In addition, the proposed framework
along with heterogeneous multi-task clients also improves individual task
performances including the diagnosis of COVID-19, eliminating the need for
sharing large weights with innumerable parameters. Our results affirm the
suitability of Transformer for collaborative learning in medical imaging and
pave the way forward for future real-world implementations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangjoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gwanghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeongsol Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Boah Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01340">
<title>Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research for Language Understanding Tasks. (arXiv:2111.01340v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01340</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language understanding (NLU) has made massive progress driven by
large benchmarks, paired with research on transfer learning to broaden its
impact. Benchmarks are dominated by a small set of frequent phenomena, leaving
a long tail of infrequent phenomena underrepresented. In this work, we reflect
on the question: have transfer learning methods sufficiently addressed
performance of benchmark-trained models on the long tail? Since benchmarks do
not list included/excluded phenomena, we conceptualize the long tail using
macro-level dimensions such as underrepresented genres, topics, etc. We assess
trends in transfer learning research through a qualitative meta-analysis of 100
representative papers on transfer learning for NLU. Our analysis asks three
questions: (i) Which long tail dimensions do transfer learning studies target?
(ii) Which properties help adaptation methods improve performance on the long
tail? (iii) Which methodological gaps have greatest negative impact on long
tail performance? Our answers to these questions highlight major avenues for
future research in transfer learning for the long tail. Lastly, we present a
case study comparing the performance of various adaptation methods on clinical
narratives to show how systematically conducted meta-experiments can provide
insights that enable us to make progress along these future avenues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naik_A/0/1/0/all/0/1&quot;&gt;Aakanksha Naik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Jill Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rose_C/0/1/0/all/0/1&quot;&gt;Carolyn Rose&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01341">
<title>Lipschitz widths. (arXiv:2111.01341v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01341</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a measure, called Lipschitz widths, of the optimal
performance possible of certain nonlinear methods of approximation. It
discusses their relation to entropy numbers and other well known widths such as
the Kolmogorov and the stable manifold widths. It also shows that the Lipschitz
widths provide a theoretical benchmark for the approximation quality achieved
via deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Petrova_G/0/1/0/all/0/1&quot;&gt;Guergana Petrova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wojtaszczyk_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Wojtaszczyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01342">
<title>Attention-Guided Generative Adversarial Network for Whisper to Normal Speech Conversion. (arXiv:2111.01342v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2111.01342</link>
<description rdf:parseType="Literal">&lt;p&gt;Whispered speech is a special way of pronunciation without using vocal cord
vibration. A whispered speech does not contain a fundamental frequency, and its
energy is about 20dB lower than that of a normal speech. Converting a whispered
speech into a normal speech can improve speech quality and intelligibility. In
this paper, a novel attention-guided generative adversarial network model
incorporating an autoencoder, a Siamese neural network, and an identity mapping
loss function for whisper to normal speech conversion (AGAN-W2SC) is proposed.
The proposed method avoids the challenge of estimating the fundamental
frequency of the normal voiced speech converted from a whispered speech.
Specifically, the proposed model is more amendable to practical applications
because it does not need to align speech features for training. Experimental
results demonstrate that the proposed AGAN-W2SC can obtain improved speech
quality and intelligibility compared with dynamic-time-warping-based methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Teng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huabin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1&quot;&gt;Liang Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwan_H/0/1/0/all/0/1&quot;&gt;Hon Keung Kwan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01348">
<title>Faster Convex Lipschitz Regression via 2-block ADMM. (arXiv:2111.01348v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01348</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of approximating an arbitrary convex function arises in several
learning problems such as convex regression, learning with a difference of
convex (DC) functions, and approximating Bregman divergences. In this paper, we
show how a broad class of convex function learning problems can be solved via a
2-block ADMM approach, where updates for each block can be computed in closed
form. For the task of convex Lipschitz regression, we establish that our
proposed algorithm converges at the rate of $O(n^3 d^{1.5}+n^2 d^{2.5}+n d^3)$
for a dataset $X \in R^{n\times d}$. This new rate improves the state of the
art $O(n^5d^2$) available by interior point methods if $d = o( n^4)$. Further
we provide similar solvers for DC regression and Bregman divergence learning.
Unlike previous approaches, our method is amenable to the use of GPUs. We
demonstrate on regression and metric learning experiments that our approach is
up to 20 times faster than the existing method, and produces results that are
comparable to state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siahkamari_A/0/1/0/all/0/1&quot;&gt;Ali Siahkamari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Acar_D/0/1/0/all/0/1&quot;&gt;Durmus Alp Emre Acar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liao_C/0/1/0/all/0/1&quot;&gt;Christopher Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Geyer_K/0/1/0/all/0/1&quot;&gt;Kelly Geyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saligrama_V/0/1/0/all/0/1&quot;&gt;Venkatesh Saligrama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kulis_B/0/1/0/all/0/1&quot;&gt;Brian Kulis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01350">
<title>Constructing High-Order Signed Distance Maps from Computed Tomography Data with Application to Bone Morphometry. (arXiv:2111.01350v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01350</link>
<description rdf:parseType="Literal">&lt;p&gt;An algorithm is presented for constructing high-order signed distance fields
for two phase materials imaged with computed tomography. The signed distance
field is high-order in that it is free of the quantization artifact associated
with the distance transform of sampled signals. The narrowband is solved using
a closest point algorithm extended for implicit embeddings that are not a
signed distance field. The high-order fast sweeping algorithm is used to extend
the narrowband to the remainder of the domain. The order of accuracy of the
narrowband and extension methods are verified on ideal implicit surfaces. The
method is applied to ten excised cubes of bovine trabecular bone. Localization
of the surface, estimation of phase densities, and local morphometry is
validated with these subjects. Since the embedding is high-order, gradients and
thus curvatures can be accurately estimated locally in the image data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Besler_B/0/1/0/all/0/1&quot;&gt;Bryce A. Besler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kemp_T/0/1/0/all/0/1&quot;&gt;Tannis D. Kemp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Forkert_N/0/1/0/all/0/1&quot;&gt;Nils D. Forkert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Boyd_S/0/1/0/all/0/1&quot;&gt;Steven K. Boyd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01351">
<title>Major Depressive Disorder Recognition and Cognitive Analysis Based on Multi-layer Brain Functional Connectivity Networks. (arXiv:2111.01351v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2111.01351</link>
<description rdf:parseType="Literal">&lt;p&gt;On the increase of major depressive disorders (MDD), many researchers paid
attention to their recognition and treatment. Existing MDD recognition
algorithms always use a single time-frequency domain method method, but the
single time-frequency domain method is too simple and is not conducive to
simulating the complex link relationship between brain functions. To solve this
problem, this paper proposes a recognition method based on multi-layer brain
functional connectivity networks (MBFCN) for major depressive disorder and
conducts cognitive analysis. Cognitive analysis based on the proposed MBFCN
finds that the Alpha-Beta1 frequency band is the key sub-band for recognizing
MDD. The connections between the right prefrontal lobe and the temporal lobe of
the extremely depressed disorders (EDD) are deficient in the brain functional
connectivity networks (BFCN) based on phase lag index (PLI). Furthermore,
potential biomarkers by the significance analysis of depression features and
PHQ-9 can be found.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiaofang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xiangwei Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yonghui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Lizhen Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Bin Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01353">
<title>Can Vision Transformers Perform Convolution?. (arXiv:2111.01353v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01353</link>
<description rdf:parseType="Literal">&lt;p&gt;Several recent studies have demonstrated that attention-based networks, such
as Vision Transformer (ViT), can outperform Convolutional Neural Networks
(CNNs) on several computer vision tasks without using convolutional layers.
This naturally leads to the following questions: Can a self-attention layer of
ViT express any convolution operation? In this work, we prove that a single ViT
layer with image patches as the input can perform any convolution operation
constructively, where the multi-head attention mechanism and the relative
positional encoding play essential roles. We further provide a lower bound on
the number of heads for Vision Transformers to express CNNs. Corresponding with
our analysis, experimental results show that the construction in our proof can
help inject convolutional bias into Transformers and significantly improve the
performance of ViT in low data regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shanda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiangning Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1&quot;&gt;Di He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01354">
<title>SmartKC: Smartphone-based Corneal Topographer for Keratoconus Detection. (arXiv:2111.01354v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2111.01354</link>
<description rdf:parseType="Literal">&lt;p&gt;Keratoconus is a severe eye disease affecting the cornea (the clear,
dome-shaped outer surface of the eye), causing it to become thin and develop a
conical bulge. The diagnosis of keratoconus requires sophisticated ophthalmic
devices which are non-portable and very expensive. This makes early detection
of keratoconus inaccessible to large populations in low- and middle-income
countries, making it a leading cause for partial/complete blindness among such
populations. We propose SmartKC, a low-cost, smartphone-based keratoconus
diagnosis system comprising of a 3D-printed placido&apos;s disc attachment, an LED
light strip, and an intelligent smartphone app to capture the reflection of the
placido rings on the cornea. An image processing pipeline analyzes the corneal
image and uses the smartphone&apos;s camera parameters, the placido rings&apos; 3D
location, the pixel location of the reflected placido rings and the setup&apos;s
working distance to construct the corneal surface, via the Arc-Step method and
Zernike polynomials based surface fitting. In a clinical study with 101
distinct eyes, we found that SmartKC achieves a sensitivity of 87.8% and a
specificity of 80.4%. Moreover, the quantitative curvature estimates (sim-K)
strongly correlate with a gold-standard medical device (Pearson correlation
coefficient =0.77). Our results indicate that SmartKC has the potential to be
used as a keratoconus screening tool under real-world medical settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gairola_S/0/1/0/all/0/1&quot;&gt;Siddhartha Gairola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohra_M/0/1/0/all/0/1&quot;&gt;Murtuza Bohra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaheer_N/0/1/0/all/0/1&quot;&gt;Nadeem Shaheer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaprakash_N/0/1/0/all/0/1&quot;&gt;Navya Jayaprakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_P/0/1/0/all/0/1&quot;&gt;Pallavi Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramaniam_A/0/1/0/all/0/1&quot;&gt;Anand Balasubramaniam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murali_K/0/1/0/all/0/1&quot;&gt;Kaushik Murali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwatra_N/0/1/0/all/0/1&quot;&gt;Nipun Kwatra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1&quot;&gt;Mohit Jain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01355">
<title>Real-time Forecasting of Dockless Scooter-Sharing Demand: A Context-Aware Spatio-Temporal Multi-Graph Convolutional Network Approach. (arXiv:2111.01355v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2111.01355</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time demand forecasting for shared micromobility can greatly enhance its
potential benefits and mitigate its adverse effects on urban mobility. The deep
learning models provide researchers powerful tools to deal with the real-time
dockless scooter-sharing demand prediction problem, but existing studies have
not fully incorporated the features that are highly associated with the demand,
such as weather conditions, demographic characteristics, and transportation
supply. This paper proposes a novel deep learning model named Context-Aware
Spatio-Temporal Multi-Graph Convolutional Network (CA-STMGCN) to forecast the
real-time spatiotemporal dockless scooter-sharing demand. The proposed model
applies a graph convolutional network (GCN) component that uses spatial
adjacency graph, functional similarity graph, demographic similarity graph, and
transportation supply similarity graph as input to extract spatial dependency
and attach it to historical demand data. Then, we use a gated recurrent unit
component to process the output of GCN and weather condition data to capture
temporal dependency. A fully connected neural network layer is used to generate
the final prediction. The proposed model is evaluated using the real-world
dockless scooter-sharing demand data in Washington, D.C. The results show that
CA-STMGCN significantly outperforms all the selected benchmark models, and the
most important model component is the weather information. The proposed model
can help the operators develop optimal vehicle rebalancing schemes and guide
cities to regulate the dockless scooter-sharing usage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paliwal_M/0/1/0/all/0/1&quot;&gt;Mudit Paliwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xilei Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01356">
<title>DeepParticle: learning invariant measure by a deep neural network minimizing Wasserstein distance on data generated from an interacting particle method. (arXiv:2111.01356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01356</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the so called DeepParticle method to learn and generate
invariant measures of stochastic dynamical systems with physical parameters
based on data computed from an interacting particle method (IPM). We utilize
the expressiveness of deep neural networks (DNNs) to represent the transform of
samples from a given input (source) distribution to an arbitrary target
distribution, neither assuming distribution functions in closed form nor a
finite state space for the samples. In training, we update the network weights
to minimize a discrete Wasserstein distance between the input and target
samples. To reduce computational cost, we propose an iterative
divide-and-conquer (a mini-batch interior point) algorithm, to find the optimal
transition matrix in the Wasserstein distance. We present numerical results to
demonstrate the performance of our method for accelerating IPM computation of
invariant measures of stochastic dynamical systems arising in computing
reaction-diffusion front speeds through chaotic flows. The physical parameter
is a large Pecl\&apos;et number reflecting the advection dominated regime of our
interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongjian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1&quot;&gt;Jack Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiwen Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01359">
<title>Unfoldings and Nets of Regular Polytopes. (arXiv:2111.01359v1 [cs.CG])</title>
<link>http://arxiv.org/abs/2111.01359</link>
<description rdf:parseType="Literal">&lt;p&gt;Over a decade ago, it was shown that every edge unfolding of the Platonic
solids was without self-overlap, yielding a valid net. We consider this
property for regular polytopes in arbitrary dimensions, notably the simplex,
cube, and orthoplex. It was recently proven that all unfoldings of the $n$-cube
yield nets. We show this is also true for the $n$-simplex and the $4$-orthoplex
but demonstrate its surprising failure for any orthoplex of higher dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devadoss_S/0/1/0/all/0/1&quot;&gt;Satyan L. Devadoss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harvey_M/0/1/0/all/0/1&quot;&gt;Matthew Harvey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01361">
<title>Outlier-Robust Optimal Transport: Duality, Structure, and Statistical Applications. (arXiv:2111.01361v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01361</link>
<description rdf:parseType="Literal">&lt;p&gt;The Wasserstein distance, rooted in optimal transport (OT) theory, is a
popular discrepancy measure between probability distributions with various
applications to statistics and machine learning. Despite their rich structure
and demonstrated utility, Wasserstein distances are sensitive to outliers in
the considered distributions, which hinders applicability in practice. Inspired
by the Huber contamination model, we propose a new outlier-robust Wasserstein
distance $\mathsf{W}_p^\varepsilon$ which allows for $\varepsilon$ outlier mass
to be removed from each contaminated distribution. Our formulation amounts to a
highly regular optimization problem that lends itself better for analysis
compared to previously considered frameworks. Leveraging this, we conduct a
thorough theoretical study of $\mathsf{W}_p^\varepsilon$, encompassing
characterization of optimal perturbations, regularity, duality, and statistical
estimation and robustness results. In particular, by decoupling the
optimization variables, we arrive at a simple dual form for
$\mathsf{W}_p^\varepsilon$ that can be implemented via an elementary
modification to standard, duality-based OT solvers. We illustrate the benefits
of our framework via applications to generative modeling with contaminated
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nietert_S/0/1/0/all/0/1&quot;&gt;Sloan Nietert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cummings_R/0/1/0/all/0/1&quot;&gt;Rachel Cummings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldfeld_Z/0/1/0/all/0/1&quot;&gt;Ziv Goldfeld&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01363">
<title>Knowledge Cross-Distillation for Membership Privacy. (arXiv:2111.01363v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2111.01363</link>
<description rdf:parseType="Literal">&lt;p&gt;A membership inference attack (MIA) poses privacy risks on the training data
of a machine learning model. With an MIA, an attacker guesses if the target
data are a member of the training dataset. The state-of-the-art defense against
MIAs, distillation for membership privacy (DMP), requires not only private data
to protect but a large amount of unlabeled public data. However, in certain
privacy-sensitive domains, such as medical and financial, the availability of
public data is not obvious. Moreover, a trivial method to generate the public
data by using generative adversarial networks significantly decreases the model
accuracy, as reported by the authors of DMP. To overcome this problem, we
propose a novel defense against MIAs using knowledge distillation without
requiring public data. Our experiments show that the privacy protection and
accuracy of our defense are comparable with those of DMP for the benchmark
tabular datasets used in MIA researches, Purchase100 and Texas100, and our
defense has much better privacy-utility trade-off than those of the existing
defenses without using public data for image dataset CIFAR10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chourasia_R/0/1/0/all/0/1&quot;&gt;Rishav Chourasia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enkhtaivan_B/0/1/0/all/0/1&quot;&gt;Batnyam Enkhtaivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ito_K/0/1/0/all/0/1&quot;&gt;Kunihiro Ito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mori_J/0/1/0/all/0/1&quot;&gt;Junki Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teranishi_I/0/1/0/all/0/1&quot;&gt;Isamu Teranishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuchida_H/0/1/0/all/0/1&quot;&gt;Hikaru Tsuchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01364">
<title>Learning to Explore by Reinforcement over High-Level Options. (arXiv:2111.01364v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01364</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous 3D environment exploration is a fundamental task for various
applications such as navigation. The goal of exploration is to investigate a
new environment and build its occupancy map efficiently. In this paper, we
propose a new method which grants an agent two intertwined options of
behaviors: &quot;look-around&quot; and &quot;frontier navigation&quot;. This is implemented by an
option-critic architecture and trained by reinforcement learning algorithms. In
each timestep, an agent produces an option and a corresponding action according
to the policy. We also take advantage of macro-actions by incorporating classic
path-planning techniques to increase training efficiency. We demonstrate the
effectiveness of the proposed method on two publicly available 3D environment
datasets and the results show our method achieves higher coverage than
competing techniques with better efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juncheng_L/0/1/0/all/0/1&quot;&gt;Liu Juncheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brendan_M/0/1/0/all/0/1&quot;&gt;McCane Brendan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steven_M/0/1/0/all/0/1&quot;&gt;Mills Steven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01365">
<title>Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics. (arXiv:2111.01365v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01365</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline reinforcement learning leverages large datasets to train policies
without interactions with the environment. The learned policies may then be
deployed in real-world settings where interactions are costly or dangerous.
Current algorithms over-fit to the training dataset and as a consequence
perform poorly when deployed to out-of-distribution generalizations of the
environment. We aim to address these limitations by learning a Koopman latent
representation which allows us to infer symmetries of the system&apos;s underlying
dynamic. The latter is then utilized to extend the otherwise static offline
dataset during training; this constitutes a novel data augmentation framework
which reflects the system&apos;s dynamic and is thus to be interpreted as an
exploration of the environments phase space. To obtain the symmetries we employ
Koopman theory in which nonlinear dynamics are represented in terms of a linear
operator acting on the space of measurement functions of the system and thus
symmetries of the dynamics may be inferred directly. We provide novel
theoretical results on the existence and nature of symmetries relevant for
control systems such as reinforcement learning settings. Moreover, we
empirically evaluate our method on several benchmark offline reinforcement
learning tasks and datasets including D4RL, Metaworld and Robosuite and find
that by using our framework we consistently improve the state-of-the-art for
Q-learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissenbacher_M/0/1/0/all/0/1&quot;&gt;Matthias Weissenbacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1&quot;&gt;Samarth Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1&quot;&gt;Animesh Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawahara_Y/0/1/0/all/0/1&quot;&gt;Yoshinobu Kawahara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01366">
<title>Improved Loss Function-Based Prediction Method of Extreme Temperatures in Greenhouses. (arXiv:2111.01366v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01366</link>
<description rdf:parseType="Literal">&lt;p&gt;The prediction of extreme greenhouse temperatures to which crops are
susceptible is essential in the field of greenhouse planting. It can help avoid
heat or freezing damage and economic losses. Therefore, it&apos;s important to
develop models that can predict them accurately. Due to the lack of extreme
temperature data in datasets, it is challenging for models to accurately
predict it. In this paper, we propose an improved loss function, which is
suitable for a variety of machine learning models. By increasing the weight of
extreme temperature samples and reducing the possibility of misjudging extreme
temperature as normal, the proposed loss function can enhance the prediction
results in extreme situations. To verify the effectiveness of the proposed
method, we implement the improved loss function in LightGBM, long short-term
memory, and artificial neural network and conduct experiments on a real-world
greenhouse dataset. The results show that the performance of models with the
improved loss function is enhanced compared to the original models in extreme
cases. The improved models can be used to guarantee the timely judgment of
extreme temperatures in agricultural greenhouses, thereby preventing
unnecessary losses caused by incorrect predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1&quot;&gt;Liao Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shuaiqi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yunsong Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01369">
<title>Wafer-level Variation Modeling for Multi-site RF IC Testing via Hierarchical Gaussian Process. (arXiv:2111.01369v1 [cs.AR])</title>
<link>http://arxiv.org/abs/2111.01369</link>
<description rdf:parseType="Literal">&lt;p&gt;Wafer-level performance prediction has been attracting attention to reduce
measurement costs without compromising test quality in production tests.
Although several efficient methods have been proposed, the site-to-site
variation, which is often observed in multi-site testing for radio frequency
circuits, has not yet been sufficiently addressed. In this paper, we propose a
wafer-level performance prediction method for multi-site testing that can
consider the site-to-site variation. The proposed method is based on the
Gaussian process, which is widely used for wafer-level spatial correlation
modeling, improving the prediction accuracy by extending hierarchical modeling
to exploit the test site information provided by test engineers. In addition,
we propose an active test-site sampling method to maximize measurement cost
reduction. Through experiments using industrial production test data, we
demonstrate that the proposed method can reduce the estimation error to 1/19 of
that obtained using a conventional method. Moreover, we demonstrate that the
proposed sampling method can reduce the number of the measurements by 97% while
achieving sufficient estimation accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shintani_M/0/1/0/all/0/1&quot;&gt;Michihiro Shintani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mian_R/0/1/0/all/0/1&quot;&gt;Riaz-Ul-Haque Mian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_T/0/1/0/all/0/1&quot;&gt;Tomoki Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kajiyama_M/0/1/0/all/0/1&quot;&gt;Masuo Kajiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eiki_M/0/1/0/all/0/1&quot;&gt;Makoto Eiki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inoue_M/0/1/0/all/0/1&quot;&gt;Michiko Inoue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01370">
<title>FedGraph: Federated Graph Learning with Intelligent Sampling. (arXiv:2111.01370v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01370</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning has attracted much research attention due to its privacy
protection in distributed machine learning. However, existing work of federated
learning mainly focuses on Convolutional Neural Network (CNN), which cannot
efficiently handle graph data that are popular in many applications. Graph
Convolutional Network (GCN) has been proposed as one of the most promising
techniques for graph learning, but its federated setting has been seldom
explored. In this paper, we propose FedGraph for federated graph learning among
multiple computing clients, each of which holds a subgraph. FedGraph provides
strong graph learning capability across clients by addressing two unique
challenges. First, traditional GCN training needs feature data sharing among
clients, leading to risk of privacy leakage. FedGraph solves this issue using a
novel cross-client convolution operation. The second challenge is high GCN
training overhead incurred by large graph size. We propose an intelligent graph
sampling algorithm based on deep reinforcement learning, which can
automatically converge to the optimal sampling policies that balance training
speed and accuracy. We implement FedGraph based on PyTorch and deploy it on a
testbed for performance evaluation. The experimental results of four popular
datasets demonstrate that FedGraph significantly outperforms existing work by
enabling faster convergence to higher accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Fahao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miyazaki_T/0/1/0/all/0/1&quot;&gt;Toshiaki Miyazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Celimuge Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01371">
<title>Envelope Imbalance Learning Algorithm based on Multilayer Fuzzy C-means Clustering and Minimum Interlayer discrepancy. (arXiv:2111.01371v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01371</link>
<description rdf:parseType="Literal">&lt;p&gt;Imbalanced learning is important and challenging since the problem of the
classification of imbalanced datasets is prevalent in machine learning and data
mining fields. Sampling approaches are proposed to address this issue, and
cluster-based oversampling methods have shown great potential as they aim to
simultaneously tackle between-class and within-class imbalance issues. However,
all existing clustering methods are based on a one-time approach. Due to the
lack of a priori knowledge, improper setting of the number of clusters often
exists, which leads to poor clustering performance. Besides, the existing
methods are likely to generate noisy instances. To solve these problems, this
paper proposes a deep instance envelope network-based imbalanced learning
algorithm with the multilayer fuzzy c-means (MlFCM) and a minimum interlayer
discrepancy mechanism based on the maximum mean discrepancy (MIDMD). This
algorithm can guarantee high quality balanced instances using a deep instance
envelope network in the absence of prior knowledge. In the experimental
section, thirty-three popular public datasets are used for verification, and
over ten representative algorithms are used for comparison. The experimental
results show that the proposed approach significantly outperforms other popular
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yongming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01374">
<title>A Game of Primes. (arXiv:2111.01374v1 [math.GM])</title>
<link>http://arxiv.org/abs/2111.01374</link>
<description rdf:parseType="Literal">&lt;p&gt;The basis for most of the ideas mentioned in this paper is the theory of
cellular automata. A cellular automata contains a regular grid of cells, with
each cell having a pre-defined set of finite states. The initial state is
determined at time/state zero. At this point all the cells are assigned their
respective starting states. The automata is defined by a set of simple rules
that decide the subsequent states of the cells. We aim to create a cellular
automata of prime numbers and come up with some axioms, theorems and
conjectures for the same.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bhat_R/0/1/0/all/0/1&quot;&gt;Raghavendra Bhat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01376">
<title>SEED: Series Elastic End Effectors in 6D for Visuotactile Tool Use. (arXiv:2111.01376v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01376</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the framework of Series Elastic End Effectors in 6D (SEED), which
combines a spatially compliant element with visuotactile sensing to grasp and
manipulate tools in the wild. Our framework generalizes the benefits of series
elasticity to 6-dof, while providing an abstraction of control using
visuotactile sensing. We propose an algorithm for relative pose estimation from
visuotactile sensing, and a spatial hybrid force-position controller capable of
achieving stable force interaction with the environment. We demonstrate the
effectiveness of our framework on tools that require regulation of spatial
forces. Video link: https://youtu.be/2-YuIfspDrk
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suh_H/0/1/0/all/0/1&quot;&gt;H.J. Terry Suh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuppuswamy_N/0/1/0/all/0/1&quot;&gt;Naveen Kuppuswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1&quot;&gt;Tao Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitiguy_P/0/1/0/all/0/1&quot;&gt;Paul Mitiguy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alspach_A/0/1/0/all/0/1&quot;&gt;Alex Alspach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1&quot;&gt;Russ Tedrake&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01378">
<title>Finding the KT partition of a weighted graph in near-linear time. (arXiv:2111.01378v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2111.01378</link>
<description rdf:parseType="Literal">&lt;p&gt;In a breakthrough work, Kawarabayashi and Thorup (J.~ACM&apos;19) gave a
near-linear time deterministic algorithm for minimum cut in a simple graph $G =
(V,E)$. A key component is finding the $(1+\varepsilon)$-KT partition of $G$,
the coarsest partition $\{P_1, \ldots, P_k\}$ of $V$ such that for every
non-trivial $(1+\varepsilon)$-near minimum cut with sides $\{S, \bar{S}\}$ it
holds that $P_i$ is contained in either $S$ or $\bar{S}$, for $i=1, \ldots, k$.
Here we give a near-linear time randomized algorithm to find the
$(1+\varepsilon)$-KT partition of a weighted graph. Our algorithm is quite
different from that of Kawarabayashi and Thorup and builds on Karger&apos;s
framework of tree-respecting cuts (J.~ACM&apos;00).
&lt;/p&gt;
&lt;p&gt;We describe applications of the algorithm. (i) The algorithm makes progress
towards a more efficient algorithm for constructing the polygon representation
of the set of near-minimum cuts in a graph. This is a generalization of the
cactus representation initially described by Bencz\&apos;ur (FOCS&apos;95). (ii) We
improve the time complexity of a recent quantum algorithm for minimum cut in a
simple graph in the adjacency list model from $\widetilde O(n^{3/2})$ to
$\widetilde O(\sqrt{mn})$. (iii) We describe a new type of randomized algorithm
for minimum cut in simple graphs with complexity $O(m + n \log^6 n)$. For
slightly dense graphs this matches the complexity of the current best $O(m + n
\log^2 n)$ algorithm which uses a different approach based on random
contractions.
&lt;/p&gt;
&lt;p&gt;The key technical contribution of our work is the following. Given a weighted
graph $G$ with $m$ edges and a spanning tree $T$, consider the graph $H$ whose
nodes are the edges of $T$, and where there is an edge between two nodes of $H$
iff the corresponding 2-respecting cut of $T$ is a non-trivial near-minimum cut
of $G$. We give a $O(m \log^4 n)$ time deterministic algorithm to compute a
spanning forest of $H$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apers_S/0/1/0/all/0/1&quot;&gt;Simon Apers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gawrychowski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Gawrychowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Troy Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01383">
<title>A Comparative Analysis of Machine Learning Algorithms for Intrusion Detection in Edge-Enabled IoT Networks. (arXiv:2111.01383v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2111.01383</link>
<description rdf:parseType="Literal">&lt;p&gt;A significant increase in the number of interconnected devices and data
communication through wireless networks has given rise to various threats,
risks and security concerns. Internet of Things (IoT) applications is deployed
in almost every field of daily life, including sensitive environments. The edge
computing paradigm has complemented IoT applications by moving the
computational processing near the data sources. Among various security models,
Machine Learning (ML) based intrusion detection is the most conceivable defense
mechanism to combat the anomalous behavior in edge-enabled IoT networks. The ML
algorithms are used to classify the network traffic into normal and malicious
attacks. Intrusion detection is one of the challenging issues in the area of
network security. The research community has proposed many intrusion detection
systems. However, the challenges involved in selecting suitable algorithm(s) to
provide security in edge-enabled IoT networks exist. In this paper, a
comparative analysis of conventional machine learning classification algorithms
has been performed to categorize the network traffic on NSL-KDD dataset using
Jupyter on Pycharm tool. It can be observed that Multi-Layer Perception (MLP)
has dependencies between input and output and relies more on network
configuration for intrusion detection. Therefore, MLP can be more appropriate
for edge-based IoT networks with a better training time of 1.2 seconds and
testing accuracy of 79%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevappa_P/0/1/0/all/0/1&quot;&gt;Poornima Mahadevappa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muzammal_S/0/1/0/all/0/1&quot;&gt;Syeda Mariam Muzammal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murugesan_R/0/1/0/all/0/1&quot;&gt;Raja Kumar Murugesan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01387">
<title>Understanding Entropic Regularization in GANs. (arXiv:2111.01387v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01387</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks are a popular method for learning
distributions from data by modeling the target distribution as a function of a
known distribution. The function, often referred to as the generator, is
optimized to minimize a chosen distance measure between the generated and
target distributions. One commonly used measure for this purpose is the
Wasserstein distance. However, Wasserstein distance is hard to compute and
optimize, and in practice entropic regularization techniques are used to
improve numerical convergence. The influence of regularization on the learned
solution, however, remains not well-understood. In this paper, we study how
several popular entropic regularizations of Wasserstein distance impact the
solution in a simple benchmark setting where the generator is linear and the
target distribution is high-dimensional Gaussian. We show that entropy
regularization promotes the solution sparsification, while replacing the
Wasserstein distance with the Sinkhorn divergence recovers the unregularized
solution. Both regularization techniques remove the curse of dimensionality
suffered by Wasserstein distance. We show that the optimal generator can be
learned to accuracy $\epsilon$ with $O(1/\epsilon^2)$ samples from the target
distribution. We thus conclude that these regularization techniques can improve
the quality of the generator learned from empirical data for a large class of
distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reshetova_D/0/1/0/all/0/1&quot;&gt;Daria Reshetova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yikun Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiugang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1&quot;&gt;Ayfer Ozgur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01391">
<title>Simulation of Parallel-Jaw Grasping using Incremental Potential Contact Models. (arXiv:2111.01391v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01391</link>
<description rdf:parseType="Literal">&lt;p&gt;Soft compliant jaw tips are almost universally used with parallel-jaw robot
grippers due to their ability to increase contact area and friction between the
jaws and the object to be manipulated. However, interactions between the
compliant surfaces and rigid objects are notoriously difficult to model. We
introduce IPC-GraspSim, a novel simulator using Incremental Potential Contact
(IPC) - a deformation model developed in 2020 for computer graphics - that
models both the dynamics and the deformation of compliant jaw tips during
grasping. IPC-GraspSim is evaluated using a set of 2,000 physical grasps across
16 adversarial objects where standard analytic models perform poorly. In
comparison to both analytic quasistatic contact models (soft point contact,
REACH, 6DFC) and dynamic grasp simulators (Isaac Gym with FleX backend),
results suggest that IPC-GraspSim more accurately models real-world grasps,
increasing F1 score by 9%. All data, code, videos, and supplementary material
are available at https://sites.google.com/berkeley.edu/ipcgraspsim.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1&quot;&gt;Chung Min Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danielczuk_M/0/1/0/all/0/1&quot;&gt;Michael Danielczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_I/0/1/0/all/0/1&quot;&gt;Isabella Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1&quot;&gt;Ken Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01392">
<title>Overlapping and nonoverlapping models. (arXiv:2111.01392v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01392</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a directed network with $K_{r}$ row communities and $K_{c}$ column
communities. Previous works found that modeling directed networks in which all
nodes have overlapping property requires $K_{r}=K_{c}$ for identifiability. In
this paper, we propose an overlapping and nonoverlapping model to study
directed networks in which row nodes have overlapping property while column
nodes do not. The proposed model is identifiable when $K_{r}\leq K_{c}$.
Meanwhile, we provide one identifiable model as extension of ONM to model
directed networks with variation in node degree. Two spectral algorithms with
theoretical guarantee on consistent estimations are designed to fit the models.
A small scale of numerical studies are used to illustrate the algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qing_H/0/1/0/all/0/1&quot;&gt;Huan Qing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01393">
<title>Time Series Comparisons in Deep Space Network. (arXiv:2111.01393v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01393</link>
<description rdf:parseType="Literal">&lt;p&gt;The Deep Space Network is NASA&apos;s international array of antennas that support
interplanetary spacecraft missions. A track is a block of multi-dimensional
time series from the beginning to end of DSN communication with the target
spacecraft, containing thousands of monitor data items lasting several hours at
a frequency of 0.2-1Hz. Monitor data on each track reports on the performance
of specific spacecraft operations and the DSN itself. DSN is receiving signals
from 32 spacecraft across the solar system. DSN has pressure to reduce costs
while maintaining the quality of support for DSN mission users. DSN Link
Control Operators need to simultaneously monitor multiple tracks and identify
anomalies in real time. DSN has seen that as the number of missions increases,
the data that needs to be processed increases over time. In this project, we
look at the last 8 years of data for analysis. Any anomaly in the track
indicates a problem with either the spacecraft, DSN equipment, or weather
conditions. DSN operators typically write Discrepancy Reports for further
analysis. It is recognized that it would be quite helpful to identify 10
similar historical tracks out of the huge database to quickly find and match
anomalies. This tool has three functions: (1) identification of the top 10
similar historical tracks, (2) detection of anomalies compared to the reference
normal track, and (3) comparison of statistical differences between two given
tracks. The requirements for these features were confirmed by survey responses
from 21 DSN operators and engineers. The preliminary machine learning model has
shown promising performance (AUC=0.92). We plan to increase the number of data
sets and perform additional testing to improve performance further before its
planned integration into the track visualizer interface to assist DSN field
operators and engineers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_K/0/1/0/all/0/1&quot;&gt;Kyongsik Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1&quot;&gt;Rishi Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rebbapragada_U/0/1/0/all/0/1&quot;&gt;Umaa Rebbapragada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01394">
<title>Solving Partial Differential Equations with Point Source Based on Physics-Informed Neural Networks. (arXiv:2111.01394v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01394</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep learning technology has been used to solve partial
differential equations (PDEs), among which the physics-informed neural networks
(PINNs) emerges to be a promising method for solving both forward and inverse
PDE problems. PDEs with a point source that is expressed as a Dirac delta
function in the governing equations are mathematical models of many physical
processes. However, they cannot be solved directly by conventional PINNs method
due to the singularity brought by the Dirac delta function. We propose a
universal solution to tackle this problem with three novel techniques. Firstly
the Dirac delta function is modeled as a continuous probability density
function to eliminate the singularity; secondly a lower bound constrained
uncertainty weighting algorithm is proposed to balance the PINNs losses between
point source area and other areas; and thirdly a multi-scale deep neural
network with periodic activation function is used to improve the accuracy and
convergence speed of the PINNs method. We evaluate the proposed method with
three representative PDEs, and the experimental results show that our method
outperforms existing deep learning-based methods with respect to the accuracy,
the efficiency and the versatility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongsheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1&quot;&gt;Beiji Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zidong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1&quot;&gt;Kang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_B/0/1/0/all/0/1&quot;&gt;Bingya Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Min Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1&quot;&gt;Haotian Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jing Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1&quot;&gt;Bei Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bin Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01395">
<title>Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds. (arXiv:2111.01395v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01395</link>
<description rdf:parseType="Literal">&lt;p&gt;Certified robustness is a desirable property for deep neural networks in
safety-critical applications, and popular training algorithms can certify
robustness of a neural network by computing a global bound on its Lipschitz
constant. However, such a bound is often loose: it tends to over-regularize the
neural network and degrade its natural accuracy. A tighter Lipschitz bound may
provide a better tradeoff between natural and certified accuracy, but is
generally hard to compute exactly due to non-convexity of the network. In this
work, we propose an efficient and trainable \emph{local} Lipschitz upper bound
by considering the interactions between activation functions (e.g. ReLU) and
weight matrices. Specifically, when computing the induced norm of a weight
matrix, we eliminate the corresponding rows and columns where the activation
function is guaranteed to be a constant in the neighborhood of each given data
point, which provides a provably tighter bound than the global Lipschitz
constant of the neural network. Our method can be used as a plug-in module to
tighten the Lipschitz bound in many certifiable training algorithms.
Furthermore, we propose to clip activation functions (e.g., ReLU and MaxMin)
with a learnable upper threshold and a sparsity loss to assist the network to
achieve an even tighter local Lipschitz bound. Experimentally, we show that our
method consistently outperforms state-of-the-art methods in both clean and
certified accuracy on MNIST, CIFAR-10 and TinyImageNet datasets with various
network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yujia Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J Zico Kolter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01396">
<title>Boundary Distribution Estimation to Precise Object Detection. (arXiv:2111.01396v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01396</link>
<description rdf:parseType="Literal">&lt;p&gt;In principal modern detectors, the task of object localization is implemented
by the box subnet which concentrates on bounding box regression. The box subnet
customarily predicts the position of the object by regressing box center
position and scaling factors. Although this approach is frequently adopted, we
observe that the result of localization remains defective, which makes the
performance of the detector unsatisfactory. In this paper, we prove the flaws
in the previous method through theoretical analysis and experimental
verification and propose a novel solution to detect objects precisely. Rather
than plainly focusing on center and size, our approach refines the edges of the
bounding box on previous localization results by estimating the distribution at
the boundary of the object. Experimental results have shown the potentiality
and generalization of our proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Haoran Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Rui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qingguo Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01398">
<title>Integrating Pretrained Language Model for Dialogue Policy Learning. (arXiv:2111.01398v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01398</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL) has been witnessed its potential for training a
dialogue policy agent towards maximizing the accumulated rewards given from
users. However, the reward can be very sparse for it is usually only provided
at the end of a dialog session, which causes unaffordable interaction
requirements for an acceptable dialog agent. Distinguished from many efforts
dedicated to optimizing the policy and recovering the reward alternatively
which suffers from easily getting stuck in local optima and model collapse, we
decompose the adversarial training into two steps: 1) we integrate a
pre-trained language model as a discriminator to judge whether the current
system action is good enough for the last user action (i.e., \textit{next
action prediction}); 2) the discriminator gives and extra local dense reward to
guide the agent&apos;s exploration. The experimental result demonstrates that our
method significantly improves the complete rate (~4.4\%) and success rate
(~8.0\%) of the dialogue system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongru Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huimin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zezhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;Kam-Fai Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01400">
<title>Cognitive Load and Productivity Implications in Human-Chatbot Interaction. (arXiv:2111.01400v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2111.01400</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing progress in artificial intelligence and respective machine
learning technology has fostered the proliferation of chatbots to the point
where today they are being embedded into various human-technology interaction
tasks. In enterprise contexts, the use of chatbots seeks to reduce labor costs
and consequently increase productivity. For simple, repetitive customer service
tasks such already proves beneficial, yet more complex collaborative knowledge
work seems to require a better understanding of how the technology may best be
integrated. Particularly, the additional mental burden which accompanies the
use of these natural language based artificial assistants, often remains
overlooked. To this end, cognitive load theory implies that unnecessary use of
technology can induce additional extrinsic load and thus may have a contrary
effect on users&apos; productivity. The research presented in this paper thus
reports on a study assessing cognitive load and productivity implications of
human chatbot interaction in a realistic enterprise setting. A/B testing
software-only vs. software + chatbot interaction, and the NASA TLX were used to
evaluate and compare the cognitive load of two user groups. Results show that
chatbot users experienced less cognitive load and were more productive than
software-only users. Furthermore, they show lower frustration levels and better
overall performance (i.e, task quality) despite their slightly longer average
task completion time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;Johanna Schmidhuber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlogl_S/0/1/0/all/0/1&quot;&gt;Stephan Schl&amp;#xf6;gl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ploder_C/0/1/0/all/0/1&quot;&gt;Christian Ploder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01404">
<title>Cascadable all-optical NAND gates using diffractive networks. (arXiv:2111.01404v1 [physics.optics])</title>
<link>http://arxiv.org/abs/2111.01404</link>
<description rdf:parseType="Literal">&lt;p&gt;Owing to its potential advantages such as scalability, low latency and power
efficiency, optical computing has seen rapid advances over the last decades. A
core unit of a potential all-optical processor would be the NAND gate, which
can be cascaded to perform an arbitrary logical operation. Here, we present the
design and analysis of cascadable all-optical NAND gates using diffractive
neural networks. We encoded the logical values at the input and output planes
of a diffractive NAND gate using the relative optical power of two
spatially-separated apertures. Based on this architecture, we numerically
optimized the design of a diffractive neural network composed of 4 passive
layers to all-optically perform NAND operation using the diffraction of light,
and cascaded these diffractive NAND gates to perform complex logical functions
by successively feeding the output of one diffractive NAND gate into another.
We demonstrated the cascadability of our diffractive NAND gates by using
identical diffractive designs to all-optically perform AND and OR operations,
as well as a half-adder. Cascadable all-optical NAND gates composed of
spatially-engineered passive diffractive layers can serve as a core component
of various optical computing platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yi Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mengu_D/0/1/0/all/0/1&quot;&gt;Deniz Mengu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ozcan_A/0/1/0/all/0/1&quot;&gt;Aydogan Ozcan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01406">
<title>Dazed and Confused: What&apos;s Wrong with Crypto Libraries?. (arXiv:2111.01406v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2111.01406</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have shown that developers have difficulties in using
cryptographic APIs, which often led to security flaws. We are interested to
tackle this matter by looking into what types of problems exist in various
crypto libraries. We manually studied 500 posts on Stack Overflow associated
with 20 popular crypto libraries. We realized there are 10 themes in the
discussions. Interestingly, there were only two questions related to attacks
against cryptography. There were 63 discussions in which developers had
interoperability issues when working with more than a crypto library. The
majority of posts (i.e. 112) were about encryption/decryption problems and 111
were about installation/compilation issues of crypto libraries. Overall, we
realize that the crypto libraries are frequently involved in more than five
themes of discussions. We believe the current initial findings can help team
leaders and experienced developers to correctly guide the team members in the
domain of cryptography. Moreover, future research should investigate the
similarity of problems at the API level among popular crypto libraries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazhirpasand_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Hazhirpasand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nierstrasz_O/0/1/0/all/0/1&quot;&gt;Oscar Nierstrasz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghafari_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghafari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01409">
<title>Efficient Learning of the Parameters of Non-Linear Models using Differentiable Resampling in Particle Filters. (arXiv:2111.01409v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01409</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been widely documented that the sampling and resampling steps in
particle filters cannot be differentiated. The {\itshape reparameterisation
trick} was introduced to allow the sampling step to be reformulated into a
differentiable function. We extend the {\itshape reparameterisation trick} to
include the stochastic input to resampling therefore limiting the
discontinuities in the gradient calculation after this step. Knowing the
gradients of the prior and likelihood allows us to run particle Markov Chain
Monte Carlo (p-MCMC) and use the No-U-Turn Sampler (NUTS) as the proposal when
estimating parameters.
&lt;/p&gt;
&lt;p&gt;We compare the Metropolis-adjusted Langevin algorithm (MALA), Hamiltonian
Monte Carlo with different number of steps and NUTS. We consider two
state-space models and show that NUTS improves the mixing of the Markov chain
and can produce more accurate results in less computational time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rosato_C/0/1/0/all/0/1&quot;&gt;Conor Rosato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Horridge_P/0/1/0/all/0/1&quot;&gt;Paul Horridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maskell_S/0/1/0/all/0/1&quot;&gt;Simon Maskell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01413">
<title>A Minmax Utilization Algorithm for Network Traffic Scheduling of Industrial Robots. (arXiv:2111.01413v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01413</link>
<description rdf:parseType="Literal">&lt;p&gt;Emerging 5G and beyond wireless industrial virtualized networks are expected
to support a significant number of robotic manipulators. Depending on the
processes involved, these industrial robots might result in significant volume
of multi-modal traffic that will need to traverse the network all the way to
the (public/private) edge cloud, where advanced processing, control and service
orchestration will be taking place. In this paper, we perform the traffic
engineering by capitalizing on the underlying pseudo-deterministic nature of
the repetitive processes of robotic manipulators in an industrial environment
and propose an integer linear programming (ILP) model to minimize the maximum
aggregate traffic in the network. The task sequence and time gap requirements
are also considered in the proposed model. To tackle the curse of
dimensionality in ILP, we provide a random search algorithm with quadratic time
complexity. Numerical investigations reveal that the proposed scheme can reduce
the peak data rate up to 53.4% compared with the nominal case where robotic
manipulators operate in an uncoordinated fashion, resulting in significant
improvement in the utilization of the underlying network resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yantong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friderikos_V/0/1/0/all/0/1&quot;&gt;Vasilis Friderikos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andraos_S/0/1/0/all/0/1&quot;&gt;Sebastian Andraos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01414">
<title>A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots. (arXiv:2111.01414v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01414</link>
<description rdf:parseType="Literal">&lt;p&gt;In spoken dialogue systems, we aim to deploy artificial intelligence to build
automated dialogue agents that can converse with humans. Dialogue systems are
increasingly being designed to move beyond just imitating conversation and also
improve from such interactions over time. In this survey, we present a broad
overview of methods developed to build dialogue systems over the years.
Different use cases for dialogue systems ranging from task-based systems to
open domain chatbots motivate and necessitate specific systems. Starting from
simple rule-based systems, research has progressed towards increasingly complex
architectures trained on a massive corpus of datasets, like deep learning
systems. Motivated with the intuition of resembling human dialogues, progress
has been made towards incorporating emotions into the natural language
generator, using reinforcement learning. While we see a trend of highly
marginal improvement on some metrics, we find that limited justification exists
for the metrics, and evaluation practices are not uniform. To conclude, we flag
these concerns and highlight possible research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patlan_A/0/1/0/all/0/1&quot;&gt;Atharv Singh Patlan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1&quot;&gt;Shiven Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korde_S/0/1/0/all/0/1&quot;&gt;Shubham Korde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01415">
<title>iCallee: Recovering Call Graphs for Binaries. (arXiv:2111.01415v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2111.01415</link>
<description rdf:parseType="Literal">&lt;p&gt;Recovering programs&apos; call graphs is crucial for inter-procedural analysis
tasks and applications based on them. The core challenge is recognizing targets
of indirect calls (i.e., indirect callees). It becomes more challenging if
target programs are in binary forms, due to information loss in binaries.
Existing indirect callee recognition solutions for binaries all have high false
positives and negatives, making call graphs inaccurate.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a new solution iCallee based on the Siamese Neural
Network, inspired by the advances in question-answering applications. The key
insight is that, neural networks can learn to answer whether a callee function
is a potential target of an indirect callsite by comprehending their contexts,
i.e., instructions nearby callsites and of callees. Following this insight, we
first preprocess target binaries to extract contexts of callsites and callees.
Then, we build a customized Natural Language Processing (NLP) model applicable
to assembly language. Further, we collect abundant pairs of callsites and
callees, and embed their contexts with the NLP model, then train a Siamese
network and a classifier to answer the callsite-callee question. We have
implemented a prototype of iCallee and evaluated it on several groups of
targets. Evaluation results showed that, our solution could match callsites to
callees with an F1-Measure of 93.7%, recall of 93.8%, and precision of 93.5%,
much better than state-of-the-art solutions. To show its usefulness, we apply
iCallee to two specific applications - binary code similarity detection and
binary program hardening, and found that it could greatly improve
state-of-the-art solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wenyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhiyao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zihan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_Z/0/1/0/all/0/1&quot;&gt;Zhijian Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01418">
<title>A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic Segmentation. (arXiv:2111.01418v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01418</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot semantic segmentation addresses the learning task in which only few
images with ground truth pixel-level labels are available for the novel classes
of interest. One is typically required to collect a large mount of data (i.e.,
base classes) with such ground truth information, followed by meta-learning
strategies to address the above learning task. When only image-level semantic
labels can be observed during both training and testing, it is considered as an
even more challenging task of weakly supervised few-shot semantic segmentation.
To address this problem, we propose a novel meta-learning framework, which
predicts pseudo pixel-level segmentation masks from a limited amount of data
and their semantic labels. More importantly, our learning scheme further
exploits the produced pixel-level information for query image inputs with
segmentation guarantees. Thus, our proposed learning model can be viewed as a
pixel-level meta-learner. Through extensive experiments on benchmark datasets,
we show that our model achieves satisfactory performances under fully
supervised settings, yet performs favorably against state-of-the-art methods
under weakly supervised settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yuan-Hao Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fu-En Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Chiang Frank Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01419">
<title>The Multiplicative Compound of a Matrix Pencil with Applications to Difference-Algebraic Equations. (arXiv:2111.01419v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01419</link>
<description rdf:parseType="Literal">&lt;p&gt;The multiplicative and additive compounds of a matrix have important
applications in geometry, linear algebra, and dynamical systems described by
difference equations and by ordinary differential equations. Here, we introduce
a generalization of the multiplicative compound to matrix pencils. We analyze
the properties of this new compound and describe several applications to the
analysis of discrete-time dynamical systems described by difference-algebraic
equations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ofir_R/0/1/0/all/0/1&quot;&gt;Ron Ofir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Margaliot_M/0/1/0/all/0/1&quot;&gt;Michael Margaliot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01421">
<title>The Security Risk of Lacking Compiler Protection in WebAssembly. (arXiv:2111.01421v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2111.01421</link>
<description rdf:parseType="Literal">&lt;p&gt;WebAssembly is increasingly used as the compilation target for cross-platform
applications. In this paper, we investigate whether one can rely on the
security measures enforced by existing C compilers when compiling C programs to
WebAssembly. We compiled 4,469 C programs with known buffer overflow
vulnerabilities to x86 code and to WebAssembly, and observed the outcome of the
execution of the generated code to differ for 1,088 programs. Through manual
inspection, we identified that the root cause for these is the lack of security
measures such as stack canaries in the generated WebAssembly: while x86 code
crashes upon a stack-based buffer overflow, the corresponding WebAssembly
continues to be executed. We conclude that compiling an existing C program to
WebAssembly without additional precautions may hamper its security, and we
encourage more research in this direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stievenart_Q/0/1/0/all/0/1&quot;&gt;Quentin Sti&amp;#xe9;venart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roover_C/0/1/0/all/0/1&quot;&gt;Coen De Roover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghafari_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghafari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01422">
<title>Fast Algorithms for Hop-Constrained Flows and Moving Cuts. (arXiv:2111.01422v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2111.01422</link>
<description rdf:parseType="Literal">&lt;p&gt;Hop-constrained flows and their duals, moving cuts, are two fundamental
quantities in network optimization. Up to poly-logarithmic factors, they
characterize how quickly a network can accomplish numerous distributed
primitives. In this work, we give the first efficient algorithms for computing
$(1 \pm \epsilon) $-optimal $h$-hop-constrained flows and moving cuts with high
probability. Our algorithms take $\tilde{O}(m \cdot \text{poly}(h))$ sequential
time, $\tilde{O}(\text{poly}(h))$ parallel time and $\tilde{O}(\text{poly}(h))$
distributed CONGEST time. We use these algorithms to efficiently compute
hop-constrained cutmatches, an object at the heart of recent advances in
expander decompositions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1&quot;&gt;Bernhard Haeupler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hershkowitz_D/0/1/0/all/0/1&quot;&gt;D Ellis Hershkowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1&quot;&gt;Thatchaphol Saranurak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01425">
<title>Rational Agreement in the Presence of Crash Faults. (arXiv:2111.01425v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2111.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Blockchain systems need to solve consensus despite the presence of rational
users and failures. The notion of $(k,t)$-robustness has shown instrumental to
list problems that cannot be solved if $k$ players are rational and $t$ players
are Byzantine or act arbitrarily. What is less clear is whether one can solve
such problems if the faults are benign.
&lt;/p&gt;
&lt;p&gt;In this paper, we bridge the gap between games that are robust against
Byzantine players and games that are robust against crash players. Our first
result is an impossibility result:
&lt;/p&gt;
&lt;p&gt;We show that no $(k,t)$-robust consensus protocol can solve consensus in the
crash model if $k+2t\geq n$ unless there is a particular punishment strategy,
called the $(k,t)$-baiting strategy. This reveals the need to introduce baiting
as the act of rewarding a colluding node when betraying its coalition, to make
blockchains more secure.
&lt;/p&gt;
&lt;p&gt;Our second result is an equivalence relation between crash fault tolerant
games and Byzantine fault tolerant games, which raises an interesting research
question on the power of baiting to solve consensus. To this end, we show, on
the one hand, that a $(k,t)$-robust consensus protocol becomes $(k+t,t)$-robust
in the crash model. We show, on the other hand, that the existence of a
$(k,t)$-robust consensus protocol in the crash model that does not make use of
a baiting strategy implies the existence of a $(k-t,t)$-robust consensus
protocol in the Byzantine model, with the help of cryptography.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranchal_Pedrosa_A/0/1/0/all/0/1&quot;&gt;Alejandro Ranchal-Pedrosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gramoli_V/0/1/0/all/0/1&quot;&gt;Vincent Gramoli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01430">
<title>CycleGAN with Dual Adversarial Loss for Bone-Conducted Speech Enhancement. (arXiv:2111.01430v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2111.01430</link>
<description rdf:parseType="Literal">&lt;p&gt;Compared with air-conducted speech, bone-conducted speech has the unique
advantage of shielding background noise. Enhancement of bone-conducted speech
helps to improve its quality and intelligibility. In this paper, a novel
CycleGAN with dual adversarial loss (CycleGAN-DAL) is proposed for
bone-conducted speech enhancement. The proposed method uses an adversarial loss
and a cycle-consistent loss simultaneously to learn forward and cyclic mapping,
in which the adversarial loss is replaced with the classification adversarial
loss and the defect adversarial loss to consolidate the forward mapping.
Compared with conventional baseline methods, it can learn feature mapping
between bone-conducted speech and target speech without additional
air-conducted speech assistance. Moreover, the proposed method also avoids the
oversmooth problem which is occurred commonly in conventional statistical based
models. Experimental results show that the proposed method outperforms baseline
methods such as CycleGAN, GMM, and BLSTM. Keywords: Bone-conducted speech
enhancement, dual adversarial loss, Parallel CycleGAN, high frequency speech
reconstruction
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1&quot;&gt;Qing Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Teng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huabin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1&quot;&gt;Liang Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwan_H/0/1/0/all/0/1&quot;&gt;Hon Keung Kwan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01431">
<title>Graph Tree Deductive Networks. (arXiv:2111.01431v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01431</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce Graph Tree Deductive Networks, a network that
performs deductive reasoning. To have high-dimensional thinking, combining
various axioms and putting the results back into another axiom is necessary to
produce new relationships and results. For example, it would be given two
propositions: &quot;Socrates is a man.&quot; and &quot;All men are mortals.&quot; and two
propositions could be used to infer the new proposition, &quot;Therefore Socrates is
mortal.&quot;. To evaluate, we used MNIST Dataset, a handwritten numerical image
dataset, to apply it to the group theory and show the results of performing
deductive learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seokjun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1&quot;&gt;Jaeeun Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyeoncheol Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01432">
<title>Practical and Light-weight Secure Aggregation for Federated Submodel Learning. (arXiv:2111.01432v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01432</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Niu, et. al. introduced a new variant of Federated Learning (FL),
called Federated Submodel Learning (FSL). Different from traditional FL, each
client locally trains the submodel (e.g., retrieved from the servers) based on
its private data and uploads a submodel at its choice to the servers. Then all
clients aggregate all their submodels and finish the iteration. Inevitably, FSL
introduces two privacy-preserving computation tasks, i.e., Private Submodel
Retrieval (PSR) and Secure Submodel Aggregation (SSA). Existing work fails to
provide a loss-less scheme, or has impractical efficiency. In this work, we
leverage Distributed Point Function (DPF) and cuckoo hashing to construct a
practical and light-weight secure FSL scheme in the two-server setting. More
specifically, we propose two basic protocols with few optimisation techniques,
which ensures our protocol practicality on specific real-world FSL tasks. Our
experiments show that our proposed protocols can finish in less than 1 minute
when weight sizes $\leq 2^{15}$, we also demonstrate protocol efficiency by
comparing with existing work and by handling a real-world FSL task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jamie Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1&quot;&gt;Tiandi Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01436">
<title>Learning Size and Shape of Calabi-Yau Spaces. (arXiv:2111.01436v1 [hep-th])</title>
<link>http://arxiv.org/abs/2111.01436</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new machine learning library for computing metrics of string
compactification spaces. We benchmark the performance on Monte-Carlo sampled
integrals against previous numerical approximations and find that our neural
networks are more sample- and computation-efficient. We are the first to
provide the possibility to compute these metrics for arbitrary, user-specified
shape and size parameters of the compact space and observe a linear relation
between optimization of the partial differential equation we are training
against and vanishing Ricci curvature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Larfors_M/0/1/0/all/0/1&quot;&gt;Magdalena Larfors&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Lukas_A/0/1/0/all/0/1&quot;&gt;Andre Lukas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Ruehle_F/0/1/0/all/0/1&quot;&gt;Fabian Ruehle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Schneider_R/0/1/0/all/0/1&quot;&gt;Robin Schneider&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01439">
<title>The Secrecy Gain of Formally Unimodular Lattices on the Gaussian Wiretap Channel. (arXiv:2111.01439v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2111.01439</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider lattice coding for the Gaussian wiretap channel, where the
challenge is to ensure reliable communication between two authorized parties
while preventing an eavesdropper from learning the transmitted messages.
Recently, a measure called the secrecy function of a lattice coding scheme was
proposed as a design criterion to characterize the eavesdropper&apos;s probability
of correct decision. In this paper, the family of formally unimodular lattices
is presented and shown to possess the same secrecy function behavior as
unimodular and isodual lattices. Based on Construction A, we provide a
universal approach to determine the secrecy gain, i.e., the maximum value of
the secrecy function, for formally unimodular lattices obtained from formally
self-dual codes. Furthermore, we show that formally unimodular lattices can
achieve higher secrecy gain than the best-known unimodular lattices from the
literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bollauf_M/0/1/0/all/0/1&quot;&gt;Maiara F. Bollauf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Yin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ytrehus_O/0/1/0/all/0/1&quot;&gt;&amp;#xd8;yvind Ytrehus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01440">
<title>HHP-Net: A light Heteroscedastic neural network for Head Pose estimation with uncertainty. (arXiv:2111.01440v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01440</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce a novel method to estimate the head pose of people
in single images starting from a small set of head keypoints. To this purpose,
we propose a regression model that exploits keypoints computed automatically by
2D pose estimation algorithms and outputs the head pose represented by yaw,
pitch, and roll. Our model is simple to implement and more efficient with
respect to the state of the art -- faster in inference and smaller in terms of
memory occupancy -- with comparable accuracy. Our method also provides a
measure of the heteroscedastic uncertainties associated with the three angles,
through an appropriately designed loss function; we show there is a correlation
between error and uncertainty values, thus this extra source of information may
be used in subsequent computational steps. As an example application, we
address social interaction analysis in images: we propose an algorithm for a
quantitative estimation of the level of interaction between people, starting
from their head poses and reasoning on their mutual positions. The code is
available at https://github.com/cantarinigiorgio/HHP-Net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cantarini_G/0/1/0/all/0/1&quot;&gt;Giorgio Cantarini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomenotti_F/0/1/0/all/0/1&quot;&gt;Federico Figari Tomenotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noceti_N/0/1/0/all/0/1&quot;&gt;Nicoletta Noceti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odone_F/0/1/0/all/0/1&quot;&gt;Francesca Odone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01454">
<title>Conservative Time Discretization: A Comparative Study. (arXiv:2111.01454v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01454</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the first review of methods to overapproximate the set of
reachable states of linear time-invariant systems subject to uncertain initial
states and input signals for short time horizons. These methods are fundamental
to state-of-the-art reachability algorithms for long time horizons, which
proceed in two steps: they first use such a method to discretize the system for
a short time horizon, and then they efficiently obtain a solution of the new
discrete system for the long time horizon. Traditionally, both qualitative and
quantitative comparison between different reachability algorithms has only
considered the combination of both steps. In this paper we study the first step
in isolation. We perform a variety of numerical experiments for six fundamental
discretization methods from the literature. As we show, these methods have
different trade-offs regarding accuracy and computational cost and, depending
on the characteristics of the system, some methods may be preferred over
others. We also discuss preprocessing steps to improve the results and
efficient implementation strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Forets_M/0/1/0/all/0/1&quot;&gt;Marcelo Forets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schilling_C/0/1/0/all/0/1&quot;&gt;Christian Schilling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01455">
<title>Learning a perceptual manifold with deep features for animation video resequencing. (arXiv:2111.01455v1 [cs.GR])</title>
<link>http://arxiv.org/abs/2111.01455</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel deep learning framework for animation video resequencing.
Our system produces new video sequences by minimizing a perceptual distance of
images from an existing animation video clip. To measure perceptual distance,
we utilize the activations of convolutional neural networks and learn a
perceptual distance by training these features on a small network with data
comprised of human perceptual judgments. We show that with this perceptual
metric and graph-based manifold learning techniques, our framework can produce
new smooth and visually appealing animation video results for a variety of
animation video styles. In contrast to previous work on animation video
resequencing, the proposed framework applies to wide range of image styles and
does not require hand-crafted feature extraction, background subtraction, or
feature correspondence. In addition, we also show that our framework has
applications to appealing arrange unordered collections of images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morace_C/0/1/0/all/0/1&quot;&gt;Charles C.Morace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Thi-Ngoc-Hanh Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1&quot;&gt;Sheng-Yi Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shang-Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Tong-Yee Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01456">
<title>WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks for Keyword Spotting. (arXiv:2111.01456v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01456</link>
<description rdf:parseType="Literal">&lt;p&gt;Ultra-low power local signal processing is a crucial aspect for edge
applications on always-on devices. Neuromorphic processors emulating spiking
neural networks show great computational power while fulfilling the limited
power budget as needed in this domain. In this work we propose spiking neural
dynamics as a natural alternative to dilated temporal convolutions. We extend
this idea to WaveSense, a spiking neural network inspired by the WaveNet
architecture. WaveSense uses simple neural dynamics, fixed time-constants and a
simple feed-forward architecture and hence is particularly well suited for a
neuromorphic implementation. We test the capabilities of this model on several
datasets for keyword-spotting. The results show that the proposed network beats
the state of the art of other spiking neural networks and reaches near
state-of-the-art performance of artificial neural networks such as CNNs and
LSTMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weidel_P/0/1/0/all/0/1&quot;&gt;Philipp Weidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheik_S/0/1/0/all/0/1&quot;&gt;Sadique Sheik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01457">
<title>Synthesizing Speech from Intracranial Depth Electrodes using an Encoder-Decoder Framework. (arXiv:2111.01457v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2111.01457</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech Neuroprostheses have the potential to enable communication for people
with dysarthria or anarthria. Recent advances have demonstrated high-quality
text decoding and speech synthesis from electrocorticographic grids placed on
the cortical surface. Here, we investigate a less invasive measurement
modality, namely stereotactic EEG (sEEG) that provides sparse sampling from
multiple brain regions, including subcortical regions. To evaluate whether sEEG
can also be used to synthesize high-quality audio from neural recordings, we
employ a recurrent encoder-decoder framework based on modern deep learning
methods. We demonstrate that high-quality speech can be reconstructed from
these minimally invasive recordings, despite a limited amount of training data.
Finally, we utilize variational feature dropout to successfully identify the
most informative electrode contacts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1&quot;&gt;Jonas Kohler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ottenhoff_M/0/1/0/all/0/1&quot;&gt;Maarten C. Ottenhoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goulis_S/0/1/0/all/0/1&quot;&gt;Sophocles Goulis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angrick_M/0/1/0/all/0/1&quot;&gt;Miguel Angrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colon_A/0/1/0/all/0/1&quot;&gt;Albert J. Colon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagner_L/0/1/0/all/0/1&quot;&gt;Louis Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tousseyn_S/0/1/0/all/0/1&quot;&gt;Simon Tousseyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kubben_P/0/1/0/all/0/1&quot;&gt;Pieter L. Kubben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herff_C/0/1/0/all/0/1&quot;&gt;Christian Herff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01460">
<title>Geometry-aware Bayesian Optimization in Robotics using Riemannian Mat\&apos;ern Kernels. (arXiv:2111.01460v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01460</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization is a data-efficient technique which can be used for
control parameter tuning, parametric policy adaptation, and structure design in
robotics. Many of these problems require optimization of functions defined on
non-Euclidean domains like spheres, rotation groups, or spaces of
positive-definite matrices. To do so, one must place a Gaussian process prior,
or equivalently define a kernel, on the space of interest. Effective kernels
typically reflect the geometry of the spaces they are defined on, but designing
them is generally non-trivial. Recent work on the Riemannian Mat\&apos;ern kernels,
based on stochastic partial differential equations and spectral theory of the
Laplace-Beltrami operator, offers promising avenues towards constructing such
geometry-aware kernels. In this paper, we study techniques for implementing
these kernels on manifolds of interest in robotics, demonstrate their
performance on a set of artificial benchmark functions, and illustrate
geometry-aware Bayesian optimization for a variety of robotic applications,
covering orientation control, manipulability optimization, and motion planning,
while showing its improved performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaquier_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9;mie Jaquier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borovitskiy_V/0/1/0/all/0/1&quot;&gt;Viacheslav Borovitskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smolensky_A/0/1/0/all/0/1&quot;&gt;Andrei Smolensky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terenin_A/0/1/0/all/0/1&quot;&gt;Alexander Terenin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1&quot;&gt;Tamim Asfour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1&quot;&gt;Leonel Rozo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01465">
<title>System Combination for Grammatical Error Correction Based on Integer Programming. (arXiv:2111.01465v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01465</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a system combination method for grammatical error
correction (GEC), based on nonlinear integer programming (IP). Our method
optimizes a novel F score objective based on error types, and combines multiple
end-to-end GEC systems. The proposed IP approach optimizes the selection of a
single best system for each grammatical error type present in the data.
Experiments of the IP approach on combining state-of-the-art standalone GEC
systems show that the combined system outperforms all standalone systems. It
improves F0.5 score by 3.61% when combining the two best participating systems
in the BEA 2019 shared task, and achieves F0.5 score of 73.08%. We also perform
experiments to compare our IP approach with another state-of-the-art system
combination method for GEC, demonstrating IP&apos;s competitive combination
capability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Ruixi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_H/0/1/0/all/0/1&quot;&gt;Hwee Tou Ng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01466">
<title>Trace maximization algorithm for the approximate tensor diagonalization. (arXiv:2111.01466v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01466</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we develop a Jacobi-type algorithm for the (approximate)
diagonalization of tensors of order $d\geq3$ via tensor trace maximization. For
a general tensor this is an alternating least squares algorithm and the
rotation matrices are chosen in each mode one-by-one to maximize the tensor
trace. On the other hand, for symmetric tensors we discuss a
structure-preserving variant of this algorithm where in each iteration the same
rotation is applied in all modes. We show that both versions of the algorithm
converge to the stationary points of the corresponding objective functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Begovic_E/0/1/0/all/0/1&quot;&gt;Erna Begovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Boksic_A/0/1/0/all/0/1&quot;&gt;Ana Boksic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01470">
<title>Practical error bounds for properties in plane-wave electronic structure calculations. (arXiv:2111.01470v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01470</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose accurate computable error bounds for quantities of interest in
electronic structure calculations, in particular ground-state density matrices
and energies, and interatomic forces. These bounds are based on an estimation
of the error in terms of the residual of the solved equations, which is then
efficiently approximated with computable terms. After providing coarse bounds
based on an analysis of the inverse Jacobian, we improve on these bounds by
solving a linear problem in a small dimension that involves a Schur complement.
We numerically show how accurate these bounds are on a few representative
materials, namely silicon, gallium arsenide and titanium dioxide.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cances_E/0/1/0/all/0/1&quot;&gt;Eric Canc&amp;#xe8;s&lt;/a&gt; (CERMICS, MATHERIALS), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dusson_G/0/1/0/all/0/1&quot;&gt;Genevi&amp;#xe8;ve Dusson&lt;/a&gt; (LMB), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kemlin_G/0/1/0/all/0/1&quot;&gt;Gaspard Kemlin&lt;/a&gt; (CERMICS, MATHERIALS), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Levitt_A/0/1/0/all/0/1&quot;&gt;Antoine Levitt&lt;/a&gt; (CERMICS, MATHERIALS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01471">
<title>Zero-Shot Translation using Diffusion Models. (arXiv:2111.01471v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01471</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we show a novel method for neural machine translation (NMT),
using a denoising diffusion probabilistic model (DDPM), adjusted for textual
data, following recent advances in the field. We show that it&apos;s possible to
translate sentences non-autoregressively using a diffusion model conditioned on
the source sentence. We also show that our model is able to translate between
pairs of languages unseen during training (zero-shot learning).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1&quot;&gt;Eliya Nachmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dovrat_S/0/1/0/all/0/1&quot;&gt;Shaked Dovrat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01472">
<title>Some Questions of Uniformity in Algorithmic Randomness. (arXiv:2111.01472v1 [cs.LO])</title>
<link>http://arxiv.org/abs/2111.01472</link>
<description rdf:parseType="Literal">&lt;p&gt;The $\Omega$ numbers-the halting probabilities of universal prefix-free
machines-are known to be exactly the Martin-L{\&quot;o}f random left-c.e. reals. We
show that one cannot uniformly produce, from a Martin-L{\&quot;o}f random left-c.e.
real $\alpha$, a universal prefix-free machine U whose halting probability is
$\alpha$. We also answer a question of Barmpalias and Lewis-Pye by showing that
given a left-c.e. real $\alpha$, one cannot uniformly produce a left-c.e. real
$\beta$ such that $\alpha$ -- $\beta$ is neither left-c.e. nor right-c.e.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bienvenu_L/0/1/0/all/0/1&quot;&gt;Laurent Bienvenu&lt;/a&gt; (LaBRI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csima_B/0/1/0/all/0/1&quot;&gt;Barbara Csima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrison_Trainor_M/0/1/0/all/0/1&quot;&gt;Matthew Harrison-Trainor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01479">
<title>Dealing With Misspecification In Fixed-Confidence Linear Top-m Identification. (arXiv:2111.01479v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01479</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of the identification of m arms with largest means under
a fixed error rate $\delta$ (fixed-confidence Top-m identification), for
misspecified linear bandit models. This problem is motivated by practical
applications, especially in medicine and recommendation systems, where linear
models are popular due to their simplicity and the existence of efficient
algorithms, but in which data inevitably deviates from linearity. In this work,
we first derive a tractable lower bound on the sample complexity of any
$\delta$-correct algorithm for the general Top-m identification problem. We
show that knowing the scale of the deviation from linearity is necessary to
exploit the structure of the problem. We then describe the first algorithm for
this setting, which is both practical and adapts to the amount of
misspecification. We derive an upper bound to its sample complexity which
confirms this adaptivity and that matches the lower bound when $\delta$
$\rightarrow$ 0. Finally, we evaluate our algorithm on both synthetic and
real-world data, showing competitive performance with respect to existing
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reda_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;mence R&amp;#xe9;da&lt;/a&gt; (UP, INSERM), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tirinzoni_A/0/1/0/all/0/1&quot;&gt;Andrea Tirinzoni&lt;/a&gt; (Scool, CNRS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Degenne_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;my Degenne&lt;/a&gt; (Scool, CNRS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01480">
<title>Variational message passing (VMP) applied to LDA. (arXiv:2111.01480v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01480</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) is the
original inference mechanism for LDA. Many variants of VB for LDA, as well as
for VB in general, have been developed since LDA&apos;s inception in 2013, but
standard VB is still widely applied to LDA. Variational message passing (VMP)
is the message passing equivalent of VB and is a useful tool for constructing a
variational inference solution for a large variety of conjugate exponential
graphical models (there is also a non conjugate variant available for other
models). In this article we present the VMP equations for LDA and also provide
a brief discussion of the equations. We hope that this will assist others when
deriving variational inference solutions to other similar graphical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_R/0/1/0/all/0/1&quot;&gt;Rebecca M.C. Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Preez_J/0/1/0/all/0/1&quot;&gt;Johan A. du Preez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01481">
<title>The supersingular isogeny path and endomorphism ring problems are equivalent. (arXiv:2111.01481v1 [math.NT])</title>
<link>http://arxiv.org/abs/2111.01481</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that the path-finding problem in $\ell$-isogeny graphs and the
endomorphism ring problem for supersingular elliptic curves are equivalent
under reductions of polynomial expected time, assuming the generalised Riemann
hypothesis. The presumed hardness of these problems is foundational for
isogeny-based cryptography. As an essential tool, we develop a rigorous
algorithm for the quaternion analog of the path-finding problem, building upon
the heuristic method of Kohel, Lauter, Petit and Tignol. This problem, and its
(previously heuristic) resolution, are both a powerful cryptanalytic tool and a
building-block for cryptosystems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wesolowski_B/0/1/0/all/0/1&quot;&gt;Benjamin Wesolowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01482">
<title>DAGSurv: Directed Acyclic Graph Based Survival Analysis Using Deep Neural Networks. (arXiv:2111.01482v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01482</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal structures for observational survival data provide crucial information
regarding the relationships between covariates and time-to-event. We derive
motivation from the information theoretic source coding argument, and show that
incorporating the knowledge of the directed acyclic graph (DAG) can be
beneficial if suitable source encoders are employed. As a possible source
encoder in this context, we derive a variational inference based conditional
variational autoencoder for causal structured survival prediction, which we
refer to as DAGSurv. We illustrate the performance of DAGSurv on low and
high-dimensional synthetic datasets, and real-world datasets such as METABRIC
and GBSG. We demonstrate that the proposed method outperforms other survival
analysis baselines such as Cox Proportional Hazards, DeepSurv and Deephit,
which are oblivious to the underlying causal relationship between data
entities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Ansh Kumar Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kukreja_R/0/1/0/all/0/1&quot;&gt;Rahul Kukreja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prasad_R/0/1/0/all/0/1&quot;&gt;Ranjitha Prasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1&quot;&gt;Shilpa Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01484">
<title>ArchABM: an agent-based simulator of human interaction with the built environment. $CO_2$ and viral load analysis for indoor air quality. (arXiv:2111.01484v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2111.01484</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent evidence suggests that SARS-CoV-2, which is the virus causing a global
pandemic in 2020, is predominantly transmitted via airborne aerosols in indoor
environments. This calls for novel strategies when assessing and controlling a
building&apos;s indoor air quality (IAQ). IAQ can generally be controlled by
ventilation and/or policies to regulate human-building-interaction. However, in
a building, occupants use rooms in different ways, and it may not be obvious
which measure or combination of measures leads to a cost- and energy-effective
solution ensuring good IAQ across the entire building. Therefore, in this
article, we introduce a novel agent-based simulator, ArchABM, designed to
assist in creating new or adapt existing buildings by estimating adequate room
sizes, ventilation parameters and testing the effect of policies while taking
into account IAQ as a result of complex human-building interaction patterns. A
recently published aerosol model was adapted to calculate time-dependent carbon
dioxide ($CO_2$) and virus quanta concentrations in each room and inhaled
$CO_2$ and virus quanta for each occupant over a day as a measure of
physiological response. ArchABM is flexible regarding the aerosol model and the
building layout due to its modular architecture, which allows implementing
further models, any number and size of rooms, agents, and actions reflecting
human-building interaction patterns. We present a use case based on a real
floor plan and working schedules adopted in our research center. This study
demonstrates how advanced simulation tools can contribute to improving IAQ
across a building, thereby ensuring a healthy indoor environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Martinez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruse_J/0/1/0/all/0/1&quot;&gt;Jan L. Bruse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florez_Tapia_A/0/1/0/all/0/1&quot;&gt;Ane M. Florez-Tapia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viles_E/0/1/0/all/0/1&quot;&gt;Elisabeth Viles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olaizola_I/0/1/0/all/0/1&quot;&gt;Igor G. Olaizola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01485">
<title>A strong call-by-need calculus. (arXiv:2111.01485v1 [cs.LO])</title>
<link>http://arxiv.org/abs/2111.01485</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a call-by-need $\lambda$-calculus that enables strong reduction
(that is, reduction inside the body of abstractions) and guarantees that
arguments are only evaluated if needed and at most once. This calculus uses
explicit substitutions and subsumes the existing strong-call-by-need strategy,
but allows for more reduction sequences, and often shorter ones, while
preserving the neededness. The calculus is shown to be normalizing in a strong
sense: Whenever a $\lambda$-term t admits a normal form n in the
$\lambda$-calculus, then any reduction sequence from t in the calculus
eventually reaches a representative of the normal form n. We also exhibit a
restriction of this calculus that has the diamond property and that only
performs reduction sequences of minimal length, which makes it systematically
better than the existing strategy. We have used the Abella proof assistant to
formalize part of this calculus, and discuss how this experiment affected its
design. In particular, it led us to derive a new description of call-by-need
reduction based on inductive rules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balabonski_T/0/1/0/all/0/1&quot;&gt;Thibaut Balabonski&lt;/a&gt; (LMF), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanco_A/0/1/0/all/0/1&quot;&gt;Antoine Lanco&lt;/a&gt; (TOCCATA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melquiond_G/0/1/0/all/0/1&quot;&gt;Guillaume Melquiond&lt;/a&gt; (TOCCATA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01495">
<title>Constructing Neural Network-Based Models for Simulating Dynamical Systems. (arXiv:2111.01495v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01495</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamical systems see widespread use in natural sciences like physics,
biology, chemistry, as well as engineering disciplines such as circuit
analysis, computational fluid dynamics, and control. For simple systems, the
differential equations governing the dynamics can be derived by applying
fundamental physical laws. However, for more complex systems, this approach
becomes exceedingly difficult. Data-driven modeling is an alternative paradigm
that seeks to learn an approximation of the dynamics of a system using
observations of the true system. In recent years, there has been an increased
interest in data-driven modeling techniques, in particular neural networks have
proven to provide an effective framework for solving a wide range of tasks.
This paper provides a survey of the different ways to construct models of
dynamical systems using neural networks. In addition to the basic overview, we
review the related literature and outline the most significant challenges from
numerical simulations that this modeling paradigm must overcome. Based on the
reviewed literature and identified challenges, we provide a discussion on
promising research areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legaard_C/0/1/0/all/0/1&quot;&gt;Christian M&amp;#xf8;ldrup Legaard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schranz_T/0/1/0/all/0/1&quot;&gt;Thomas Schranz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schweiger_G/0/1/0/all/0/1&quot;&gt;Gerald Schweiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drgona_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe1;n Drgo&amp;#x148;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falay_B/0/1/0/all/0/1&quot;&gt;Basak Falay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe1;udio Gomes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1&quot;&gt;Alexandros Iosifidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abkar_M/0/1/0/all/0/1&quot;&gt;Mahdi Abkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_P/0/1/0/all/0/1&quot;&gt;Peter Gorm Larsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01496">
<title>Quality change: norm or exception? Measurement, Analysis and Detection of Quality Change in Wikipedia. (arXiv:2111.01496v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01496</link>
<description rdf:parseType="Literal">&lt;p&gt;Wikipedia has been turned into an immensely popular crowd-sourced
encyclopedia for information dissemination on numerous versatile topics in the
form of subscription free content. It allows anyone to contribute so that the
articles remain comprehensive and updated. For enrichment of content without
compromising standards, the Wikipedia community enumerates a detailed set of
guidelines, which should be followed. Based on these, articles are categorized
into several quality classes by the Wikipedia editors with increasing adherence
to guidelines. This quality assessment task by editors is laborious as well as
demands platform expertise. As a first objective, in this paper, we study
evolution of a Wikipedia article with respect to such quality scales. Our
results show novel non-intuitive patterns emerging from this exploration. As a
second objective we attempt to develop an automated data driven approach for
the detection of the early signals influencing the quality change of articles.
We posit this as a change point detection problem whereby we represent an
article as a time series of consecutive revisions and encode every revision by
a set of intuitive features. Finally, various change point detection algorithms
are used to efficiently and accurately detect the future change points. We also
perform various ablation studies to understand which group of features are most
effective in identifying the change points. To the best of our knowledge, this
is the first work that rigorously explores English Wikipedia article quality
life cycle from the perspective of quality indicators and provides a novel
unsupervised page level approach to detect quality switch, which can help in
automatic content monitoring in Wikipedia thus contributing significantly to
the CSCW community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1&quot;&gt;Paramita Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guda_B/0/1/0/all/0/1&quot;&gt;Bhanu Prakash Reddy Guda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seelaboyina_S/0/1/0/all/0/1&quot;&gt;Sasi Bhusan Seelaboyina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1&quot;&gt;Soumya Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Animesh Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01501">
<title>Constructing a software requirements specification and design for electronic IT news magazine system. (arXiv:2111.01501v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2111.01501</link>
<description rdf:parseType="Literal">&lt;p&gt;Requirements engineering process intends to obtain software services and
constraints. This process is essential to meet the customer&apos;s needs and
expectations. This process includes three main activities in general. These are
detecting requirements by interacting with software stakeholders, transferring
these requirements into a standard document, and examining that the
requirements really define the software that the client needs. Functional
requirements are services that the software should deliver to the end-user. In
addition, functional requirements describe how the software should respond to
specific inputs, and how the software should behave in certain circumstances.
This paper aims to develop a software requirements specification document of
the electronic IT news magazine system. The electronic magazine provides users
to post and view up-to-date IT news. Still, there is a lack in the literature
of comprehensive studies about the construction of the electronic magazine
software specification and design in conformance with the contemporary software
development processes. Moreover, there is a need for a suitable research
framework to support the requirements engineering process. The novelty of this
paper is the construction of software specification and design of the
electronic magazine by following the Al-Msie&apos;deen research framework. All the
documents of software requirements specification and design have been
constructed to conform to the agile usage-centered design technique and the
proposed research framework. A requirements specification and design are
suggested and followed for the construction of the electronic magazine
software. This study proved that involving users extensively in the process of
software requirements specification and design will lead to the creation of
dependable and acceptable software systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Msiedeen_R/0/1/0/all/0/1&quot;&gt;Ra&amp;#x27;Fat Al-Msie&amp;#x27;deen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasi_A/0/1/0/all/0/1&quot;&gt;Anas H. Blasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alsuwaiket_M/0/1/0/all/0/1&quot;&gt;Mohammed A. Alsuwaiket&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01504">
<title>Towards Enabling I/O Awareness in Task-based Programming Models. (arXiv:2111.01504v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2111.01504</link>
<description rdf:parseType="Literal">&lt;p&gt;Storage systems have not kept the same technology improvement rate as
computing systems. As applications produce more and more data, I/O becomes the
limiting factor for increasing application performance. I/O congestion caused
by concurrent access to storage devices is one of the main obstacles that cause
I/O performance degradation and, consequently, total performance degradation.
&lt;/p&gt;
&lt;p&gt;Although task-based programming models made it possible to achieve higher
levels of parallelism by enabling the execution of tasks in large-scale
distributed platforms, this parallelism only benefited the compute workload of
the application. Previous efforts addressing I/O performance bottlenecks either
focused on optimizing fine-grained I/O access patterns using I/O libraries or
avoiding system-wide I/O congestion by minimizing interference between multiple
applications.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose enabling I/O Awareness in task-based programming
models for improving the total performance of applications. An I/O aware
programming model is able to create more parallelism and mitigate the causes of
I/O performance degradation. On the one hand, more parallelism can be created
by supporting special tasks for executing I/O workloads, called I/O tasks, that
can overlap with the execution of compute tasks. On the other hand, I/O
congestion can be mitigated by constraining I/O tasks scheduling. We propose
two approaches for specifying such constraints: explicitly set by the users or
automatically inferred and tuned during application&apos;s execution to optimize the
execution of variable I/O workloads on a certain storage infrastructure.
&lt;/p&gt;
&lt;p&gt;Our experiments on the MareNostrum 4 Supercomputer demonstrate that using I/O
aware programming model can achieve up to 43% total performance improvement as
compared to the I/O non-aware implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elshazly_H/0/1/0/all/0/1&quot;&gt;Hatem Elshazly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ejarque_J/0/1/0/all/0/1&quot;&gt;Jorge Ejarque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lordan_F/0/1/0/all/0/1&quot;&gt;Francesc Lordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badia_R/0/1/0/all/0/1&quot;&gt;Rosa M. Badia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01505">
<title>Out of distribution detection for skin and malaria images. (arXiv:2111.01505v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01505</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have shown promising results in disease detection and
classification using medical image data. However, they still suffer from the
challenges of handling real-world scenarios especially reliably detecting
out-of-distribution (OoD) samples. We propose an approach to robustly classify
OoD samples in skin and malaria images without the need to access labeled OoD
samples during training. Specifically, we use metric learning along with
logistic regression to force the deep networks to learn much rich class
representative features. To guide the learning process against the OoD
examples, we generate ID similar-looking examples by either removing
class-specific salient regions in the image or permuting image parts and
distancing them away from in-distribution samples. During inference time, the
K-reciprocal nearest neighbor is employed to detect out-of-distribution
samples. For skin cancer OoD detection, we employ two standard benchmark skin
cancer ISIC datasets as ID, and six different datasets with varying difficulty
levels were taken as out of distribution. For malaria OoD detection, we use the
BBBC041 malaria dataset as ID and five different challenging datasets as out of
distribution. We achieved state-of-the-art results, improving 5% and 4% in
TNR@TPR95% over the previous state-of-the-art for skin cancer and malaria OoD
detection respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zaida_M/0/1/0/all/0/1&quot;&gt;Muhammad Zaida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1&quot;&gt;Shafaqat Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ali_M/0/1/0/all/0/1&quot;&gt;Mohsen Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hussein_S/0/1/0/all/0/1&quot;&gt;Sarfaraz Hussein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saadia_A/0/1/0/all/0/1&quot;&gt;Asma Saadia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sultani_W/0/1/0/all/0/1&quot;&gt;Waqas Sultani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01510">
<title>A Hybrid Approach for Learning to Shift and Grasp with Elaborate Motion Primitives. (arXiv:2111.01510v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01510</link>
<description rdf:parseType="Literal">&lt;p&gt;Many possible fields of application of robots in real world settings hinge on
the ability of robots to grasp objects. As a result, robot grasping has been an
active field of research for many years. With our publication we contribute to
the endeavor of enabling robots to grasp, with a particular focus on bin
picking applications. Bin picking is especially challenging due to the often
cluttered and unstructured arrangement of objects and the often limited
graspability of objects by simple top down grasps. To tackle these challenges,
we propose a fully self-supervised reinforcement learning approach based on a
hybrid discrete-continuous adaptation of soft actor-critic (SAC). We employ
parametrized motion primitives for pushing and grasping movements in order to
enable a flexibly adaptable behavior to the difficult setups we consider.
Furthermore, we use data augmentation to increase sample efficiency. We
demonnstrate our proposed method on challenging picking scenarios in which
planar grasp learning or action discretization methods would face a lot of
difficulties
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_Z/0/1/0/all/0/1&quot;&gt;Zohar Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1&quot;&gt;Hanna Ziesche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1&quot;&gt;Ngo Anh Vien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1&quot;&gt;Dotan Di Castro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01511">
<title>ISP-Agnostic Image Reconstruction for Under-Display Cameras. (arXiv:2111.01511v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01511</link>
<description rdf:parseType="Literal">&lt;p&gt;Under-display cameras have been proposed in recent years as a way to reduce
the form factor of mobile devices while maximizing the screen area.
Unfortunately, placing the camera behind the screen results in significant
image distortions, including loss of contrast, blur, noise, color shift,
scattering artifacts, and reduced light sensitivity. In this paper, we propose
an image-restoration pipeline that is ISP-agnostic, i.e. it can be combined
with any legacy ISP to produce a final image that matches the appearance of
regular cameras using the same ISP. This is achieved with a deep learning
approach that performs a RAW-to-RAW image restoration. To obtain large
quantities of real under-display camera training data with sufficient contrast
and scene diversity, we furthermore develop a data capture method utilizing an
HDR monitor, as well as a data augmentation method to generate suitable HDR
content. The monitor data is supplemented with real-world data that has less
scene diversity but allows us to achieve fine detail recovery without being
limited by the monitor resolution. Together, this approach successfully
restores color and contrast as well as image detail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qi_M/0/1/0/all/0/1&quot;&gt;Miao Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuqi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heidrich_W/0/1/0/all/0/1&quot;&gt;Wolfgang Heidrich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01515">
<title>Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model. (arXiv:2111.01515v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01515</link>
<description rdf:parseType="Literal">&lt;p&gt;The enormous amount of data being generated on the web and social media has
increased the demand for detecting online hate speech. Detecting hate speech
will reduce their negative impact and influence on others. A lot of effort in
the Natural Language Processing (NLP) domain aimed to detect hate speech in
general or detect specific hate speech such as religion, race, gender, or
sexual orientation. Hate communities tend to use abbreviations, intentional
spelling mistakes, and coded words in their communication to evade detection,
adding more challenges to hate speech detection tasks. Thus, word
representation will play an increasingly pivotal role in detecting hate speech.
This paper investigates the feasibility of leveraging domain-specific word
embedding in Bidirectional LSTM based deep model to automatically
detect/classify hate speech. Furthermore, we investigate the use of the
transfer learning language model (BERT) on hate speech problem as a binary
classification task. The experiments showed that domainspecific word embedding
with the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT
achieved up to 96% f1-score on a combined balanced dataset from available hate
speech datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1&quot;&gt;Hind Saleh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alhothali_A/0/1/0/all/0/1&quot;&gt;Areej Alhothali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moria_K/0/1/0/all/0/1&quot;&gt;Kawthar Moria&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01516">
<title>FedFly: Towards Migration in Edge-based Distributed Federated Learning. (arXiv:2111.01516v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2111.01516</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is a privacy-preserving distributed machine learning
technique that trains models without having direct access to the original data
generated on devices. Since devices may be resource constrained, offloading can
be used to improve FL performance by transferring computational workload from
devices to edge servers. However, due to mobility, devices participating in FL
may leave the network during training and need to connect to a different edge
server. This is challenging because the offloaded computations from edge server
need to be migrated. In line with this assertion, we present FedFly, which is,
to the best of our knowledge, the first work to migrate a deep neural network
(DNN) when devices move between edge servers during FL training. Our empirical
results on the CIFAR-10 dataset, with both balanced and imbalanced data
distribution support our claims that FedFly can reduce training time by up to
33% when a device moves after 50% of the training is completed, and by up to
45% when 90% of the training is completed when compared to state-of-the-art
offloading approach in FL. FedFly has negligible overhead of 2 seconds and does
not compromise accuracy. Finally, we highlight a number of open research issues
for further investigation. FedFly can be downloaded from
https://github.com/qub-blesson/FedFly
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullah_R/0/1/0/all/0/1&quot;&gt;Rehmat Ullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Di Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harvey_P/0/1/0/all/0/1&quot;&gt;Paul Harvey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilpatrick_P/0/1/0/all/0/1&quot;&gt;Peter Kilpatrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spence_I/0/1/0/all/0/1&quot;&gt;Ivor Spence&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varghese_B/0/1/0/all/0/1&quot;&gt;Blesson Varghese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01526">
<title>A modified gravity model based on network efficiency for vital nodes identification in complex networks. (arXiv:2111.01526v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01526</link>
<description rdf:parseType="Literal">&lt;p&gt;Vital nodes identification is an essential problem in network science.
Various methods have been proposed to solve this problem. In particular, based
on the gravity model, a series of improved gravity models are proposed to find
vital nodes better in complex networks. However, they still have the room to be
improved. In this paper, a novel and improved gravity model, which is named
network efficiency gravity centrality model (NEG), integrates gravity model and
network efficiency is proposed. Compared to other methods based on different
gravity models, the proposed method considers the effect of the nodes on
structure robustness of the network better. To solidate the superiority of the
proposed method, experiments on varieties of real-world networks are carried
out.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hanwen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_Q/0/1/0/all/0/1&quot;&gt;Qiuyan Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yong Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01527">
<title>Household Cloth Object Set: Fostering Benchmarking in Deformable Object Manipulation. (arXiv:2111.01527v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01527</link>
<description rdf:parseType="Literal">&lt;p&gt;Benchmarking of robotic manipulations is one of the open issues in robotic
research. An important factor that has enabled progress in this area in the
last decade is the existence of common object sets that have been shared among
different research groups. However, the existing object sets are very limited
when it comes to cloth-like objects that have unique particularities and
challenges. This paper is a first step towards the design of a cloth object set
to be distributed among research groups from the robotics cloth manipulation
community. We present a set of household cloth objects and related tasks that
serve to expose the challenges related to gathering such an object set and
propose a roadmap to the design of common benchmarks in cloth manipulation
tasks, with the intention to set the grounds for a future debate in the
community that will be necessary to foster benchmarking for the manipulation of
cloth-like objects. Some RGB-D and object scans are also collected as examples
for the objects in relevant configurations. More details about the cloth set
are shared in
&lt;a href=&quot;http://www.iri.upc.edu/groups/perception/ClothObjectSet/HouseholdClothSet.html.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Camacho_I/0/1/0/all/0/1&quot;&gt;Irene Garcia-Camacho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borras_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfa;lia Borr&amp;#xe0;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calli_B/0/1/0/all/0/1&quot;&gt;Berk Calli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norton_A/0/1/0/all/0/1&quot;&gt;Adam Norton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alenya_G/0/1/0/all/0/1&quot;&gt;Guillem Aleny&amp;#xe0;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01528">
<title>HydraText: Multi-objective Optimization for Adversarial Textual Attack. (arXiv:2111.01528v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01528</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of adversarial textual attack has significantly grown over the last
years, where the commonly considered objective is to craft adversarial examples
that can successfully fool the target models. However, the imperceptibility of
attacks, which is also an essential objective, is often left out by previous
studies. In this work, we advocate considering both objectives at the same
time, and propose a novel multi-optimization approach (dubbed HydraText) with
provable performance guarantee to achieve successful attacks with high
imperceptibility. We demonstrate the efficacy of HydraText through extensive
experiments under both score-based and decision-based settings, involving five
modern NLP models across five benchmark datasets. In comparison to existing
state-of-the-art attacks, HydraText consistently achieves simultaneously higher
success rates, lower modification rates, and higher semantic similarity to the
original texts. A human evaluation study shows that the adversarial examples
crafted by HydraText maintain validity and naturality well. Finally, these
examples also exhibit good transferability and can bring notable robustness
improvement to the target models by adversarial training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shengcai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1&quot;&gt;Ning Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1&quot;&gt;Chao Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1&quot;&gt;Ke Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01531">
<title>Generating synthetic transactional profiles. (arXiv:2111.01531v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01531</link>
<description rdf:parseType="Literal">&lt;p&gt;Financial institutions use clients&apos; payment transactions in numerous banking
applications. Transactions are very personal and rich in behavioural patterns,
often unique to individuals, which make them equivalent to personally
identifiable information in some cases. In this paper, we generate synthetic
transactional profiles using machine learning techniques with the goal to
preserve both data utility and privacy. A challenge we faced was to deal with
sparse vectors due to the few spending categories a client uses compared to all
the ones available. We measured data utility by calculating common insights
used by the banking industry on both the original and the synthetic data-set.
Our approach shows that neural network models can generate valuable synthetic
data in such context. Finally, we tried privacy-preserving techniques and
observed its effect on models&apos; performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lautraite_H/0/1/0/all/0/1&quot;&gt;Hadrien Lautraite&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mesana_P/0/1/0/all/0/1&quot;&gt;Patrick Mesana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01533">
<title>A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v1 [math.OC])</title>
<link>http://arxiv.org/abs/2111.01533</link>
<description rdf:parseType="Literal">&lt;p&gt;Most real optimization problems are defined over a mixed search space where
the variables are both discrete and continuous. In engineering applications,
the objective function is typically calculated with a numerically costly
black-box simulation.General mixed and costly optimization problems are
therefore of a great practical interest, yet their resolution remains in a
large part an open scientific question. In this article, costly mixed problems
are approached through Gaussian processes where the discrete variables are
relaxed into continuous latent variables. The continuous space is more easily
harvested by classical Bayesian optimization techniques than a mixed space
would. Discrete variables are recovered either subsequently to the continuous
optimization, or simultaneously with an additional continuous-discrete
compatibility constraint that is handled with augmented Lagrangians. Several
possible implementations of such Bayesian mixed optimizers are compared. In
particular, the reformulation of the problem with continuous latent variables
is put in competition with searches working directly in the mixed space. Among
the algorithms involving latent variables and an augmented Lagrangian, a
particular attention is devoted to the Lagrange multipliers for which a local
and a global estimation techniques are studied. The comparisons are based on
the repeated optimization of three analytical functions and a beam design
problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1&quot;&gt;Jhouben Cuesta-Ramirez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1&quot;&gt;Rodolphe Le Riche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1&quot;&gt;Olivier Roustant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1&quot;&gt;Guillaume Perrin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1&quot;&gt;Cedric Durantin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1&quot;&gt;Alain Gliere&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01536">
<title>Learning Circular Hidden Quantum Markov Models: A Tensor Network Approach. (arXiv:2111.01536v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2111.01536</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose circular Hidden Quantum Markov Models (c-HQMMs),
which can be applied for modeling temporal data in quantum datasets (with
classical datasets as a special case). We show that c-HQMMs are equivalent to a
constrained tensor network (more precisely, circular Local Purified State with
positive-semidefinite decomposition) model. This equivalence enables us to
provide an efficient learning model for c-HQMMs. The proposed learning approach
is evaluated on six real datasets and demonstrates the advantage of c-HQMMs on
multiple datasets as compared to HQMMs, circular HMMs, and HMMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Javidian_M/0/1/0/all/0/1&quot;&gt;Mohammad Ali Javidian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jacob_Z/0/1/0/all/0/1&quot;&gt;Zubin Jacob&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01537">
<title>Physical Channel Modeling for RIS-Empowered Wireless Networks in Sub-6 GHz Bands. (arXiv:2111.01537v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2111.01537</link>
<description rdf:parseType="Literal">&lt;p&gt;Reconfigurable intelligent surface (RIS)-assisted communications is one of
the promising candidates for next generation wireless networks by controlling
the propagation environment dynamically. In this study, a channel modeling
strategy for RIS-assisted wireless networks is introduced in sub-6 GHz bands by
considering both far-field and near-field behaviours in transmission. We also
proposed an open-source physical channel simulator for sub-6 GHz bands where
operating frequency, propagation environment, terminal locations, RIS location
and size can be adjusted. It is demonstrated via extensive computer simulations
that an improved achievable rate performance is obtained in the presence of
RISs for both near-field and far-field conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilinc_F/0/1/0/all/0/1&quot;&gt;Fatih Kilinc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yildirim_I/0/1/0/all/0/1&quot;&gt;Ibrahim Yildirim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basar_E/0/1/0/all/0/1&quot;&gt;Ertugrul Basar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01540">
<title>MillenniumDB: A Persistent, Open-Source, Graph Database. (arXiv:2111.01540v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2111.01540</link>
<description rdf:parseType="Literal">&lt;p&gt;In this systems paper, we present MillenniumDB: a novel graph database engine
that is modular, persistent, and open source. MillenniumDB is based on a graph
data model, which we call domain graphs, that provides a simple abstraction
upon which a variety of popular graph models can be supported. The engine
itself is founded on a combination of tried and tested techniques from
relational data management, state-of-the-art algorithms for worst-case-optimal
joins, as well as graph-specific algorithms for evaluating path queries. In
this paper, we present the main design principles underlying MillenniumDB,
describing the abstract graph model and query semantics supported, the concrete
data model and query syntax implemented, as well as the storage, indexing,
query planning and query evaluation techniques used. We evaluate MillenniumDB
over real-world data and queries from the Wikidata knowledge graph, where we
find that it outperforms other popular persistent graph database engines
(including both enterprise and open source alternatives) that support similar
query features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vrgoc_D/0/1/0/all/0/1&quot;&gt;Domagoj Vrgoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1&quot;&gt;Carlos Rojas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angles_R/0/1/0/all/0/1&quot;&gt;Renzo Angles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arenas_M/0/1/0/all/0/1&quot;&gt;Marcelo Arenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arroyuelo_D/0/1/0/all/0/1&quot;&gt;Diego Arroyuelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aranda_C/0/1/0/all/0/1&quot;&gt;Carlos Buil Aranda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hogan_A/0/1/0/all/0/1&quot;&gt;Aidan Hogan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navarro_G/0/1/0/all/0/1&quot;&gt;Gonzalo Navarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riveros_C/0/1/0/all/0/1&quot;&gt;Cristian Riveros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romero_J/0/1/0/all/0/1&quot;&gt;Juan Romero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01543">
<title>UQuAD1.0: Development of an Urdu Question Answering Training Data for Machine Reading Comprehension. (arXiv:2111.01543v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01543</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, low-resource Machine Reading Comprehension (MRC) has made
significant progress, with models getting remarkable performance on various
language datasets. However, none of these models have been customized for the
Urdu language. This work explores the semi-automated creation of the Urdu
Question Answering Dataset (UQuAD1.0) by combining machine-translated SQuAD
with human-generated samples derived from Wikipedia articles and Urdu RC
worksheets from Cambridge O-level books. UQuAD1.0 is a large-scale Urdu dataset
intended for extractive machine reading comprehension tasks consisting of 49k
question Answers pairs in question, passage, and answer format. In UQuAD1.0,
45000 pairs of QA were generated by machine translation of the original
SQuAD1.0 and approximately 4000 pairs via crowdsourcing. In this study, we used
two types of MRC models: rule-based baseline and advanced Transformer-based
models. However, we have discovered that the latter outperforms the others;
thus, we have decided to concentrate solely on Transformer-based architectures.
Using XLMRoBERTa and multi-lingual BERT, we acquire an F1 score of 0.66 and
0.63, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazi_S/0/1/0/all/0/1&quot;&gt;Samreen Kazi&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoja_S/0/1/0/all/0/1&quot;&gt;Shakeel Khoja&lt;/a&gt; (1) ((1) School of Mathematics &amp;amp; Computer Science, Institute of Business Administration, Karachi Pakistan)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01544">
<title>Comprehensive and Clinically Accurate Head and Neck Organs at Risk Delineation via Stratified Deep Learning: A Large-scale Multi-Institutional Study. (arXiv:2111.01544v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01544</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate organ at risk (OAR) segmentation is critical to reduce the
radiotherapy post-treatment complications. Consensus guidelines recommend a set
of more than 40 OARs in the head and neck (H&amp;amp;N) region, however, due to the
predictable prohibitive labor-cost of this task, most institutions choose a
substantially simplified protocol by delineating a smaller subset of OARs and
neglecting the dose distributions associated with other OARs. In this work we
propose a novel, automated and highly effective stratified OAR segmentation
(SOARS) system using deep learning to precisely delineate a comprehensive set
of 42 H&amp;amp;N OARs. SOARS stratifies 42 OARs into anchor, mid-level, and small &amp;amp;
hard subcategories, with specifically derived neural network architectures for
each category by neural architecture search (NAS) principles. We built SOARS
models using 176 training patients in an internal institution and independently
evaluated on 1327 external patients across six different institutions. It
consistently outperformed other state-of-the-art methods by at least 3-5% in
Dice score for each institutional evaluation (up to 36% relative error
reduction in other metrics). More importantly, extensive multi-user studies
evidently demonstrated that 98% of the SOARS predictions need only very minor
or no revisions for direct clinical acceptance (saving 90% radiation
oncologists workload), and their segmentation and dosimetric accuracy are
within or smaller than the inter-user variation. These findings confirmed the
strong clinical applicability of SOARS for the OAR delineation process in H&amp;amp;N
cancer radiotherapy workflows, with improved efficiency, comprehensiveness, and
quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Dazhou Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ge_J/0/1/0/all/0/1&quot;&gt;Jia Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xianghua Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Senxiang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xin_Y/0/1/0/all/0/1&quot;&gt;Yi Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yuchen Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bing-shen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hung_T/0/1/0/all/0/1&quot;&gt;Tsung-Min Hung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhuotun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1&quot;&gt;Ling Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yanping Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Rui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Gong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mao_M/0/1/0/all/0/1&quot;&gt;Mengyuan Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaohua Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenxiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuzhen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lingyun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1&quot;&gt;Jing Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Harrison_A/0/1/0/all/0/1&quot;&gt;Adam P. Harrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1&quot;&gt;Le Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chien-Yu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jin_D/0/1/0/all/0/1&quot;&gt;Dakai Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ho_T/0/1/0/all/0/1&quot;&gt;Tsung-Ying Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01549">
<title>Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima. (arXiv:2111.01549v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01549</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers incremental few-shot learning, which requires a model to
continually recognize new categories with only a few examples provided. Our
study shows that existing methods severely suffer from catastrophic forgetting,
a well-known problem in incremental learning, which is aggravated due to data
scarcity and imbalance in the few-shot setting. Our analysis further suggests
that to prevent catastrophic forgetting, actions need to be taken in the
primitive stage -- the training of base classes instead of later few-shot
learning sessions. Therefore, we propose to search for flat local minima of the
base training objective function and then fine-tune the model parameters within
the flat region on new tasks. In this way, the model can efficiently learn new
classes while preserving the old ones. Comprehensive experimental results
demonstrate that our approach outperforms all prior state-of-the-art methods
and is very close to the approximate upper bound. The source code is available
at https://github.com/moukamisama/F2M.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1&quot;&gt;Guangyuan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiaxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenlong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1&quot;&gt;Li-Ming Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiao-Ming Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01550">
<title>A Comprehensive Survey on Nanophotonics Neural Networks. (arXiv:2111.01550v1 [cs.ET])</title>
<link>http://arxiv.org/abs/2111.01550</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last years, materializations of neuromorphic circuits based on
nanophotonic arrangements have been proposed, which contain complete optical
circuits, laser, photodetectors, photonic crystals, optical fibers, flat
waveguides, and other passive optical elements of nanostructured materials,
which eliminate the time of simultaneous processing of big groups of data,
taking advantage of the quantum perspective and thus highly increasing the
potentials of contemporary intelligent computational systems. This article is
an effort to record and study the research that has been conducted concerning
the methods of development and materi-alization of neuromorphic circuits of
Neural Networks of nanophotonic arrangements. In particular, an investigative
study of the methods of developing nanophotonic neuromorphic processors, their
originality in neuronic architectural structure, their training methods and
their optimization has been realized along with the study of special issues
such as optical activation functions and cost functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demertzis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Demertzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papadopoulos_G/0/1/0/all/0/1&quot;&gt;Georgios Papadopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iliadis_L/0/1/0/all/0/1&quot;&gt;Lazaros Iliadis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magafas_L/0/1/0/all/0/1&quot;&gt;Lykourgos Magafas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01551">
<title>Classifying Approximation Algorithms: Understanding the APX Complexity Class. (arXiv:2111.01551v1 [cs.CC])</title>
<link>http://arxiv.org/abs/2111.01551</link>
<description rdf:parseType="Literal">&lt;p&gt;We are interested in the intersection of approximation algorithms and
complexity theory, in particular focusing on the complexity class APX.
Informally, APX $\subseteq$ NPO is the complexity class comprising optimization
problems where the ratio $\frac{OPT(I)}{ALG(I)} \leq c$ for all instances I. We
will do a deep dive into studying APX as a complexity class, in particular,
investigating how researchers have defined PTAS and L reductions, as well as
the notion of APX-completeness, thereby clarifying where APX lies on the
polynomial hierarchy. We will discuss the relationship of this class with
FPTAS, PTAS, APX, log-APX and poly-APX). We will sketch the proof that Max
3-SAT is APX-hard, and compare this complexity class in relation to $BPP$,
$ZPP$ to elucidate whether randomization is powerful enough to achieve certain
approximation guarantees and introduce techniques that complement the design of
approximation algorithms such as through \textit{primal-dual} analysis,
\textit{local search} and \textit{semi-definite programming}. Through the PCP
theorem, we will explore the fundamental relationship between hardness of
approximation and randomness, and will recast the way we look at the complexity
class NP. We will finish by looking at the \textit{&quot;real world&quot;} applications
of this material in Economics. Finally, we will touch upon recent breakthroughs
in the Metric Travelling Salesman and asymmetric travelling salesman problem,
as well original directions for future research, such as quantifying the amount
of additional compute power that access to an APX oracle provides, elucidating
fundamental combinatorial properties of log-APX problems and unique ways to
attack the problem of whether the minimum set-cover problem is self-improvable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1&quot;&gt;Arthur Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Bruce Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01555">
<title>Likelihood-Free Inference in State-Space Models with Unknown Dynamics. (arXiv:2111.01555v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01555</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a method for inferring and predicting latent states in the
important and difficult case of state-space models where observations can only
be simulated, and transition dynamics are unknown. In this setting, the
likelihood of observations is not available and only synthetic observations can
be generated from a black-box simulator. We propose a way of doing
likelihood-free inference (LFI) of states and state prediction with a limited
number of simulations. Our approach uses a multi-output Gaussian process for
state inference, and a Bayesian Neural Network as a model of the transition
dynamics for state prediction. We improve upon existing LFI methods for the
inference task, while also accurately learning transition dynamics. The
proposed method is necessary for modelling inverse problems in dynamical
systems with computationally expensive simulations, as demonstrated in
experiments with non-stationary user models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aushev_A/0/1/0/all/0/1&quot;&gt;Alexander Aushev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Thong Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pesonen_H/0/1/0/all/0/1&quot;&gt;Henri Pesonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howes_A/0/1/0/all/0/1&quot;&gt;Andrew Howes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01556">
<title>Accounting for Dependencies in Deep Learning Based Multiple Instance Learning for Whole Slide Imaging. (arXiv:2111.01556v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01556</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a key algorithm for classification of
whole slide images (WSI). Histology WSIs can have billions of pixels, which
create enormous computational and annotation challenges. Typically, such images
are divided into a set of patches (a bag of instances), where only bag-level
class labels are provided. Deep learning based MIL methods calculate instance
features using convolutional neural network (CNN). Our proposed approach is
also deep learning based, with the following two contributions: Firstly, we
propose to explicitly account for dependencies between instances during
training by embedding self-attention Transformer blocks to capture dependencies
between instances. For example, a tumor grade may depend on the presence of
several particular patterns at different locations in WSI, which requires to
account for dependencies between patches. Secondly, we propose an instance-wise
loss function based on instance pseudo-labels. We compare the proposed
algorithm to multiple baseline methods, evaluate it on the PANDA challenge
dataset, the largest publicly available WSI dataset with over 11K images, and
demonstrate state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Myronenko_A/0/1/0/all/0/1&quot;&gt;Andriy Myronenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Ziyue Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Dong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roth_H/0/1/0/all/0/1&quot;&gt;Holger Roth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Daguang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01557">
<title>PointNu-Net: Simultaneous Multi-tissue Histology Nuclei Segmentation and Classification in the Clinical Wild. (arXiv:2111.01557v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01557</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic nuclei segmentation and classification plays a vital role in
digital pathology. However, previous works are mostly built on data with
limited diversity and small sizes, making the results questionable or
misleading in actual downstream tasks. In this paper, we aim to build a
reliable and robust method capable of dealing with data from the &apos;the clinical
wild&apos;. Specifically, we study and design a new method to simultaneously detect,
segment, and classify nuclei from Haematoxylin and Eosin (H&amp;amp;E) stained
histopathology data, and evaluate our approach using the recent largest
dataset: PanNuke. We address the detection and classification of each nuclei as
a novel semantic keypoint estimation problem to determine the center point of
each nuclei. Next, the corresponding class-agnostic masks for nuclei center
points are obtained using dynamic instance segmentation. By decoupling two
simultaneous challenging tasks, our method can benefit from class-aware
detection and class-agnostic segmentation, thus leading to a significant
performance boost. We demonstrate the superior performance of our proposed
approach for nuclei segmentation and classification across 19 different tissue
types, delivering new benchmark results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yao_K/0/1/0/all/0/1&quot;&gt;Kai Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaizhu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jie Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hussain_A/0/1/0/all/0/1&quot;&gt;Amir Hussain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jude_C/0/1/0/all/0/1&quot;&gt;Curran Jude&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01560">
<title>Efficient Learning of Quadratic Variance Function Directed Acyclic Graphs via Topological Layers. (arXiv:2111.01560v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01560</link>
<description rdf:parseType="Literal">&lt;p&gt;Directed acyclic graph (DAG) models are widely used to represent causal
relationships among random variables in many application domains. This paper
studies a special class of non-Gaussian DAG models, where the conditional
variance of each node given its parents is a quadratic function of its
conditional mean. Such a class of non-Gaussian DAG models are fairly flexible
and admit many popular distributions as special cases, including Poisson,
Binomial, Geometric, Exponential, and Gamma. To facilitate learning, we
introduce a novel concept of topological layers, and develop an efficient DAG
learning algorithm. It first reconstructs the topological layers in a
hierarchical fashion and then recoveries the directed edges between nodes in
different layers, which requires much less computational cost than most
existing algorithms in literature. Its advantage is also demonstrated in a
number of simulated examples, as well as its applications to two real-life
datasets, including an NBA player statistics data and a cosmetic sales data
collected by Alibaba.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1&quot;&gt;Wei Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junhui Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01561">
<title>Sub-cortical structure segmentation database for young population. (arXiv:2111.01561v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01561</link>
<description rdf:parseType="Literal">&lt;p&gt;Segmentation of sub-cortical structures from MRI scans is of interest in many
neurological diagnosis. Since this is a laborious task machine learning and
specifically deep learning (DL) methods have become explored. The structural
complexity of the brain demands a large, high quality segmentation dataset to
develop good DL-based solutions for sub-cortical structure segmentation.
Towards this, we are releasing a set of 114, 1.5 Tesla, T1 MRI scans with
manual delineations for 14 sub-cortical structures. The scans in the dataset
were acquired from healthy young (21-30 years) subjects ( 58 male and 56
female) and all the structures are manually delineated by experienced radiology
experts. Segmentation experiments have been conducted with this dataset and
results demonstrate that accurate results can be obtained with deep-learning
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sivaswamy_J/0/1/0/all/0/1&quot;&gt;Jayanthi Sivaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Thottupattu_A/0/1/0/all/0/1&quot;&gt;Alphin J Thottupattu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+V_M/0/1/0/all/0/1&quot;&gt;Mythri V&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mehta_R/0/1/0/all/0/1&quot;&gt;Raghav Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sheelakumari_R/0/1/0/all/0/1&quot;&gt;R Sheelakumari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kesavadas_C/0/1/0/all/0/1&quot;&gt;Chandrasekharan Kesavadas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01562">
<title>Evaluating deep transfer learning for whole-brain cognitive decoding. (arXiv:2111.01562v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2111.01562</link>
<description rdf:parseType="Literal">&lt;p&gt;Research in many fields has shown that transfer learning (TL) is well-suited
to improve the performance of deep learning (DL) models in datasets with small
numbers of samples. This empirical success has triggered interest in the
application of TL to cognitive decoding analyses with functional neuroimaging
data. Here, we systematically evaluate TL for the application of DL models to
the decoding of cognitive states (e.g., viewing images of faces or houses) from
whole-brain functional Magnetic Resonance Imaging (fMRI) data. We first
pre-train two DL architectures on a large, public fMRI dataset and subsequently
evaluate their performance in an independent experimental task and a fully
independent dataset. The pre-trained models consistently achieve higher
decoding accuracies and generally require less training time and data than
model variants that were not pre-trained, clearly underlining the benefits of
pre-training. We demonstrate that these benefits arise from the ability of the
pre-trained models to reuse many of their learned features when training with
new data, providing deeper insights into the mechanisms giving rise to the
benefits of pre-training. Yet, we also surface nuanced challenges for
whole-brain cognitive decoding with DL models when interpreting the decoding
decisions of the pre-trained models, as these have learned to utilize the fMRI
data in unforeseen and counterintuitive ways to identify individual cognitive
states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Thomas_A/0/1/0/all/0/1&quot;&gt;Armin W. Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lindenberger_U/0/1/0/all/0/1&quot;&gt;Ulman Lindenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01564">
<title>MultiplexNet: Towards Fully Satisfied Logical Constraints in Neural Networks. (arXiv:2111.01564v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01564</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel way to incorporate expert knowledge into the training of
deep neural networks. Many approaches encode domain constraints directly into
the network architecture, requiring non-trivial or domain-specific engineering.
In contrast, our approach, called MultiplexNet, represents domain knowledge as
a logical formula in disjunctive normal form (DNF) which is easy to encode and
to elicit from human experts. It introduces a Categorical latent variable that
learns to choose which constraint term optimizes the error function of the
network and it compiles the constraints directly into the output of existing
learning algorithms. We demonstrate the efficacy of this approach empirically
on several classical deep learning tasks, such as density estimation and
classification in both supervised and unsupervised settings where prior
knowledge about the domains was expressed as logical constraints. Our results
show that the MultiplexNet approach learned to approximate unknown
distributions well, often requiring fewer data samples than the alternative
approaches. In some cases, MultiplexNet finds better solutions than the
baselines; or solutions that could not be achieved with the alternative
approaches. Our contribution is in encoding domain knowledge in a way that
facilitates inference that is shown to be both efficient and general; and
critically, our approach guarantees 100% constraint satisfaction in a network&apos;s
output.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoernle_N/0/1/0/all/0/1&quot;&gt;Nicholas Hoernle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karampatsis_R/0/1/0/all/0/1&quot;&gt;Rafael Michael Karampatsis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belle_V/0/1/0/all/0/1&quot;&gt;Vaishak Belle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gal_K/0/1/0/all/0/1&quot;&gt;Kobi Gal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01566">
<title>Strategyproof and Proportionally Fair Facility Location. (arXiv:2111.01566v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2111.01566</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on a simple, one-dimensional collective decision problem (often
referred to as the facility location problem) and explore issues of
strategyproofness and proportional fairness. We present several
characterization results for mechanisms that satisfy strategyproofness and
varying levels of proportional fairness. We also characterize one of the
mechanisms as the unique equilibrium outcome for any mechanism that satisfies
natural fairness and monotonicity properties. Finally, we identify
strategyproof and proportionally fair mechanisms that provide the best
welfare-optimal approximation among all mechanisms that satisfy the
corresponding fairness axiom.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_H/0/1/0/all/0/1&quot;&gt;Haris Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1&quot;&gt;Alexander Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Barton E. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walsh_T/0/1/0/all/0/1&quot;&gt;Toby Walsh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01570">
<title>Privacy-Preserving Communication-Efficient Federated Multi-Armed Bandits. (arXiv:2111.01570v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01570</link>
<description rdf:parseType="Literal">&lt;p&gt;Communication bottleneck and data privacy are two critical concerns in
federated multi-armed bandit (MAB) problems, such as situations in
decision-making and recommendations of connected vehicles via wireless. In this
paper, we design the privacy-preserving communication-efficient algorithm in
such problems and study the interactions among privacy, communication and
learning performance in terms of the regret. To be specific, we design
privacy-preserving learning algorithms and communication protocols and derive
the learning regret when networked private agents are performing online bandit
learning in a master-worker, a decentralized and a hybrid structure. Our bandit
learning algorithms are based on epoch-wise sub-optimal arm eliminations at
each agent and agents exchange learning knowledge with the server/each other at
the end of each epoch. Furthermore, we adopt the differential privacy (DP)
approach to protect the data privacy at each agent when exchanging information;
and we curtail communication costs by making less frequent communications with
fewer agents participation. By analyzing the regret of our proposed algorithmic
framework in the master-worker, decentralized and hybrid structures, we
theoretically show tradeoffs between regret and communication costs/privacy.
Finally, we empirically show these trade-offs which are consistent with our
theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Linqi Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01576">
<title>Provably efficient, succinct, and precise explanations. (arXiv:2111.01576v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01576</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of explaining the predictions of an arbitrary
blackbox model $f$: given query access to $f$ and an instance $x$, output a
small set of $x$&apos;s features that in conjunction essentially determines $f(x)$.
We design an efficient algorithm with provable guarantees on the succinctness
and precision of the explanations that it returns. Prior algorithms were either
efficient but lacked such guarantees, or achieved such guarantees but were
inefficient.
&lt;/p&gt;
&lt;p&gt;We obtain our algorithm via a connection to the problem of {\sl implicitly}
learning decision trees. The implicit nature of this learning task allows for
efficient algorithms even when the complexity of $f$ necessitates an
intractably large surrogate decision tree. We solve the implicit learning
problem by bringing together techniques from learning theory, local computation
algorithms, and complexity theory.
&lt;/p&gt;
&lt;p&gt;Our approach of &quot;explaining by implicit learning&quot; shares elements of two
previously disparate methods for post-hoc explanations, global and local
explanations, and we make the case that it enjoys advantages of both.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1&quot;&gt;Guy Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1&quot;&gt;Jane Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1&quot;&gt;Li-Yang Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01577">
<title>Do Names Echo Semantics? A Large-Scale Study of Identifiers Used in C++&apos;s Named Casts. (arXiv:2111.01577v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2111.01577</link>
<description rdf:parseType="Literal">&lt;p&gt;Developers relax restrictions on a type to reuse methods with other types.
While type casts are prevalent, in weakly typed languages such as C++, they are
also extremely permissive. If type conversions are performed without care, they
can lead to software bugs. Therefore, there is a clear need to check whether a
type conversion is essential and used adequately according to the developer&apos;s
intent. In this paper, we propose a technique to judge the fidelity of type
conversions from an explicit cast operation, using the identifiers in an
assignment. We measure accord in the identifiers using entropy and use it to
check if the semantics of the source expression in the cast match the semantics
of the variable it is being assigned. We present the results of running our
tool on 34 components of the Chromium project, which collectively account for
27MLOC. Our tool identified 1,368 cases of discord indicating potential
anti-patterns in the usage of explicit casts. We performed a manual evaluation
of a random-uniform sample of these cases. Our evaluation shows that our tool
identified 25.6% cases representing incorrect implementations of named casts
and 28.04% cases representing imprecise names of identifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrescu_C/0/1/0/all/0/1&quot;&gt;Constantin Cezar Petrescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Sam Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giavrimis_R/0/1/0/all/0/1&quot;&gt;Rafail Giavrimis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1&quot;&gt;Santanu Kumar Dash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01582">
<title>LMdiff: A Visual Diff Tool to Compare Language Models. (arXiv:2111.01582v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01582</link>
<description rdf:parseType="Literal">&lt;p&gt;While different language models are ubiquitous in NLP, it is hard to contrast
their outputs and identify which contexts one can handle better than the other.
To address this question, we introduce LMdiff, a tool that visually compares
probability distributions of two models that differ, e.g., through finetuning,
distillation, or simply training with different parameter sizes. LMdiff allows
the generation of hypotheses about model behavior by investigating text
instances token by token and further assists in choosing these interesting text
instances by identifying the most interesting phrases from large corpora. We
showcase the applicability of LMdiff for hypothesis generation across multiple
case studies. A demo is available at &lt;a href=&quot;http://lmdiff.net&quot;&gt;this http URL&lt;/a&gt; .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strobelt_H/0/1/0/all/0/1&quot;&gt;Hendrik Strobelt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoover_B/0/1/0/all/0/1&quot;&gt;Benjamin Hoover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Satyanarayan_A/0/1/0/all/0/1&quot;&gt;Arvind Satyanarayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1&quot;&gt;Sebastian Gehrmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01584">
<title>Fitness Landscape Footprint: A Framework to Compare Neural Architecture Search Problems. (arXiv:2111.01584v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01584</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural architecture search is a promising area of research dedicated to
automating the design of neural network models. This field is rapidly growing,
with a surge of methodologies ranging from Bayesian optimization,neuroevoltion,
to differentiable search, and applications in various contexts. However,
despite all great advances, few studies have presented insights on the
difficulty of the problem itself, thus the success (or fail) of these
methodologies remains unexplained. In this sense, the field of optimization has
developed methods that highlight key aspects to describe optimization problems.
The fitness landscape analysis stands out when it comes to characterize
reliably and quantitatively search algorithms. In this paper, we propose to use
fitness landscape analysis to study a neural architecture search problem.
Particularly, we introduce the fitness landscape footprint, an aggregation of
eight (8)general-purpose metrics to synthesize the landscape of an architecture
search problem. We studied two problems, the classical image classification
benchmark CIFAR-10, and the Remote-Sensing problem So2Sat LCZ42. The results
present a quantitative appraisal of the problems, allowing to characterize the
relative difficulty and other characteristics, such as the ruggedness or the
persistence, that helps to tailor a search strategy to the problem. Also, the
footprint is a tool that enables the comparison of multiple problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Traore_K/0/1/0/all/0/1&quot;&gt;Kalifou Ren&amp;#xe9; Traor&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camero_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Camero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiao Xiang Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01585">
<title>Is RIS-Aided Massive MIMO Promising with ZF Detectors and Imperfect CSI?. (arXiv:2111.01585v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2111.01585</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides a theoretical framework for understanding the performance
of reconfigurable intelligent surface (RIS)-aided massive multiple-input
multiple-output (MIMO) with zero-forcing (ZF) detectors under imperfect channel
state information (CSI). We first propose a low-overhead minimum mean square
error (MMSE) channel estimator, and then derive and analyze closed-form
expressions for the uplink achievable rate. Our analytical results demonstrate
that: $1)$ regardless of the RIS phase shift design, the rate of all users
scales at least on the order of
$\mathcal{O}\left(\log_2\left(MN\right)\right)$, where $M$ and $N$ are the
numbers of antennas and reflecting elements, respectively; $2)$ by aligning the
RIS phase shifts to one user, the rate of this user can at most scale on the
order of $\mathcal{O}\left(\log_2\left(MN^2\right)\right)$; $3)$ either $M$ or
the transmit power can be reduced inversely proportional to $N$, while
maintaining a given rate. Furthermore, we propose two low-complexity
majorization-minimization (MM)-based algorithms to optimize the sum user rate
and the minimum user rate, respectively, where closed-form solutions are
obtained in each iteration. Finally, simulation results validate all derived
analytical results. Our simulation results also show that the maximum sum rate
can be closely approached by simply aligning the RIS phase shifts to an
arbitrary user.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhi_K/0/1/0/all/0/1&quot;&gt;Kangda Zhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1&quot;&gt;Cunhua Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Gui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Hong Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elkashlan_M/0/1/0/all/0/1&quot;&gt;Maged Elkashlan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schober_R/0/1/0/all/0/1&quot;&gt;Robert Schober&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01587">
<title>Procedural Generalization by Planning with Self-Supervised World Models. (arXiv:2111.01587v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01587</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the key promises of model-based reinforcement learning is the ability
to generalize using an internal model of the world to make predictions in novel
environments and tasks. However, the generalization ability of model-based
agents is not well understood because existing work has focused on model-free
agents when benchmarking generalization. Here, we explicitly measure the
generalization ability of model-based agents in comparison to their model-free
counterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a
powerful model-based agent, and evaluate its performance on both procedural and
task generalization. We identify three factors of procedural generalization --
planning, self-supervised representation learning, and procedural data
diversity -- and show that by combining these techniques, we achieve
state-of-the art generalization performance and data efficiency on Procgen
(Cobbe et al., 2019). However, we find that these factors do not always provide
the same benefits for the task generalization benchmarks in Meta-World (Yu et
al., 2019), indicating that transfer remains a challenge and may require
different approaches than procedural generalization. Overall, we suggest that
building generalizable agents requires moving beyond the single-task,
model-free paradigm and towards self-supervised model-based agents that are
trained in rich, procedural, multi-task environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1&quot;&gt;Ankesh Anand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1&quot;&gt;Jacob Walker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yazhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vertes_E/0/1/0/all/0/1&quot;&gt;Eszter V&amp;#xe9;rtes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schrittwieser_J/0/1/0/all/0/1&quot;&gt;Julian Schrittwieser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1&quot;&gt;Sherjil Ozair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;ophane Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01589">
<title>Nonstochastic Bandits and Experts with Arm-Dependent Delays. (arXiv:2111.01589v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01589</link>
<description rdf:parseType="Literal">&lt;p&gt;We study nonstochastic bandits and experts in a delayed setting where delays
depend on both time and arms. While the setting in which delays only depend on
time has been extensively studied, the arm-dependent delay setting better
captures real-world applications at the cost of introducing new technical
challenges. In the full information (experts) setting, we design an algorithm
with a first-order regret bound that reveals an interesting trade-off between
delays and losses. We prove a similar first-order regret bound also for the
bandit setting, when the learner is allowed to observe how many losses are
missing. These are the first bounds in the delayed setting that depend on the
losses and delays of the best arm only. When in the bandit setting no
information other than the losses is observed, we still manage to prove a
regret bound through a modification to the algorithm of Zimmert and Seldin
(2020). Our analyses hinge on a novel bound on the drift, measuring how much
better an algorithm can perform when given a look-ahead of one round.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoeven_D/0/1/0/all/0/1&quot;&gt;Dirk van der Hoeven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1&quot;&gt;Nicol&amp;#xf2; Cesa-Bianchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01590">
<title>Detect-and-Segment: a Deep Learning Approach to Automate Wound Image Segmentation. (arXiv:2111.01590v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01590</link>
<description rdf:parseType="Literal">&lt;p&gt;Chronic wounds significantly impact quality of life. If not properly managed,
they can severely deteriorate. Image-based wound analysis could aid in
objectively assessing the wound status by quantifying important features that
are related to healing. However, the high heterogeneity of the wound types,
image background composition, and capturing conditions challenge the robust
segmentation of wound images. We present Detect-and-Segment (DS), a deep
learning approach to produce wound segmentation maps with high generalization
capabilities. In our approach, dedicated deep neural networks detected the
wound position, isolated the wound from the uninformative background, and
computed the wound segmentation map. We evaluated this approach using one data
set with images of diabetic foot ulcers. For further testing, 4 supplemental
independent data sets with larger variety of wound types from different body
locations were used. The Matthews&apos; correlation coefficient (MCC) improved from
0.29 when computing the segmentation on the full image to 0.85 when combining
detection and segmentation in the same approach. When tested on the wound
images drawn from the supplemental data sets, the DS approach increased the
mean MCC from 0.17 to 0.85. Furthermore, the DS approach enabled the training
of segmentation models with up to 90% less training data while maintaining the
segmentation performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scebba_G/0/1/0/all/0/1&quot;&gt;Gaetano Scebba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catanzaro_S/0/1/0/all/0/1&quot;&gt;Sabrina Catanzaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihai_C/0/1/0/all/0/1&quot;&gt;Carina Mihai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Distler_O/0/1/0/all/0/1&quot;&gt;Oliver Distler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berli_M/0/1/0/all/0/1&quot;&gt;Martin Berli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlen_W/0/1/0/all/0/1&quot;&gt;Walter Karlen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01591">
<title>Estimating 3D Motion and Forces of Human-Object Interactions from Internet Videos. (arXiv:2111.01591v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01591</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a method to automatically reconstruct the 3D
motion of a person interacting with an object from a single RGB video. Our
method estimates the 3D poses of the person together with the object pose, the
contact positions and the contact forces exerted on the human body. The main
contributions of this work are three-fold. First, we introduce an approach to
jointly estimate the motion and the actuation forces of the person on the
manipulated object by modeling contacts and the dynamics of the interactions.
This is cast as a large-scale trajectory optimization problem. Second, we
develop a method to automatically recognize from the input video the 2D
position and timing of contacts between the person and the object or the
ground, thereby significantly simplifying the complexity of the optimization.
Third, we validate our approach on a recent video+MoCap dataset capturing
typical parkour actions, and demonstrate its performance on a new dataset of
Internet videos showing people manipulating a variety of tools in unconstrained
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zongmian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedlar_J/0/1/0/all/0/1&quot;&gt;Jiri Sedlar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carpentier_J/0/1/0/all/0/1&quot;&gt;Justin Carpentier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1&quot;&gt;Ivan Laptev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansard_N/0/1/0/all/0/1&quot;&gt;Nicolas Mansard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1&quot;&gt;Josef Sivic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01592">
<title>Trajectory Prediction with Graph-based Dual-scale Context Fusion. (arXiv:2111.01592v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01592</link>
<description rdf:parseType="Literal">&lt;p&gt;Motion prediction for traffic participants is essential for a safe and robust
automated driving system, especially in cluttered urban environments. However,
it is highly challenging due to the complex road topology as well as the
uncertain intentions of the other agents. In this paper, we present a
graph-based trajectory prediction network named the Dual Scale Predictor (DSP),
which encodes both the static and dynamical driving context in a hierarchical
manner. Different from methods based on a rasterized map or sparse lane graph,
we consider the driving context as a graph with two layers, focusing on both
geometrical and topological features. Graph neural networks (GNNs) are applied
to extract features with different levels of granularity, and features are
subsequently aggregated with attention-based inter-layer networks, realizing
better local-global feature fusion. Following the recent goal-driven trajectory
prediction pipeline, goal candidates with high likelihood for the target agent
are extracted, and predicted trajectories are generated conditioned on these
goals. Thanks to the proposed dual-scale context fusion network, our DSP is
able to generate accurate and human-like multi-modal trajectories. We evaluate
the proposed method on the large-scale Argoverse motion forecasting benchmark,
and it achieves promising results, outperforming the recent state-of-the-art
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peiliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1&quot;&gt;Shaojie Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01593">
<title>Design of Tight Minimum-Sidelobe Windows by Riemannian Newton&apos;s Method. (arXiv:2111.01593v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2111.01593</link>
<description rdf:parseType="Literal">&lt;p&gt;The short-time Fourier transform (STFT), or the discrete Gabor transform
(DGT), has been extensively used in signal analysis and processing. Their
properties are characterized by a window function, and hence window design is a
significant topic up to date. For signal processing, designing a pair of
analysis and synthesis windows is important because results of processing in
the time-frequency domain are affected by both of them. A tight window is a
special window that can perfectly reconstruct a signal by using it for both
analysis and synthesis. It is known to make time-frequency-domain processing
robust to error, and therefore designing a better tight window is desired. In
this paper, we propose a method of designing tight windows that minimize the
sidelobe energy. It is formulated as an optimization problem on an oblique
manifold, and a Riemannian Newton algorithm on this manifold is derived to
efficiently obtain a solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kitahara_D/0/1/0/all/0/1&quot;&gt;Daichi Kitahara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yatabe_K/0/1/0/all/0/1&quot;&gt;Kohei Yatabe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01594">
<title>Mean Field and Refined Mean Field Approximations for Heterogeneous Systems: It Works!. (arXiv:2111.01594v1 [cs.PF])</title>
<link>http://arxiv.org/abs/2111.01594</link>
<description rdf:parseType="Literal">&lt;p&gt;Mean field approximation is a powerful technique to study the performance of
large stochastic systems represented as $n$ interacting objects. Applications
include load balancing models, epidemic spreading, cache replacement policies,
or large-scale data centers. Mean field approximation is asymptotically exact
for systems composed of $n$ homogeneous objects under mild conditions. In this
paper, we study what happens when objects are heterogeneous. This can represent
servers with different speeds or contents with different popularities. We
define an interaction model that allows obtaining asymptotic convergence
results for stochastic systems with heterogeneous object behavior, and show
that the error of the mean field approximation is of order $O(1/n)$. More
importantly, we show how to adapt the refined mean field approximation,
developed by Gast et al. 2019, and show that the error of this approximation is
reduced to $O(1/n^2)$. To illustrate the applicability of our result, we
present two examples. The first addresses a list-based cache replacement model
RANDOM($m$), which is an extension of the RANDOM policy. The second is a
heterogeneous supermarket model. These examples show that the proposed
approximations are computationally tractable and very accurate. They also show
that for moderate system sizes ($n\approx30$) the refined mean field
approximation tends to be more accurate than simulations for any reasonable
simulation time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allmeier_S/0/1/0/all/0/1&quot;&gt;Sebastian Allmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gast_N/0/1/0/all/0/1&quot;&gt;Nicolas Gast&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01602">
<title>Stochastic Online Linear Regression: the Forward Algorithm to Replace Ridge. (arXiv:2111.01602v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01602</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of online linear regression in the stochastic
setting. We derive high probability regret bounds for online ridge regression
and the forward algorithm. This enables us to compare online regression
algorithms more accurately and eliminate assumptions of bounded observations
and predictions. Our study advocates for the use of the forward algorithm in
lieu of ridge due to its enhanced bounds and robustness to the regularization
parameter. Moreover, we explain how to integrate it in algorithms involving
linear function approximation to remove a boundedness assumption without
deteriorating theoretical bounds. We showcase this modification in linear
bandit settings where it yields improved regret bounds. Last, we provide
numerical experiments to illustrate our results and endorse our intuitions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouhamma_R/0/1/0/all/0/1&quot;&gt;Reda Ouhamma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maillard_O/0/1/0/all/0/1&quot;&gt;Odalric Maillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1&quot;&gt;Vianney Perchet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01604">
<title>A Critical Study on the Recent Deep Learning Based Semi-Supervised Video Anomaly Detection Methods. (arXiv:2111.01604v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01604</link>
<description rdf:parseType="Literal">&lt;p&gt;Video anomaly detection is one of the hot research topics in computer vision
nowadays, as abnormal events contain a high amount of information. Anomalies
are one of the main detection targets in surveillance systems, usually needing
real-time actions. Regarding the availability of labeled data for training
(i.e., there is not enough labeled data for abnormalities), semi-supervised
anomaly detection approaches have gained interest recently. This paper
introduces the researchers of the field to a new perspective and reviews the
recent deep-learning based semi-supervised video anomaly detection approaches,
based on a common strategy they use for anomaly detection. Our goal is to help
researchers develop more effective video anomaly detection methods. As the
selection of a right Deep Neural Network plays an important role for several
parts of this task, a quick comparative review on DNNs is prepared first.
Unlike previous surveys, DNNs are reviewed from a spatiotemporal feature
extraction viewpoint, customized for video anomaly detection. This part of the
review can help researchers in this field select suitable networks for
different parts of their methods. Moreover, some of the state-of-the-art
anomaly detection methods, based on their detection strategy, are critically
surveyed. The review provides a novel and deep look at existing methods and
results in stating the shortcomings of these approaches, which can be a hint
for future works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baradaran_M/0/1/0/all/0/1&quot;&gt;Mohammad Baradaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergevin_R/0/1/0/all/0/1&quot;&gt;Robert Bergevin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01605">
<title>Profit Sharing Contracts between Content and Service Providers for Enhanced Network Quality. (arXiv:2111.01605v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2111.01605</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been a long demand of Internet Service Providers (ISPs) that the
Content Providers (CPs) share their profits for investments in network
infrastructure. In this paper, we study profit sharing contracts between a CP
with multiple ISPs. Each ISP commits to improving the Quality of Service (QoS)
for the end-users through higher investments efforts. The CP agrees to share
the profits due to the resulting higher demand for its content. We first model
non-cooperative interaction between the CP and the ISPs as a two-stage
Stackelberg game. CP is the leader that decides what fraction of its profits
will be shared with the ISPs. Each ISP then simultaneously decides the amount
of effort (investment) to enhance network quality. Here, CP cannot observe
individual effort by the ISPs, which poses a challenge for the CP to decide how
to share the profits with each ISP. Therefore, we also investigate a
cooperative scenario, where the CP only decides the total share it gives to the
ISPs, and each ISP then cooperatively shares the profit among themselves. We
study the effect of such cooperation between the ISPs by building a Nash
Bargaining based model. We show that the collaboration improves total effort by
the ISPs and the payoff of the CP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_F/0/1/0/all/0/1&quot;&gt;Fehmina Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayel_M/0/1/0/all/0/1&quot;&gt;Manjesh K. Hanawal Yezekael Hayel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01606">
<title>PolyTrack: Tracking with Bounding Polygons. (arXiv:2111.01606v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01606</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a novel method called PolyTrack for fast
multi-object tracking and segmentation using bounding polygons. Polytrack
detects objects by producing heatmaps of their center keypoint. For each of
them, a rough segmentation is done by computing a bounding polygon over each
instance instead of the traditional bounding box. Tracking is done by taking
two consecutive frames as input and computing a center offset for each object
detected in the first frame to predict its location in the second frame. A
Kalman filter is also applied to reduce the number of ID switches. Since our
target application is automated driving systems, we apply our method on urban
environment videos. We trained and evaluated PolyTrack on the MOTS and
KITTIMOTS datasets. Results show that tracking polygons can be a good
alternative to bounding box and mask tracking. The code of PolyTrack is
available at https://github.com/gafaua/PolyTrack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faure_G/0/1/0/all/0/1&quot;&gt;Gaspar Faure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perreault_H/0/1/0/all/0/1&quot;&gt;Hughes Perreault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1&quot;&gt;Guillaume-Alexandre Bilodeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunier_N/0/1/0/all/0/1&quot;&gt;Nicolas Saunier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01616">
<title>OnSlicing: Online End-to-End Network Slicing with Reinforcement Learning. (arXiv:2111.01616v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2111.01616</link>
<description rdf:parseType="Literal">&lt;p&gt;Network slicing allows mobile network operators to virtualize infrastructures
and provide customized slices for supporting various use cases with
heterogeneous requirements. Online deep reinforcement learning (DRL) has shown
promising potential in solving network problems and eliminating the
simulation-to-reality discrepancy. Optimizing cross-domain resources with
online DRL is, however, challenging, as the random exploration of DRL violates
the service level agreement (SLA) of slices and resource constraints of
infrastructures. In this paper, we propose OnSlicing, an online end-to-end
network slicing system, to achieve minimal resource usage while satisfying
slices&apos; SLA. OnSlicing allows individualized learning for each slice and
maintains its SLA by using a novel constraint-aware policy update method and
proactive baseline switching mechanism. OnSlicing complies with resource
constraints of infrastructures by using a unique design of action modification
in slices and parameter coordination in infrastructures. OnSlicing further
mitigates the poor performance of online learning during the early learning
stage by offline imitating a rule-based solution. Besides, we design four new
domain managers to enable dynamic resource configuration in radio access,
transport, core, and edge networks, respectively, at a timescale of subseconds.
We implement OnSlicing on an end-to-end slicing testbed designed based on
OpenAirInterface with both 4G LTE and 5G NR, OpenDayLight SDN platform, and
OpenAir-CN core network. The experimental results show that OnSlicing achieves
61.3% usage reduction as compared to the rule-based solution and maintains
nearly zero violation (0.06%) throughout the online learning phase. As online
learning is converged, OnSlicing reduces 12.5% usage without any violations as
compared to the state-of-the-art online DRL solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_N/0/1/0/all/0/1&quot;&gt;Nakjung Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tao Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01619">
<title>StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN. (arXiv:2111.01619v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01619</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, StyleGAN has enabled various image manipulation and editing tasks
thanks to the high-quality generation and the disentangled latent space.
However, additional architectures or task-specific training paradigms are
usually required for different tasks. In this work, we take a deeper look at
the spatial properties of StyleGAN. We show that with a pretrained StyleGAN
along with some operations, without any additional architecture, we can perform
comparably to the state-of-the-art methods on various tasks, including image
blending, panorama generation, generation from a single image, controllable and
local multimodal image to image translation, and attributes transfer. The
proposed method is simple, effective, efficient, and applicable to any existing
pretrained StyleGAN model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1&quot;&gt;Min Jin Chong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hsin-Ying Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1&quot;&gt;David Forsyth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01622">
<title>Towards an Optimal Hybrid Algorithm for EV Charging Stations Placement using Quantum Annealing and Genetic Algorithms. (arXiv:2111.01622v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2111.01622</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum Annealing is a heuristic for solving optimization problems that have
seen a recent surge in usage owing to the success of D-Wave Systems. This paper
aims to find a good heuristic for solving the Electric Vehicle Charger
Placement (EVCP) problem, a problem that stands to be very important given the
costs of setting up an electric vehicle (EV) charger and the expected surge in
electric vehicles across the world. The same problem statement can also be
generalised to the optimal placement of any entity in a grid and can be
explored for further uses. Finally, the authors introduce a novel heuristic
combining Quantum Annealing and Genetic Algorithms to solve the problem. The
proposed hybrid approach entails seeding the genetic algorithm with the results
of a quantum annealer. Our experiments show this method decreases the minimum
distance from POIs by 42.89% compared to vanilla quantum annealing over our
sample EVCP datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chandra_A/0/1/0/all/0/1&quot;&gt;Aman Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lalwani_J/0/1/0/all/0/1&quot;&gt;Jitesh Lalwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jajodia_B/0/1/0/all/0/1&quot;&gt;Babita Jajodia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01623">
<title>A Tri-attention Fusion Guided Multi-modal Segmentation Network. (arXiv:2111.01623v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01623</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of multimodal segmentation, the correlation between different
modalities can be considered for improving the segmentation results.
Considering the correlation between different MR modalities, in this paper, we
propose a multi-modality segmentation network guided by a novel tri-attention
fusion. Our network includes N model-independent encoding paths with N image
sources, a tri-attention fusion block, a dual-attention fusion block, and a
decoding path. The model independent encoding paths can capture
modality-specific features from the N modalities. Considering that not all the
features extracted from the encoders are useful for segmentation, we propose to
use dual attention based fusion to re-weight the features along the modality
and space paths, which can suppress less informative features and emphasize the
useful ones for each modality at different positions. Since there exists a
strong correlation between different modalities, based on the dual attention
fusion block, we propose a correlation attention module to form the
tri-attention fusion block. In the correlation attention module, a correlation
description block is first used to learn the correlation between modalities and
then a constraint based on the correlation is used to guide the network to
learn the latent correlated features which are more relevant for segmentation.
Finally, the obtained fused feature representation is projected by the decoder
to obtain the segmentation results. Our experiment results tested on BraTS 2018
dataset for brain tumor segmentation demonstrate the effectiveness of our
proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tongxue Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruan_S/0/1/0/all/0/1&quot;&gt;Su Ruan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vera_P/0/1/0/all/0/1&quot;&gt;Pierre Vera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canu_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Canu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01625">
<title>Learning Robotic Ultrasound Scanning Skills via Human Demonstrations and Guided Explorations. (arXiv:2111.01625v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01625</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical ultrasound has become a routine examination approach nowadays and is
widely adopted for different medical applications, so it is desired to have a
robotic ultrasound system to perform the ultrasound scanning autonomously.
However, the ultrasound scanning skill is considerably complex, which highly
depends on the experience of the ultrasound physician. In this paper, we
propose a learning-based approach to learn the robotic ultrasound scanning
skills from human demonstrations. First, the robotic ultrasound scanning skill
is encapsulated into a high-dimensional multi-modal model, which takes the
ultrasound images, the pose/position of the probe and the contact force into
account. Second, we leverage the power of imitation learning to train the
multi-modal model with the training data collected from the demonstrations of
experienced ultrasound physicians. Finally, a post-optimization procedure with
guided explorations is proposed to further improve the performance of the
learned model. Robotic experiments are conducted to validate the advantages of
our proposed framework and the learned models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xutian Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Fei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Miao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01628">
<title>Human Attention in Fine-grained Classification. (arXiv:2111.01628v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01628</link>
<description rdf:parseType="Literal">&lt;p&gt;The way humans attend to, process and classify a given image has the
potential to vastly benefit the performance of deep learning models. Exploiting
where humans are focusing can rectify models when they are deviating from
essential features for correct decisions. To validate that human attention
contains valuable information for decision-making processes such as
fine-grained classification, we compare human attention and model explanations
in discovering important features. Towards this goal, we collect human gaze
data for the fine-grained classification dataset CUB and build a dataset named
CUB-GHA (Gaze-based Human Attention). Furthermore, we propose the Gaze
Augmentation Training (GAT) and Knowledge Fusion Network (KFN) to integrate
human gaze knowledge into classification models. We implement our proposals in
CUB-GHA and the recently released medical dataset CXR-Eye of chest X-ray
images, which includes gaze data collected from a radiologist. Our result
reveals that integrating human attention knowledge benefits classification
effectively, e.g. improving the baseline by 4.38% on CXR. Hence, our work
provides not only valuable insights into understanding human attention in
fine-grained classification, but also contributes to future research in
integrating human gaze with computer vision tasks. CUB-GHA and code are
available at https://github.com/yaorong0921/CUB-GHA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1&quot;&gt;Yao Rong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wenjia Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1&quot;&gt;Zeynep Akata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1&quot;&gt;Enkelejda Kasneci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01629">
<title>Accelerating Algebraic Multigrid Methods via Artificial Neural Networks. (arXiv:2111.01629v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01629</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel Deep Learning-based algorithm to accelerate - through the
use of Artificial Neural Networks (ANNs) - the convergence of Algebraic
Multigrid (AMG) methods for the iterative solution of the linear systems of
equations stemming from Finite Element discretizations of Partial Differential
Equations. We show that ANNs can be be successfully used to predict the strong
connection parameter that enters in the construction of the sequence of
increasingly smaller matrix problems standing at the basis of the AMG
algorithm, so as to maximize the corresponding convergence factor of the AMG
scheme. To demonstrate the practical capabilities of the proposed algorithm,
which we call AMG-ANN, we consider the iterative solution via the AMG method of
the algebraic system of equations stemming from Finite Element discretizations
of a two-dimensional elliptic equation with a highly heterogeneous diffusion
coefficient. We train (off-line) our ANN with a rich data-set and present an
in-depth analysis of the effects of tuning the strong threshold parameter on
the convergence factor of the resulting AMG iterative scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Antonietti_P/0/1/0/all/0/1&quot;&gt;Paola F. Antonietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Caldana_M/0/1/0/all/0/1&quot;&gt;Matteo Caldana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dede_L/0/1/0/all/0/1&quot;&gt;Luca Dede&amp;#x27;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01631">
<title>SO{U}RCERER: Developer-Driven Security Testing Framework for Android Apps. (arXiv:2111.01631v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2111.01631</link>
<description rdf:parseType="Literal">&lt;p&gt;Frequently advised secure development recommendations often fall short in
practice for app developers. Tool-driven (e.g., using static analysis tools)
approaches lack context and domain-specific requirements of an app being
tested. App developers struggle to find an actionable and prioritized list of
vulnerabilities from a laundry list of security warnings reported by static
analysis tools. Process-driven (e.g., applying threat modeling methods)
approaches require substantial resources (e.g., security testing team, budget)
and security expertise, which small to medium-scale app dev teams could barely
afford. To help app developers securing their apps, we propose SO{U}RCERER, a
guiding framework for Android app developers for security testing. SO{U}RCERER
guides developers to identify domain-specific assets of an app, detect and
prioritize vulnerabilities, and mitigate those vulnerabilities based on secure
development guidelines. We evaluated SO{U}RCERER with a case study on analyzing
and testing 36 Android mobile money apps. We found that by following activities
guided by SO{U}RCERER, an app developer could get a concise and actionable list
of vulnerabilities (24-61% fewer security warnings produced by SO{U}RCERER than
a standalone static analyzer), directly affecting a mobile money app&apos;s critical
assets, and devise a mitigation plan. Our findings from this preliminary study
indicate a viable approach to Android app security testing without being
overwhelmingly complex for app developers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;Muhammad Sajidur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cojusner_B/0/1/0/all/0/1&quot;&gt;Blas Cojusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kennedy_R/0/1/0/all/0/1&quot;&gt;Ryon Kennedy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_P/0/1/0/all/0/1&quot;&gt;Prerit Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1&quot;&gt;Lin Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1&quot;&gt;Byron Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01632">
<title>Elucidating Noisy Data via Uncertainty-Aware Robust Learning. (arXiv:2111.01632v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01632</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust learning methods aim to learn a clean target distribution from noisy
and corrupted training data where a specific corruption pattern is often
assumed a priori. Our proposed method can not only successfully learn the clean
target distribution from a dirty dataset but also can estimate the underlying
noise pattern. To this end, we leverage a mixture-of-experts model that can
distinguish two different types of predictive uncertainty, aleatoric and
epistemic uncertainty. We show that the ability to estimate the uncertainty
plays a significant role in elucidating the corruption patterns as these two
objectives are tightly intertwined. We also present a novel validation scheme
for evaluating the performance of the corruption pattern estimation. Our
proposed method is extensively assessed in terms of both robustness and
corruption pattern estimation through a number of domains, including computer
vision and natural language processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jeongeun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1&quot;&gt;Seungyoun Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Sangheum Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungjoon Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01633">
<title>Neural Program Generation Modulo Static Analysis. (arXiv:2111.01633v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01633</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art neural models of source code tend to be evaluated on the
generation of individual expressions and lines of code, and commonly fail on
long-horizon tasks such as the generation of entire method bodies. We propose
to address this deficiency using weak supervision from a static program
analyzer. Our neurosymbolic method allows a deep generative model to
symbolically compute, using calls to a static-analysis tool, long-distance
semantic relationships in the code that it has already generated. During
training, the model observes these relationships and learns to generate
programs conditioned on them. We apply our approach to the problem of
generating entire Java methods given the remainder of the class that contains
the method. Our experiments show that the approach substantially outperforms
state-of-the-art transformers and a model that explicitly tries to learn
program semantics on this task, both in terms of producing programs free of
basic semantic errors and in terms of syntactically matching the ground truth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1&quot;&gt;Rohan Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yeming Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhari_D/0/1/0/all/0/1&quot;&gt;Dipak Chaudhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reps_T/0/1/0/all/0/1&quot;&gt;Thomas W. Reps&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1&quot;&gt;Chris Jermaine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01634">
<title>Towards Enabling High-Five Over WiFi. (arXiv:2111.01634v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2111.01634</link>
<description rdf:parseType="Literal">&lt;p&gt;The next frontier for immersive applications is enabling sentience over the
Internet. Tactile Internet (TI) envisages transporting skills by providing
Ultra-Low Latency (ULL) communications for transporting touch senses. In this
work, we focus our study on the first/last mile communication, where the future
generation WiFi-7 is pitched as the front-runner for ULL applications. We
discuss a few candidate features of WiFi-7 and highlight its major pitfalls
with respect to ULL communication. Further, through a specific implementation
of WiFi-7 (vanilla WiFi-7) in our custom simulator, we demonstrate the impact
of one of the pitfalls - standard practice of using jitter buffer in
conjunction with frame aggregation - on TI communication. To circumvent this,
we propose Non-Buffered Scheme (NoBuS) - a simple MAC layer enhancement for
enabling TI applications on WiFi-7. NoBuS trades off packet loss for latency
enabling swift synchronization between the master and controlled domains. Our
findings reveal that employing NoBuS yields a significant improvement in RMSE
of TI signals. Further, we show that the worst-case WiFi latency with NoBuS is
3.72 ms - an order of magnitude lower than vanilla WiFi-7 even under highly
congested network conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokhale_V/0/1/0/all/0/1&quot;&gt;Vineet Gokhale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eid_M/0/1/0/all/0/1&quot;&gt;Mohamad Eid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kroep_K/0/1/0/all/0/1&quot;&gt;Kees Kroep&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prasad_R/0/1/0/all/0/1&quot;&gt;R. Venkatesha Prasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_V/0/1/0/all/0/1&quot;&gt;Vijay Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01635">
<title>Characterizing and Understanding the Generalization Error of Transfer Learning with Gibbs Algorithm. (arXiv:2111.01635v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01635</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide an information-theoretic analysis of the generalization ability of
Gibbs-based transfer learning algorithms by focusing on two popular transfer
learning approaches, $\alpha$-weighted-ERM and two-stage-ERM. Our key result is
an exact characterization of the generalization behaviour using the conditional
symmetrized KL information between the output hypothesis and the target
training samples given the source samples. Our results can also be applied to
provide novel distribution-free generalization error upper bounds on these two
aforementioned Gibbs algorithms. Our approach is versatile, as it also
characterizes the generalization errors and excess risks of these two Gibbs
algorithms in the asymptotic regime, where they converge to the
$\alpha$-weighted-ERM and two-stage-ERM, respectively. Based on our theoretical
results, we show that the benefits of transfer learning can be viewed as a
bias-variance trade-off, with the bias induced by the source distribution and
the variance induced by the lack of target samples. We believe this viewpoint
can guide the choice of transfer learning algorithms in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1&quot;&gt;Yuheng Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aminian_G/0/1/0/all/0/1&quot;&gt;Gholamali Aminian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toni_L/0/1/0/all/0/1&quot;&gt;Laura Toni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1&quot;&gt;Miguel Rodrigues&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wornell_G/0/1/0/all/0/1&quot;&gt;Gregory Wornell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01638">
<title>A Finite Characterization of Perfect Equilibria. (arXiv:2111.01638v1 [econ.TH])</title>
<link>http://arxiv.org/abs/2111.01638</link>
<description rdf:parseType="Literal">&lt;p&gt;Govindan and Klumpp [7] provided a characterization of perfect equilibria
using Lexicographic Probability Systems (LPSs). Their characterization was
essentially finite in that they showed that there exists a finite bound on the
number of levels in the LPS, but they did not compute it explicitly. In this
note, we draw on two recent developments in Real Algebraic Geometry to obtain a
formula for this bound.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Callejas_I/0/1/0/all/0/1&quot;&gt;Ivonne Callejas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Govindan_S/0/1/0/all/0/1&quot;&gt;Srihari Govindan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Pahl_L/0/1/0/all/0/1&quot;&gt;Lucas Pahl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01645">
<title>Energy and Resource Efficiency by User Traffic Prediction and Classification in Cellular Networks. (arXiv:2111.01645v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01645</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a lack of research on the analysis of per-user traffic in cellular
networks, for deriving and following traffic-aware network management.
\textcolor{black}{In fact, the legacy design approach, in which resource
provisioning and operation control are performed based on the cell-aggregated
traffic scenarios, are not so energy- and cost-efficient and need to be
substituted with user-centric predictive analysis of mobile network traffic and
proactive network resource management.} Here, we shed light on this problem by
designing traffic prediction tools that utilize standard machine learning (ML)
tools, including long short-term memory (LSTM) and autoregressive integrated
moving average (ARIMA) on top of per-user data. We present an expansive
empirical evaluation of the designed solutions over a real network traffic
dataset. Within this analysis, the impact of different parameters, such as the
time granularity, the length of future predictions, and feature selection are
investigated. As a potential application of these solutions, we present an
ML-powered Discontinuous reception (DRX) scheme for energy saving. Towards this
end, we leverage the derived ML models for dynamic DRX parameter adaptation to
user traffic. The performance evaluation results demonstrate the superiority of
LSTM over ARIMA in general, especially when the length of the training time
series is high enough, and it is augmented by a \textit{wisely}-selected set of
features. Furthermore, the results show that adaptation of DRX parameters by
online prediction of future traffic provides much more energy-saving at low
latency cost in comparison with the legacy cell-wide DRX parameter adaptation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Azari_A/0/1/0/all/0/1&quot;&gt;Amin Azari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Salehi_F/0/1/0/all/0/1&quot;&gt;Fateme Salehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Papapetrou_P/0/1/0/all/0/1&quot;&gt;Panagiotis Papapetrou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cavdar_C/0/1/0/all/0/1&quot;&gt;Cicek Cavdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01647">
<title>Information Spillover in Multiple Zero-sum Games. (arXiv:2111.01647v1 [econ.TH])</title>
<link>http://arxiv.org/abs/2111.01647</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers an infinitely repeated three-player Bayesian game with
lack of information on two sides, in which an informed player plays two
zero-sum games simultaneously at each stage against two uninformed players.
This is a generalization of the Aumann et al. [1] two-player zero-sum one-sided
incomplete information model. Under a correlated prior, the informed player
faces the problem of how to optimally disclose information among two uninformed
players in order to maximize his long-term average payoffs. Our objective is to
understand the adverse effects of \information spillover&quot; from one game to the
other in the equilibrium payoff set of the informed player. We provide
conditions under which the informed player can fully overcome such adverse
effects and characterize equilibrium payoffs. In a second result, we show how
the effects of information spillover on the equilibrium payoff set of the
informed player might be severe.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Pahl_L/0/1/0/all/0/1&quot;&gt;Lucas Pahl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01652">
<title>Design and Evaluation of Active Noise Control on Machinery Noise. (arXiv:2111.01652v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2111.01652</link>
<description rdf:parseType="Literal">&lt;p&gt;Construction workers and residents live near around construction sites are
exposed to noises that might cause hearing loss, high blood pressure, heart
disease, sleep disturbance and stress. Regulations has been carried out by
national governments to limit the maximum permissible noise levels for
construction works. A four-channel active noise control system mounted on the
opening of an enclosure is designed to prevent the machinery noise from
spreading around and retaining the heat diffusion path. Multi-channel FxLMS
algorithm in time domain is implemented on the main controller. A Genelec
speaker is placed inside the box as the primary noise source to play back
different types of noises. Analyses and experiments are carried out to
investigate the controllable frequency range of this ANC system in detail.
Considerable noise reduction performance is achieved for different recorded
practical construction noises.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wen_S/0/1/0/all/0/1&quot;&gt;Shulin Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duy Hai Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Miqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gan_W/0/1/0/all/0/1&quot;&gt;Woon-Seng Gan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01654">
<title>Modeling and Automating Public Announcement Logic with Rela\-tivized Common Knowledge as a Fragment of HOL in LogiKEy. (arXiv:2111.01654v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01654</link>
<description rdf:parseType="Literal">&lt;p&gt;A shallow semantical embedding for public announcement logic with relativized
common knowledge is presented. This embedding enables the first-time automation
of this logic with off-the-shelf theorem provers for classical higher-order
logic. It is demonstrated (i) how meta-theoretical studies can be automated
this way, and (ii) how non-trivial reasoning in the target logic (public
announcement logic), required e.g. to obtain a convincing encoding and
automation of the wise men puzzle, can be realized.
&lt;/p&gt;
&lt;p&gt;Key to the presented semantical embedding is that evaluation domains are
modeled explicitly and treated as an additional parameter in the encodings of
the constituents of the embedded target logic; in previous related works, e.g.
on the embedding of normal modal logics, evaluation domains were implicitly
shared between meta-logic and target logic.
&lt;/p&gt;
&lt;p&gt;The work presented in this article constitutes an important addition to the
pluralist \logikey\ knowledge engineering methodology, which enables
experimentation with logics and their combinations, with general and domain
knowledge, and with concrete use cases -- all at the same time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benzmuller_C/0/1/0/all/0/1&quot;&gt;Christoph Benzm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiche_S/0/1/0/all/0/1&quot;&gt;Sebastian Reiche&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01657">
<title>LogLAB: Attention-Based Labeling of Log Data Anomalies via Weak Supervision. (arXiv:2111.01657v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01657</link>
<description rdf:parseType="Literal">&lt;p&gt;With increasing scale and complexity of cloud operations, automated detection
of anomalies in monitoring data such as logs will be an essential part of
managing future IT infrastructures. However, many methods based on artificial
intelligence, such as supervised deep learning models, require large amounts of
labeled training data to perform well. In practice, this data is rarely
available because labeling log data is expensive, time-consuming, and requires
a deep understanding of the underlying system. We present LogLAB, a novel
modeling approach for automated labeling of log messages without requiring
manual work by experts. Our method relies on estimated failure time windows
provided by monitoring systems to produce precise labeled datasets in
retrospect. It is based on the attention mechanism and uses a custom objective
function for weak supervision deep learning techniques that accounts for
imbalanced data. Our evaluation shows that LogLAB consistently outperforms nine
benchmark approaches across three different datasets and maintains an F1-score
of more than 0.98 even at large failure time windows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wittkopp_T/0/1/0/all/0/1&quot;&gt;Thorsten Wittkopp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiesner_P/0/1/0/all/0/1&quot;&gt;Philipp Wiesner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheinert_D/0/1/0/all/0/1&quot;&gt;Dominik Scheinert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acker_A/0/1/0/all/0/1&quot;&gt;Alexander Acker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01662">
<title>OSOA: One-Shot Online Adaptation of Deep Generative Models for Lossless Compression. (arXiv:2111.01662v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01662</link>
<description rdf:parseType="Literal">&lt;p&gt;Explicit deep generative models (DGMs), e.g., VAEs and Normalizing Flows,
have shown to offer an effective data modelling alternative for lossless
compression. However, DGMs themselves normally require large storage space and
thus contaminate the advantage brought by accurate data density estimation. To
eliminate the requirement of saving separate models for different target
datasets, we propose a novel setting that starts from a pretrained deep
generative model and compresses the data batches while adapting the model with
a dynamical system for only one epoch. We formalise this setting as that of
One-Shot Online Adaptation (OSOA) of DGMs for lossless compression and propose
a vanilla algorithm under this setting. Experimental results show that vanilla
OSOA can save significant time versus training bespoke models and space versus
using one model for all targets. With the same adaptation step number or
adaptation time, it is shown vanilla OSOA can exhibit better space efficiency,
e.g., $47\%$ less space, than fine-tuning the pretrained model and saving the
fine-tuned model. Moreover, we showcase the potential of OSOA and motivate more
sophisticated OSOA algorithms by showing further space or time efficiency with
multiple updates per batch and early stopping.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shifeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlucci_F/0/1/0/all/0/1&quot;&gt;Fabio Maria Carlucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenguo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01663">
<title>Classification of Goods Using Text Descriptions With Sentences Retrieval. (arXiv:2111.01663v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01663</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of assigning and validating internationally accepted commodity code
(HS code) to traded goods is one of the critical functions at the customs
office. This decision is crucial to importers and exporters, as it determines
the tariff rate. However, similar to court decisions made by judges, the task
can be non-trivial even for experienced customs officers. The current paper
proposes a deep learning model to assist this seemingly challenging HS code
classification. Together with Korea Customs Service, we built a decision model
based on KoELECTRA that suggests the most likely heading and subheadings (i.e.,
the first four and six digits) of the HS code. Evaluation on 129,084 past cases
shows that the top-3 suggestions made by our model have an accuracy of 95.5% in
classifying 265 subheadings. This promising result implies algorithms may
reduce the time and effort taken by customs officers substantially by assisting
the HS code classification task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1&quot;&gt;Eunji Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sundong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sihyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sungwon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1&quot;&gt;Meeyoung Cha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1&quot;&gt;Soyeon Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Suyoung Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Yeonsoo Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Sungdae Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Minsoo Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Heeja Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01665">
<title>Explainable Medical Image Segmentation via Generative Adversarial Networks and Layer-wise Relevance Propagation. (arXiv:2111.01665v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01665</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper contributes to automating medical image segmentation by proposing
generative adversarial network-based models to segment both polyps and
instruments in endoscopy images. A major contribution of this work is to
provide explanations for the predictions using a layer-wise relevance
propagation approach designating which input image pixels are relevant to the
predictions and to what extent. On the polyp segmentation task, the models
achieved 0.84 of accuracy and 0.46 on Jaccard index. On the instrument
segmentation task, the models achieved 0.96 of accuracy and 0.70 on Jaccard
index. The code is available at https://github.com/Awadelrahman/MedAI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ahmed_A/0/1/0/all/0/1&quot;&gt;Awadelrahman M. A. Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ali_L/0/1/0/all/0/1&quot;&gt;Leen A. M. Ali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01667">
<title>International Comparative Studies on the Software Testing Profession. (arXiv:2111.01667v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2111.01667</link>
<description rdf:parseType="Literal">&lt;p&gt;This work attempts to fill a gap by exploring the human dimension in
particular, by trying to understand the motivation of software professionals
for taking up and sustaining their careers as software testers. Towards that
goal, four surveys were conducted in four countries - India, Canada, Cuba, and
China - to try to understand how professional software engineers perceive and
value work-related factors that could influence their motivation to start or
move into software testing careers. From our sample of 220 software
professionals, we observed that very few were keen to take up testing careers.
Some aspects of software testing, such as the potential for learning
opportunities and the importance of the job, appear to be common motivators
across the four countries, whereas the treatment of testers as second-class
citizens and the complexity of the job appeared to be the most prominent
de-motivators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capretz_L/0/1/0/all/0/1&quot;&gt;Luiz Fernando Capretz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waychal_P/0/1/0/all/0/1&quot;&gt;Pradeep Waychal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jingdong Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lizama_Y/0/1/0/all/0/1&quot;&gt;Yadira Lizama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varona_D/0/1/0/all/0/1&quot;&gt;Daniel Varona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01673">
<title>Relational Self-Attention: What&apos;s Missing in Attention for Video Understanding. (arXiv:2111.01673v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01673</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolution has been arguably the most important feature transform for modern
neural networks, leading to the advance of deep learning. Recent emergence of
Transformer networks, which replace convolution layers with self-attention
blocks, has revealed the limitation of stationary convolution kernels and
opened the door to the era of dynamic feature transforms. The existing dynamic
transforms, including self-attention, however, are all limited for video
understanding where correspondence relations in space and time, i.e., motion
information, are crucial for effective representation. In this work, we
introduce a relational feature transform, dubbed the relational self-attention
(RSA), that leverages rich structures of spatio-temporal relations in videos by
dynamically generating relational kernels and aggregating relational contexts.
Our experiments and ablation studies show that the RSA network substantially
outperforms convolution and self-attention counterparts, achieving the state of
the art on the standard motion-centric benchmarks for video action recognition,
such as Something-Something-V1 &amp;amp; V2, Diving48, and FineGym.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Manjin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1&quot;&gt;Heeseung Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1&quot;&gt;Suha Kwak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1&quot;&gt;Minsu Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01674">
<title>Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged Robots. (arXiv:2111.01674v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01674</link>
<description rdf:parseType="Literal">&lt;p&gt;Legged locomotion is commonly studied and expressed as a discrete set of gait
patterns, like walk, trot, gallop, which are usually treated as given and
pre-programmed in legged robots for efficient locomotion at different speeds.
However, fixing a set of pre-programmed gaits limits the generality of
locomotion. Recent animal motor studies show that these conventional gaits are
only prevalent in ideal flat terrain conditions while real-world locomotion is
unstructured and more like bouts of intermittent steps. What principles could
lead to both structured and unstructured patterns across mammals and how to
synthesize them in robots? In this work, we take an analysis-by-synthesis
approach and learn to move by minimizing mechanical energy. We demonstrate that
learning to minimize energy consumption plays a key role in the emergence of
natural locomotion gaits at different speeds in real quadruped robots. The
emergent gaits are structured in ideal terrains and look similar to that of
horses and sheep. The same approach leads to unstructured gaits in rough
terrains which is consistent with the findings in animal motor control. We
validate our hypothesis in both simulation and real hardware across natural
terrains. Videos at https://energy-locomotion.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zipeng Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Ashish Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01676">
<title>Towards text-based phishing detection. (arXiv:2111.01676v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01676</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper reports on an experiment into text-based phishing detection using
readily available resources and without the use of semantics. The developed
algorithm is a modified version of previously published work that works with
the same tools. The results obtained in recognizing phishing emails are
considerably better than the previously reported work; but the rate of text
falsely identified as phishing is slightly worse. It is expected that adding
semantic component will reduce the false positive rate while preserving the
detection accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_G/0/1/0/all/0/1&quot;&gt;Gilchan Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_J/0/1/0/all/0/1&quot;&gt;Julia M. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01677">
<title>Top1 Solution of QQ Browser 2021 Ai Algorithm Competition Track 1 : Multimodal Video Similarity. (arXiv:2111.01677v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01677</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe the solution to the QQ Browser 2021 Ai Algorithm
Competition (AIAC) Track 1. We use the multi-modal transformer model for the
video embedding extraction. In the pretrain phase, we train the model with
three tasks, (1) Video Tag Classification (VTC), (2) Mask Language Modeling
(MLM) and (3) Mask Frame Modeling (MFM). In the finetune phase, we train the
model with video similarity based on rank normalized human labels. Our full
pipeline, after ensembling several models, scores 0.852 on the leaderboard,
which we achieved the 1st place in the competition. The source codes have been
released at Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_M/0/1/0/all/0/1&quot;&gt;Majing Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1&quot;&gt;Xuan Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01681">
<title>Saliency detection with moving camera via background model completion. (arXiv:2111.01681v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01681</link>
<description rdf:parseType="Literal">&lt;p&gt;To detect saliency in video is a fundamental step in many computer vision
systems. Saliency is the significant target(s) in the video. The object of
interest is further analyzed for high-level applications. The segregation of
saliency and the background can be made if they exhibit different visual cues.
Therefore, saliency detection is often formulated as background subtraction.
However, saliency detection is challenging. For instance, dynamic background
can result in false positive errors. In another scenario, camouflage will lead
to false negative errors. With moving camera, the captured scenes are even more
complicated to handle. We propose a new framework, called saliency detection
via background model completion (SD-BMC), that comprises of a background
modeler and the deep learning background/foreground segmentation network. The
background modeler generates an initial clean background image from a short
image sequence. Based on the idea of video completion, a good background frame
can be synthesized with the co-existence of changing background and moving
objects. We adopt the background/foreground segmenter, although pre-trained
with a specific video dataset, can also detect saliency in unseen videos. The
background modeler can adjust the background image dynamically when the
background/foreground segmenter output deteriorates during processing of a long
video. To the best of our knowledge, our framework is the first one to adopt
video completion for background modeling and saliency detection in videos
captured by moving camera. The results, obtained from the PTZ videos, show that
our proposed framework outperforms some deep learning-based background
subtraction models by 11% or more. With more challenging videos, our framework
also outperforms many high ranking background subtraction methods by more than
3%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yupei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1&quot;&gt;Kwok-Leung Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01682">
<title>Progressive observation of Covid-19 vaccination effects on skin-cellular structures by use of Intelligent Laser Speckle Classification (ILSC). (arXiv:2111.01682v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2111.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;We have made a progressive observation of Covid-19 Astra Zeneca Vaccination
effect on Skin cellular network and properties by use of well established
Intelligent Laser Speckle Classification (ILSC) image based technique and
managed to distinguish between three different subjects groups via their laser
speckle skin image samplings such as early-vaccinated, late-vaccinated and
non-vaccinated individuals. The results have proven that the ILSC technique in
association with the optimised Bayesian network is capable of classifying skin
changes of vaccinated and non-vaccinated individuals and also of detecting
progressive development made on skin cellular properties for a month period.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Orun_A/0/1/0/all/0/1&quot;&gt;Ahmet Orun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kurugollu_F/0/1/0/all/0/1&quot;&gt;Fatih Kurugollu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01683">
<title>Using Synthetic Images To Uncover Population Biases In Facial Landmarks Detection. (arXiv:2111.01683v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01683</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to analyze a trained model performance and identify its weak spots,
one has to set aside a portion of the data for testing. The test set has to be
large enough to detect statistically significant biases with respect to all the
relevant sub-groups in the target population. This requirement may be difficult
to satisfy, especially in data-hungry applications. We propose to overcome this
difficulty by generating synthetic test set. We use the face landmarks
detection task to validate our proposal by showing that all the biases observed
on real datasets are also seen on a carefully designed synthetic dataset. This
shows that synthetic test sets can efficiently detect a model&apos;s weak spots and
overcome limitations of real test set in terms of quantity and/or diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shadmi_R/0/1/0/all/0/1&quot;&gt;Ran Shadmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laserson_J/0/1/0/all/0/1&quot;&gt;Jonathan Laserson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elbaz_G/0/1/0/all/0/1&quot;&gt;Gil Elbaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01684">
<title>Rethinking the Knowledge Distillation From the Perspective of Model Calibration. (arXiv:2111.01684v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01684</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed dramatically improvements in the knowledge
distillation, which can generate a compact student model for better efficiency
while retaining the model effectiveness of the teacher model. Previous studies
find that: more accurate teachers do not necessary make for better teachers due
to the mismatch of abilities. In this paper, we aim to analysis the phenomenon
from the perspective of model calibration. We found that the larger teacher
model may be too over-confident, thus the student model cannot effectively
imitate. While, after the simple model calibration of the teacher model, the
size of the teacher model has a positive correlation with the performance of
the student model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lehan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jincen Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01689">
<title>Improving Classifier Training Efficiency for Automatic Cyberbullying Detection with Feature Density. (arXiv:2111.01689v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01689</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the effectiveness of Feature Density (FD) using different
linguistically-backed feature preprocessing methods in order to estimate
dataset complexity, which in turn is used to comparatively estimate the
potential performance of machine learning (ML) classifiers prior to any
training. We hypothesise that estimating dataset complexity allows for the
reduction of the number of required experiments iterations. This way we can
optimize the resource-intensive training of ML models which is becoming a
serious issue due to the increases in available dataset sizes and the ever
rising popularity of models based on Deep Neural Networks (DNN). The problem of
constantly increasing needs for more powerful computational resources is also
affecting the environment due to alarmingly-growing amount of CO2 emissions
caused by training of large-scale ML models. The research was conducted on
multiple datasets, including popular datasets, such as Yelp business review
dataset used for training typical sentiment analysis models, as well as more
recent datasets trying to tackle the problem of cyberbullying, which, being a
serious social problem, is also a much more sophisticated problem form the
point of view of linguistic representation. We use cyberbullying datasets
collected for multiple languages, namely English, Japanese and Polish. The
difference in linguistic complexity of datasets allows us to additionally
discuss the efficacy of linguistically-backed word preprocessing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eronen_J/0/1/0/all/0/1&quot;&gt;Juuso Eronen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ptaszynski_M/0/1/0/all/0/1&quot;&gt;Michal Ptaszynski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masui_F/0/1/0/all/0/1&quot;&gt;Fumito Masui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pohl_A/0/1/0/all/0/1&quot;&gt;Aleksander Pohl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leliwa_G/0/1/0/all/0/1&quot;&gt;Gniewosz Leliwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wroczynski_M/0/1/0/all/0/1&quot;&gt;Michal Wroczynski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01690">
<title>Recent Advances in End-to-End Automatic Speech Recognition. (arXiv:2111.01690v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2111.01690</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the speech community is seeing a significant trend of moving from
deep neural network based hybrid modeling to end-to-end (E2E) modeling for
automatic speech recognition (ASR). While E2E models achieve the
state-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid
models are still used in a large proportion of commercial ASR systems at the
current time. There are lots of practical factors that affect the production
model deployment decision. Traditional hybrid models, being optimized for
production for decades, are usually good at these factors. Without providing
excellent solutions to all these factors, it is hard for E2E models to be
widely commercialized. In this paper, we will overview the recent advances in
E2E models, focusing on technologies addressing those challenges from the
industry&apos;s perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jinyu Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01692">
<title>Efficient hierarchical Bayesian inference for spatio-temporal regression models in neuroimaging. (arXiv:2111.01692v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01692</link>
<description rdf:parseType="Literal">&lt;p&gt;Several problems in neuroimaging and beyond require inference on the
parameters of multi-task sparse hierarchical regression models. Examples
include M/EEG inverse problems, neural encoding models for task-based fMRI
analyses, and temperature monitoring of climate or CPU and GPU. In these
domains, both the model parameters to be inferred and the measurement noise may
exhibit a complex spatio-temporal structure. Existing work either neglects the
temporal structure or leads to computationally demanding inference schemes.
Overcoming these limitations, we devise a novel flexible hierarchical Bayesian
framework within which the spatio-temporal dynamics of model parameters and
noise are modeled to have Kronecker product covariance structure. Inference in
our framework is based on majorization-minimization optimization and has
guaranteed convergence properties. Our highly efficient algorithms exploit the
intrinsic Riemannian geometry of temporal autocovariance matrices. For
stationary dynamics described by Toeplitz matrices, the theory of circulant
embeddings is employed. We prove convex bounding properties and derive update
rules of the resulting algorithms. On both synthetic and real neural data from
M/EEG, we demonstrate that our methods lead to improved performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hashemi_A/0/1/0/all/0/1&quot;&gt;Ali Hashemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yijing Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cai_C/0/1/0/all/0/1&quot;&gt;Chang Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Sanjay Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagarajan_S/0/1/0/all/0/1&quot;&gt;Srikantan S. Nagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Haufe_S/0/1/0/all/0/1&quot;&gt;Stefan Haufe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01694">
<title>Small-Signal Stability Techniques for Power System Modal Analysis, Control, and Numerical Integration. (arXiv:2111.01694v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2111.01694</link>
<description rdf:parseType="Literal">&lt;p&gt;This thesis proposes novel Small-Signal Stability Analysis (SSSA)-based
techniques that contribute to electric power system modal analysis, automatic
control, and numerical integration. Modal analysis is a fundamental tool for
power system stability analysis and control. The thesis proposes a SSSA
approach to determine the Participation Factors (PFs) of algebraic variables in
power system dynamic modes. The thesis also explores SSSA techniques for the
design of power system controllers. The contributions on this topic are
twofold: i) Investigate a promising control approach, that is to synthesize
automatic regulators for power systems based on the theory of fractional
calculus. ii) Propose a novel perspective on the potential impact of time
delays on power system stability. Through SSSA, the thesis systematically
identifies the control parameter settings for which delays in PSSs improve the
damping of a power system. Both analytical and simulation-based results are
presented. Finally, SSSA is utilized in the thesis to systematically propose a
delay-based method to reduce the coupling of the equations of power system
models for transient stability analysis. The method consists in identifying the
variables that, when subjected to a delay equal to the time step of the
numerical integration, leave practically unchanged the system trajectories.
Such an one-step-delay approximation increases the sparsity of the system
Jacobian matrices and can be used in conjunction with state-of-the-art
techniques for the integration of DAEs. The proposed approach is evaluated in
terms of accuracy, convergence and computational burden. Throughout the thesis,
the proposed techniques are duly validated through numerical tests based on
real-world network models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tzounas_G/0/1/0/all/0/1&quot;&gt;Georgios Tzounas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01697">
<title>Low-Rank+Sparse Tensor Compression for Neural Networks. (arXiv:2111.01697v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-rank tensor compression has been proposed as a promising approach to
reduce the memory and compute requirements of neural networks for their
deployment on edge devices. Tensor compression reduces the number of parameters
required to represent a neural network weight by assuming network weights
possess a coarse higher-order structure. This coarse structure assumption has
been applied to compress large neural networks such as VGG and ResNet. However
modern state-of-the-art neural networks for computer vision tasks (i.e.
MobileNet, EfficientNet) already assume a coarse factorized structure through
depthwise separable convolutions, making pure tensor decomposition a less
attractive approach. We propose to combine low-rank tensor decomposition with
sparse pruning in order to take advantage of both coarse and fine structure for
compression. We compress weights in SOTA architectures (MobileNetv3,
EfficientNet, Vision Transformer) and compare this approach to sparse pruning
and tensor decomposition alone.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hawkins_C/0/1/0/all/0/1&quot;&gt;Cole Hawkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haichuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Meng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01701">
<title>Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters from Extremum Seeking Control. (arXiv:2111.01701v1 [math.OC])</title>
<link>http://arxiv.org/abs/2111.01701</link>
<description rdf:parseType="Literal">&lt;p&gt;Single-point zeroth-order optimization (SZO) is suitable for solving online
black-box optimization and simulation-based learning-to-control problems.
However, the vanilla SZO method suffers from a larger variance and slow
convergence, which seriously limits its practical application. On the other
hand, extremum seeking (ES) control is regarded as the continuous-time version
of SZO, while they have been mostly studied separately in the control and
optimization communities despite the close relation. In this work, we borrow
the idea of high-pass and low-pass filters from ES control to improve the
performance of SZO. Specifically, we develop a novel SZO method called HLF-SZO,
by integrating a high-pass filter and a low-pass filter into the vanilla SZO
method. Interestingly, it turns out that the integration of a high-pass filter
coincides with the residual-feedback SZO method, and the integration of a
low-pass filter can be interpreted as the momentum method. We prove that
HLF-SZO achieves a $O(d/T^{\frac{2}{3}})$ convergence rate for Lipschitz and
smooth objective functions (in both convex and nonconvex cases). Extensive
numerical experiments show that the high-pass filter can significantly reduce
the variance and the low-pass filter can accelerate the convergence. As a
result, the proposed HLF-SZO has a much smaller variance and much faster
convergence compared with the vanilla SZO method, and empirically outperforms
the state-of-the-art residual-feedback SZO method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yujie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Na Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01705">
<title>AI Ethics Statements -- Analysis and lessons learnt from NeurIPS Broader Impact Statements. (arXiv:2111.01705v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2111.01705</link>
<description rdf:parseType="Literal">&lt;p&gt;Ethics statements have been proposed as a mechanism to increase transparency
and promote reflection on the societal impacts of published research. In 2020,
the machine learning (ML) conference NeurIPS broke new ground by requiring that
all papers include a broader impact statement. This requirement was removed in
2021, in favour of a checklist approach. The 2020 statements therefore provide
a unique opportunity to learn from the broader impact experiment: to
investigate the benefits and challenges of this and similar governance
mechanisms, as well as providing an insight into how ML researchers think about
the societal impacts of their own work. Such learning is needed as NeurIPS and
other venues continue to question and adapt their policies. To enable this, we
have created a dataset containing the impact statements from all NeurIPS 2020
papers, along with additional information such as affiliation type, location
and subject area, and a simple visualisation tool for exploration. We also
provide an initial quantitative analysis of the dataset, covering
representation, engagement, common themes, and willingness to discuss potential
harms alongside benefits. We investigate how these vary by geography,
affiliation type and subject area. Drawing on these findings, we discuss the
potential benefits and negative outcomes of ethics statement requirements, and
their possible causes and associated challenges. These lead us to several
lessons to be learnt from the 2020 requirement: (i) the importance of creating
the right incentives, (ii) the need for clear expectations and guidance, and
(iii) the importance of transparency and constructive deliberation. We
encourage other researchers to use our dataset to provide additional analysis,
to further our understanding of how researchers responded to this requirement,
and to investigate the benefits and challenges of this and related mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashurst_C/0/1/0/all/0/1&quot;&gt;Carolyn Ashurst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hine_E/0/1/0/all/0/1&quot;&gt;Emmie Hine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedille_P/0/1/0/all/0/1&quot;&gt;Paul Sedille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlier_A/0/1/0/all/0/1&quot;&gt;Alexis Carlier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01706">
<title>Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim Identification in Unlabeled Data for Automated Fact-Checking. (arXiv:2111.01706v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2111.01706</link>
<description rdf:parseType="Literal">&lt;p&gt;While recent work on automated fact-checking has focused mainly on verifying
and explaining claims, for which the list of claims is readily available,
identifying check-worthy claim sentences from a text remains challenging.
Current claim identification models rely on manual annotations for each
sentence in the text, which is an expensive task and challenging to conduct on
a frequent basis across multiple domains. This paper explores methodology to
identify check-worthy claim sentences from fake news articles, irrespective of
domain, without explicit sentence-level annotations. We leverage two internal
supervisory signals - headline and the abstractive summary - to rank the
sentences based on semantic similarity. We hypothesize that this ranking
directly correlates to the check-worthiness of the sentences. To assess the
effectiveness of this hypothesis, we build pipelines that leverage the ranking
of sentences based on either the headline or the abstractive summary. The
top-ranked sentences are used for the downstream fact-checking tasks of
evidence retrieval and the article&apos;s veracity prediction by the pipeline. Our
findings suggest that the top 3 ranked sentences contain enough information for
evidence-based fact-checking of a fake news article. We also show that while
the headline has more gisting similarity with how a fact-checking website
writes a claim, the summary-based pipeline is the most promising for an
end-to-end fact-checking system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_A/0/1/0/all/0/1&quot;&gt;Archita Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srihari_R/0/1/0/all/0/1&quot;&gt;Rohini K. Srihari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01710">
<title>Multi-input Architecture and Disentangled Representation Learning for Multi-dimensional Modeling of Music Similarity. (arXiv:2111.01710v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2111.01710</link>
<description rdf:parseType="Literal">&lt;p&gt;In the context of music information retrieval, similarity-based approaches
are useful for a variety of tasks that benefit from a query-by-example
scenario. Music however, naturally decomposes into a set of semantically
meaningful factors of variation. Current representation learning strategies
pursue the disentanglement of such factors from deep representations, resulting
in highly interpretable models. This allows the modeling of music similarity
perception, which is highly subjective and multi-dimensional. While the focus
of prior work is on metadata driven notions of similarity, we suggest to
directly model the human notion of multi-dimensional music similarity. To
achieve this, we propose a multi-input deep neural network architecture, which
simultaneously processes mel-spectrogram, CENS-chromagram and tempogram in
order to extract informative features for the different disentangled musical
dimensions: genre, mood, instrument, era, tempo, and key. We evaluated the
proposed music similarity approach using a triplet prediction task and found
that the proposed multi-input architecture outperforms a state of the art
method. Furthermore, we present a novel multi-dimensional analysis in order to
evaluate the influence of each disentangled dimension on the perception of
music similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ribecky_S/0/1/0/all/0/1&quot;&gt;Sebastian Ribecky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abesser_J/0/1/0/all/0/1&quot;&gt;Jakob Abe&amp;#xdf;er&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lukashevich_H/0/1/0/all/0/1&quot;&gt;Hanna Lukashevich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01713">
<title>Realistic galaxy image simulation via score-based generative models. (arXiv:2111.01713v1 [astro-ph.IM])</title>
<link>http://arxiv.org/abs/2111.01713</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that a Denoising Diffusion Probabalistic Model (DDPM), a class of
score-based generative model, can be used to produce realistic yet fake images
that mimic observations of galaxies. Our method is tested with Dark Energy
Spectroscopic Instrument grz imaging of galaxies from the Photometry and
Rotation curve OBservations from Extragalactic Surveys (PROBES) sample and
galaxies selected from the Sloan Digital Sky Survey. Subjectively, the
generated galaxies are highly realistic when compared with samples from the
real dataset. We quantify the similarity by borrowing from the deep generative
learning literature, using the `Fr\&apos;echet Inception Distance&apos; to test for
subjective and morphological similarity. We also introduce the `Synthetic
Galaxy Distance&apos; metric to compare the emergent physical properties (such as
total magnitude, colour and half light radius) of a ground truth parent and
synthesised child dataset. We argue that the DDPM approach produces sharper and
more realistic images than other generative methods such as Adversarial
Networks (with the downside of more costly inference), and could be used to
produce large samples of synthetic observations tailored to a specific imaging
survey. We demonstrate two potential uses of the DDPM: (1) accurate in-painting
of occluded data, such as satellite trails, and (2) domain transfer, where new
input images can be processed to mimic the properties of the DDPM training set.
Here we `DESI-fy&apos; cartoon images as a proof of concept for domain transfer.
Finally, we suggest potential applications for score-based approaches that
could motivate further research on this topic within the astronomical
community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael J. Smith&lt;/a&gt; (Hertfordshire), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Geach_J/0/1/0/all/0/1&quot;&gt;James E. Geach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Jackson_R/0/1/0/all/0/1&quot;&gt;Ryan A. Jackson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Arora_N/0/1/0/all/0/1&quot;&gt;Nikhil Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Stone_C/0/1/0/all/0/1&quot;&gt;Connor Stone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Courteau_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Courteau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01714">
<title>Meta-Learning the Search Distribution of Black-Box Random Search Based Adversarial Attacks. (arXiv:2111.01714v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01714</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks based on randomized search schemes have obtained
state-of-the-art results in black-box robustness evaluation recently. However,
as we demonstrate in this work, their efficiency in different query budget
regimes depends on manual design and heuristic tuning of the underlying
proposal distributions. We study how this issue can be addressed by adapting
the proposal distribution online based on the information obtained during the
attack. We consider Square Attack, which is a state-of-the-art score-based
black-box attack, and demonstrate how its performance can be improved by a
learned controller that adjusts the parameters of the proposal distribution
online during the attack. We train the controller using gradient-based
end-to-end training on a CIFAR10 model with white box access. We demonstrate
that plugging the learned controller into the attack consistently improves its
black-box robustness estimate in different query regimes by up to 20% for a
wide range of different models with black-box access. We further show that the
learned adaptation principle transfers well to the other data distributions
such as CIFAR100 or ImageNet and to the targeted attack setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yatsura_M/0/1/0/all/0/1&quot;&gt;Maksym Yatsura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1&quot;&gt;Jan Hendrik Metzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1&quot;&gt;Matthias Hein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01715">
<title>Absolute distance prediction based on deep learning object detection and monocular depth estimation models. (arXiv:2111.01715v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01715</link>
<description rdf:parseType="Literal">&lt;p&gt;Determining the distance between the objects in a scene and the camera sensor
from 2D images is feasible by estimating depth images using stereo cameras or
3D cameras. The outcome of depth estimation is relative distances that can be
used to calculate absolute distances to be applicable in reality. However,
distance estimation is very challenging using 2D monocular cameras. This paper
presents a deep learning framework that consists of two deep networks for depth
estimation and object detection using a single image. Firstly, objects in the
scene are detected and localized using the You Only Look Once (YOLOv5) network.
In parallel, the estimated depth image is computed using a deep autoencoder
network to detect the relative distances. The proposed object detection based
YOLO was trained using a supervised learning technique, in turn, the network of
depth estimation was self-supervised training. The presented distance
estimation framework was evaluated on real images of outdoor scenes. The
achieved results show that the proposed framework is promising and it yields an
accuracy of 96% with RMSE of 0.203 of the correct absolute distance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masoumian_A/0/1/0/all/0/1&quot;&gt;Armin Masoumian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marei_D/0/1/0/all/0/1&quot;&gt;David G. F. Marei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdulwahab_S/0/1/0/all/0/1&quot;&gt;Saddam Abdulwahab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristiano_J/0/1/0/all/0/1&quot;&gt;Julian Cristiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puig_D/0/1/0/all/0/1&quot;&gt;Domenec Puig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashwan_H/0/1/0/all/0/1&quot;&gt;Hatem A. Rashwan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01717">
<title>MixFace: Improving Face Verification Focusing on Fine-grained Conditions. (arXiv:2111.01717v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01717</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance of face recognition has become saturated for public benchmark
datasets such as LFW, CFP-FP, and AgeDB, owing to the rapid advances in CNNs.
However, the effects of faces with various fine-grained conditions on FR models
have not been investigated because of the absence of such datasets. This paper
analyzes their effects in terms of different conditions and loss functions
using K-FACE, a recently introduced FR dataset with fine-grained conditions. We
propose a novel loss function, MixFace, that combines classification and metric
losses. The superiority of MixFace in terms of effectiveness and robustness is
demonstrated experimentally on various benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1&quot;&gt;Junuk Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Son_S/0/1/0/all/0/1&quot;&gt;Sungbin Son&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Joochan Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Yongjun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seonhoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_H/0/1/0/all/0/1&quot;&gt;Heung-Seon Oh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01718">
<title>Competitive Algorithms for Online Weighted Bipartite Matching and its Variants. (arXiv:2111.01718v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2111.01718</link>
<description rdf:parseType="Literal">&lt;p&gt;Online bipartite matching has been extensively studied. In the unweighted
setting, Karp et al. gave an optimal $(1 - 1/e)$-competitive randomized
algorithm. In the weighted setting, optimal algorithms have been achieved only
under assumptions on the edge weights. For the general case, little was known
beyond the trivial $1/2$-competitive greedy algorithm. Recently, Fahrbach et
al. have presented an 0.5086-competitive algorithm (for the problem in a model,
namely free-disposal), overcoming the long-standing barrier of 1/2. Besides, in
designing competitive algorithms for the online matching problem and its
variants, several techniques have been developed, in particular the primal-dual
method. Specifically, Devanur et al. gave a primal-dual framework, unifying
previous approaches and Devanur and Jain provided another scheme for a
generalization of the online matching problem.
&lt;/p&gt;
&lt;p&gt;In this paper, we present competitive algorithms for the online weighted
bipartite matching in different models; in particular we achieve the optimal
$(1-1/e)$ competitive ratio in the free-disposal model and in other model,
namely stochastic reward. Our work also unifies the previous approaches by the
mean of the primal-dual technique with configuration linear programs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thang_N/0/1/0/all/0/1&quot;&gt;Nguyen Kim Thang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01721">
<title>Bayes-Newton Methods for Approximate Bayesian Inference with PSD Guarantees. (arXiv:2111.01721v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01721</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate natural gradient variational inference (VI), expectation
propagation (EP), and posterior linearisation (PL) as extensions of Newton&apos;s
method for optimising the parameters of a Bayesian posterior distribution. This
viewpoint explicitly casts inference algorithms under the framework of
numerical optimisation. We show that common approximations to Newton&apos;s method
from the optimisation literature, namely Gauss-Newton and quasi-Newton methods
(e.g., the BFGS algorithm), are still valid under this `Bayes-Newton&apos;
framework. This leads to a suite of novel algorithms which are guaranteed to
result in positive semi-definite covariance matrices, unlike standard VI and
EP. Our unifying viewpoint provides new insights into the connections between
various inference schemes. All the presented methods apply to any model with a
Gaussian prior and non-conjugate likelihood, which we demonstrate with (sparse)
Gaussian processes and state space models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilkinson_W/0/1/0/all/0/1&quot;&gt;William J. Wilkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarkka_S/0/1/0/all/0/1&quot;&gt;Simo S&amp;#xe4;rkk&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1&quot;&gt;Arno Solin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01722">
<title>Predicting the Location of Bicycle-sharing Stations using OpenStreetMap Data. (arXiv:2111.01722v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01722</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning the layout of bicycle-sharing stations is a complex process,
especially in cities where bicycle sharing systems are just being implemented.
Urban planners often have to make a lot of estimates based on both publicly
available data and privately provided data from the administration and then use
the Location-Allocation model popular in the field. Many municipalities in
smaller cities may have difficulty hiring specialists to carry out such
planning. This thesis proposes a new solution to streamline and facilitate the
process of such planning by using spatial embedding methods. Based only on
publicly available data from OpenStreetMap, and station layouts from 34 cities
in Europe, a method has been developed to divide cities into micro-regions
using the Uber H3 discrete global grid system and to indicate regions where it
is worth placing a station based on existing systems in different cities using
transfer learning. The result of the work is a mechanism to support planners in
their decision making when planning a station layout with a choice of reference
cities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raczycki_K/0/1/0/all/0/1&quot;&gt;Kamil Raczycki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01723">
<title>CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds. (arXiv:2111.01723v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01723</link>
<description rdf:parseType="Literal">&lt;p&gt;A fast and accurate panoptic segmentation system for LiDAR point clouds is
crucial for autonomous driving vehicles to understand the surrounding objects
and scenes. Existing approaches usually rely on proposals or clustering to
segment foreground instances. As a result, they struggle to achieve real-time
performance. In this paper, we propose a novel real-time end-to-end panoptic
segmentation network for LiDAR point clouds, called CPSeg. In particular, CPSeg
comprises a shared encoder, a dual decoder, a task-aware attention module (TAM)
and a cluster-free instance segmentation head. TAM is designed to enforce these
two decoders to learn rich task-aware features for semantic and instance
embedding. Moreover, CPSeg incorporates a new cluster-free instance
segmentation head to dynamically pillarize foreground points according to the
learned embedding. Then, it acquires instance labels by finding connected
pillars with a pairwise embedding comparison. Thus, the conventional
proposal-based or clustering-based instance segmentation is transformed into a
binary segmentation problem on the pairwise embedding comparison matrix. To
help the network regress instance embedding, a fast and deterministic depth
completion algorithm is proposed to calculate surface normal of each point
cloud in real-time. The proposed method is benchmarked on two large-scale
autonomous driving datasets, namely, SemanticKITTI and nuScenes. Notably,
extensive experimental results show that CPSeg achieves the state-of-the-art
results among real-time approaches on both datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1&quot;&gt;Enxu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razani_R/0/1/0/all/0/1&quot;&gt;Ryan Razani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yixuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bingbing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01726">
<title>Instructive artificial intelligence (AI) for human training, assistance, and explainability. (arXiv:2111.01726v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2111.01726</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach to explainable AI (XAI) based on the concept of
&quot;instruction&quot; from neural networks. In this case study, we demonstrate how a
superhuman neural network might instruct human trainees as an alternative to
traditional approaches to XAI. Specifically, an AI examines human actions and
calculates variations on the human strategy that lead to better performance.
Experiments with a JHU/APL-developed AI player for the cooperative card game
Hanabi suggest this technique makes unique contributions to explainability
while improving human performance. One area of focus for Instructive AI is in
the significant discrepancies that can arise between a human&apos;s actual strategy
and the strategy they profess to use. This inaccurate self-assessment presents
a barrier for XAI, since explanations of an AI&apos;s strategy may not be properly
understood or implemented by human recipients. We have developed and are
testing a novel, Instructive AI approach that estimates human strategy by
observing human actions. With neural networks, this allows a direct calculation
of the changes in weights needed to improve the human strategy to better
emulate a more successful AI. Subjected to constraints (e.g. sparsity) these
weight changes can be interpreted as recommended changes to human strategy
(e.g. &quot;value A more, and value B less&quot;). Instruction from AI such as this
functions both to help humans perform better at tasks, but also to better
understand, anticipate, and correct the actions of an AI. Results will be
presented on AI instruction&apos;s ability to improve human decision-making and
human-AI teaming in Hanabi.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kantack_N/0/1/0/all/0/1&quot;&gt;Nicholas Kantack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1&quot;&gt;Nina Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bos_N/0/1/0/all/0/1&quot;&gt;Nathan Bos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowman_C/0/1/0/all/0/1&quot;&gt;Corey Lowman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Everett_J/0/1/0/all/0/1&quot;&gt;James Everett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endres_T/0/1/0/all/0/1&quot;&gt;Timothy Endres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01730">
<title>A Butterfly-Accelerated Volume Integral Equation Solver for Broad Permittivity and Large-Scale Electromagnetic Analysis. (arXiv:2111.01730v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01730</link>
<description rdf:parseType="Literal">&lt;p&gt;A butterfly-accelerated volume integral equation (VIE) solver is proposed for
fast and accurate electromagnetic (EM) analysis of scattering from
heterogeneous objects. The proposed solver leverages the hierarchical
off-diagonal butterfly (HOD-BF) scheme to construct the system matrix and
obtain its approximate inverse, used as a preconditioner. Complexity analysis
and numerical experiments validate the $O(N\log^2N)$ construction cost of the
HOD-BF-compressed system matrix and $O(N^{1.5}\log N)$ inversion cost for the
preconditioner, where $N$ is the number of unknowns in the high-frequency EM
scattering problem. For many practical scenarios, the proposed VIE solver
requires less memory and computational time to construct the system matrix and
obtain its approximate inverse compared to a $\mathcal{H}$ matrix-accelerated
VIE solver. The accuracy and efficiency of the proposed solver have been
demonstrated via its application to the EM analysis of large-scale canonical
and real-world structures comprising of broad permittivity values and involving
millions of unknowns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sayed_S/0/1/0/all/0/1&quot;&gt;Sadeed B. Sayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gomez_L/0/1/0/all/0/1&quot;&gt;Luis J. Gomez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yucel_A/0/1/0/all/0/1&quot;&gt;Abdulkadir C. Yucel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01732">
<title>Spatio-Temporal Variational Gaussian Processes. (arXiv:2111.01732v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01732</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a scalable approach to Gaussian process inference that combines
spatio-temporal filtering with natural gradient variational inference,
resulting in a non-conjugate GP method for multivariate data that scales
linearly with respect to time. Our natural gradient approach enables
application of parallel filtering and smoothing, further reducing the temporal
span complexity to be logarithmic in the number of time steps. We derive a
sparse approximation that constructs a state-space model over a reduced set of
spatial inducing points, and show that for separable Markov kernels the full
and sparse cases exactly recover the standard variational GP, whilst exhibiting
favourable computational properties. To further improve the spatial scaling we
propose a mean-field assumption of independence between spatial locations
which, when coupled with sparsity and parallelisation, leads to an efficient
and accurate method for large spatio-temporal problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamelijnck_O/0/1/0/all/0/1&quot;&gt;Oliver Hamelijnck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilkinson_W/0/1/0/all/0/1&quot;&gt;William J. Wilkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loppi_N/0/1/0/all/0/1&quot;&gt;Niki A. Loppi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1&quot;&gt;Arno Solin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damoulas_T/0/1/0/all/0/1&quot;&gt;Theodoros Damoulas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01740">
<title>Personalized One-Shot Lipreading for an ALS Patient. (arXiv:2111.01740v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01740</link>
<description rdf:parseType="Literal">&lt;p&gt;Lipreading or visually recognizing speech from the mouth movements of a
speaker is a challenging and mentally taxing task. Unfortunately, multiple
medical conditions force people to depend on this skill in their day-to-day
lives for essential communication. Patients suffering from Amyotrophic Lateral
Sclerosis (ALS) often lose muscle control, consequently their ability to
generate speech and communicate via lip movements. Existing large datasets do
not focus on medical patients or curate personalized vocabulary relevant to an
individual. Collecting a large-scale dataset of a patient, needed to train
mod-ern data-hungry deep learning models is, however, extremely challenging. In
this work, we propose a personalized network to lipread an ALS patient using
only one-shot examples. We depend on synthetically generated lip movements to
augment the one-shot scenario. A Variational Encoder based domain adaptation
technique is used to bridge the real-synthetic domain gap. Our approach
significantly improves and achieves high top-5accuracy with 83.2% accuracy
compared to 62.6% achieved by comparable methods for the patient. Apart from
evaluating our approach on the ALS patient, we also extend it to people with
hearing impairment relying extensively on lip movements to communicate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_B/0/1/0/all/0/1&quot;&gt;Bipasha Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Aditya Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_R/0/1/0/all/0/1&quot;&gt;Rudrabha Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1&quot;&gt;Vinay Namboodiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1&quot;&gt;C V Jawahar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01742">
<title>LogAvgExp Provides a Principled and Performant Global Pooling Operator. (arXiv:2111.01742v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01742</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to improve the pooling operation in neural networks, by applying a
more theoretically justified operator. We demonstrate that LogSumExp provides a
natural OR operator for logits. When one corrects for the number of elements
inside the pooling operator, this becomes $\text{LogAvgExp} :=
\log(\text{mean}(\exp(x)))$. By introducing a single temperature parameter,
LogAvgExp smoothly transitions from the max of its operands to the mean (found
at the limiting cases $t \to 0^+$ and $t \to +\infty$). We experimentally
tested LogAvgExp, both with and without a learnable temperature parameter, in a
variety of deep neural network architectures for computer vision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowe_S/0/1/0/all/0/1&quot;&gt;Scott C. Lowe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trappenberg_T/0/1/0/all/0/1&quot;&gt;Thomas Trappenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oore_S/0/1/0/all/0/1&quot;&gt;Sageev Oore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01743">
<title>Designing Inherently Interpretable Machine Learning Models. (arXiv:2111.01743v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01743</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretable machine learning (IML) becomes increasingly important in highly
regulated industry sectors related to the health and safety or fundamental
rights of human beings. In general, the inherently IML models should be adopted
because of their transparency and explainability, while black-box models with
model-agnostic explainability can be more difficult to defend under regulatory
scrutiny. For assessing inherent interpretability of a machine learning model,
we propose a qualitative template based on feature effects and model
architecture constraints. It provides the design principles for
high-performance IML model development, with examples given by reviewing our
recent works on ExNN, GAMI-Net, SIMTree, and the Aletheia toolkit for local
linear interpretability of deep ReLU networks. We further demonstrate how to
design an interpretable ReLU DNN model with evaluation of conceptual soundness
for a real case study of predicting credit default in home lending. We hope
that this work will provide a practical guide of developing inherently IML
models in high risk applications in banking industry, as well as other sectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudjianto_A/0/1/0/all/0/1&quot;&gt;Agus Sudjianto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aijun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01744">
<title>UnProjection: Leveraging Inverse-Projections for Visual Analytics of High-Dimensional Data. (arXiv:2111.01744v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2111.01744</link>
<description rdf:parseType="Literal">&lt;p&gt;Projection techniques are often used to visualize high-dimensional data,
allowing users to better understand the overall structure of multi-dimensional
spaces on a 2D screen. Although many such methods exist, comparably little work
has been done on generalizable methods of inverse-projection -- the process of
mapping the projected points, or more generally, the projection space back to
the original high-dimensional space. In this paper we present NNInv, a deep
learning technique with the ability to approximate the inverse of any
projection or mapping. NNInv learns to reconstruct high-dimensional data from
any arbitrary point on a 2D projection space, giving users the ability to
interact with the learned high-dimensional representation in a visual analytics
system. We provide an analysis of the parameter space of NNInv, and offer
guidance in selecting these parameters. We extend validation of the
effectiveness of NNInv through a series of quantitative and qualitative
analyses. We then demonstrate the method&apos;s utility by applying it to three
visualization tasks: interactive instance interpolation, classifier agreement,
and gradient visualization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Espadoto_M/0/1/0/all/0/1&quot;&gt;Mateus Espadoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Appleby_G/0/1/0/all/0/1&quot;&gt;Gabriel Appleby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suh_A/0/1/0/all/0/1&quot;&gt;Ashley Suh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cashman_D/0/1/0/all/0/1&quot;&gt;Dylan Cashman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mingwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheidegger_C/0/1/0/all/0/1&quot;&gt;Carlos Scheidegger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_E/0/1/0/all/0/1&quot;&gt;Erik W Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1&quot;&gt;Remco Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Telea_A/0/1/0/all/0/1&quot;&gt;Alexandru C Telea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01750">
<title>Spiking Generative Adversarial Networks With a Neural Network Discriminator: Local Training, Bayesian Models, and Continual Meta-Learning. (arXiv:2111.01750v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01750</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuromorphic data carries information in spatio-temporal patterns encoded by
spikes. Accordingly, a central problem in neuromorphic computing is training
spiking neural networks (SNNs) to reproduce spatio-temporal spiking patterns in
response to given spiking stimuli. Most existing approaches model the
input-output behavior of an SNN in a deterministic fashion by assigning each
input to a specific desired output spiking sequence. In contrast, in order to
fully leverage the time-encoding capacity of spikes, this work proposes to
train SNNs so as to match distributions of spiking signals rather than
individual spiking signals. To this end, the paper introduces a novel hybrid
architecture comprising a conditional generator, implemented via an SNN, and a
discriminator, implemented by a conventional artificial neural network (ANN).
The role of the ANN is to provide feedback during training to the SNN within an
adversarial iterative learning strategy that follows the principle of
generative adversarial network (GANs). In order to better capture multi-modal
spatio-temporal distribution, the proposed approach -- termed SpikeGAN -- is
further extended to support Bayesian learning of the generator&apos;s weight.
Finally, settings with time-varying statistics are addressed by proposing an
online meta-learning variant of SpikeGAN. Experiments bring insights into the
merits of the proposed approach as compared to existing solutions based on
(static) belief networks and maximum likelihood (or empirical risk
minimization).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenfeld_B/0/1/0/all/0/1&quot;&gt;Bleema Rosenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajendran_B/0/1/0/all/0/1&quot;&gt;Bipin Rajendran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01754">
<title>Meta-Learning to Improve Pre-Training. (arXiv:2111.01754v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01754</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-training (PT) followed by fine-tuning (FT) is an effective method for
training neural networks, and has led to significant performance improvements
in many domains. PT can incorporate various design choices such as task and
data reweighting strategies, augmentation policies, and noise models, all of
which can significantly impact the quality of representations learned. The
hyperparameters introduced by these strategies therefore must be tuned
appropriately. However, setting the values of these hyperparameters is
challenging. Most existing methods either struggle to scale to high dimensions,
are too slow and memory-intensive, or cannot be directly applied to the
two-stage PT and FT learning process. In this work, we propose an efficient,
gradient-based algorithm to meta-learn PT hyperparameters. We formalize the PT
hyperparameter optimization problem and propose a novel method to obtain PT
hyperparameter gradients by combining implicit differentiation and
backpropagation through unrolled optimization. We demonstrate that our method
improves predictive performance on two real-world domains. First, we optimize
high-dimensional task weighting hyperparameters for multitask pre-training on
protein-protein interaction graphs and improve AUROC by up to 3.9%. Second, we
optimize a data augmentation neural network for self-supervised PT with SimCLR
on electrocardiography data and improve AUROC by up to 1.9%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_A/0/1/0/all/0/1&quot;&gt;Aniruddh Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorraine_J/0/1/0/all/0/1&quot;&gt;Jonathan Lorraine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1&quot;&gt;Simon Kornblith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDermott_M/0/1/0/all/0/1&quot;&gt;Matthew McDermott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01758">
<title>Universal Path Gain Laws for Common Wireless Communication Environments. (arXiv:2111.01758v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2111.01758</link>
<description rdf:parseType="Literal">&lt;p&gt;Simple and accurate expressions for path gain are derived from
electromagnetic fundamentals in a wide variety of common environments,
including Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) indoor urban
canyons, urban/rural macro, outdoor-indoor and suburban streets with
vegetation. Penetration into a scattering region, sometimes aided by guiding,
is the &quot;universal&quot; phenomenon shared by the diverse morphologies. Root Mean
Square (RMS) errors against extensive measurements are under 5 dB, better than
3GPP models by 1-12 dB RMS, depending on environment. In urban canyons the
models have 4.7 dB RMS error, as compared to 7.9 dB from linear fit to data and
13.9/17.2 dB from LOS/NLOS 3GPP models. The theoretical path gains depend on
distance as a power law with exponents from a small set {1.5, 2, 2.5, 4},
specific to each morphology. This provides a theoretical justification for
widely used power law empirical models. Only coarse environmental data is
needed as parameters: street width, building height, vegetation depth, wall
material and antenna heights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chizhik_D/0/1/0/all/0/1&quot;&gt;Dmitry Chizhik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Jinfeng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valenzuela_R/0/1/0/all/0/1&quot;&gt;Reinaldo A. Valenzuela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01759">
<title>Truly Low-Space Element Distinctness and Subset Sum via Pseudorandom Hash Functions. (arXiv:2111.01759v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2111.01759</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider low-space algorithms for the classic Element Distinctness
problem: given an array of $n$ input integers with $O(\log n)$ bit-length,
decide whether or not all elements are pairwise distinct. Beame, Clifford, and
Machmouchi [FOCS 2013] gave an $\tilde O(n^{1.5})$-time randomized algorithm
for Element Distinctness using only $O(\log n)$ bits of working space. However,
their algorithm assumes a random oracle (in particular, read-only random access
to polynomially many random bits), and it was asked as an open question whether
this assumption can be removed.
&lt;/p&gt;
&lt;p&gt;In this paper, we positively answer this question by giving an $\tilde
O(n^{1.5})$-time randomized algorithm using $O(\log ^3 n\log \log n)$ bits of
space, with one-way access to random bits. As a corollary, we also obtain a
$\operatorname{\mathrm{poly}}(n)$-space $O^*(2^{0.86n})$-time randomized
algorithm for the Subset Sum problem, removing the random oracles required in
the algorithm of Bansal, Garg, Nederlof, and Vyas [STOC 2017].
&lt;/p&gt;
&lt;p&gt;The main technique underlying our results is a pseudorandom hash family based
on iterative restrictions, which can fool the cycle-finding procedure in the
algorithms of Beame et al. and Bansal et al.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lijie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1&quot;&gt;Ce Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_R/0/1/0/all/0/1&quot;&gt;R. Ryan Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hongxun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01760">
<title>Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics Organized by Astrocyte-modulated Plasticity. (arXiv:2111.01760v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2111.01760</link>
<description rdf:parseType="Literal">&lt;p&gt;The liquid state machine (LSM) combines low training complexity and
biological plausibility, which has made it an attractive machine learning
framework for edge and neuromorphic computing paradigms. Originally proposed as
a model of brain computation, the LSM tunes its internal weights without
backpropagation of gradients, which results in lower performance compared to
multi-layer neural networks. Recent findings in neuroscience suggest that
astrocytes, a long-neglected non-neuronal brain cell, modulate synaptic
plasticity and brain dynamics, tuning brain networks to the vicinity of the
computationally optimal critical phase transition between order and chaos.
Inspired by this disruptive understanding of how brain networks self-tune, we
propose the neuron-astrocyte liquid state machine (NALSM) that addresses
under-performance through self-organized near-critical dynamics. Similar to its
biological counterpart, the astrocyte model integrates neuronal activity and
provides global feedback to spike-timing-dependent plasticity (STDP), which
self-organizes NALSM dynamics around a critical branching factor that is
associated with the edge-of-chaos. We demonstrate that NALSM achieves
state-of-the-art accuracy versus comparable LSM methods, without the need for
data-specific hand-tuning. With a top accuracy of 97.61% on MNIST, 97.51% on
N-MNIST, and 85.84% on Fashion-MNIST, NALSM achieved comparable performance to
current fully-connected multi-layer spiking neural networks trained via
backpropagation. Our findings suggest that the further development of
brain-inspired machine learning methods has the potential to reach the
performance of deep learning, with the added benefits of supporting robust and
energy-efficient neuromorphic computing on the edge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanov_V/0/1/0/all/0/1&quot;&gt;Vladimir A. Ivanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michmizos_K/0/1/0/all/0/1&quot;&gt;Konstantinos P. Michmizos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01761">
<title>Two neural-network-based methods for solving obstacle problems. (arXiv:2111.01761v1 [math.NA])</title>
<link>http://arxiv.org/abs/2111.01761</link>
<description rdf:parseType="Literal">&lt;p&gt;Two neural-network-based numerical schemes are proposed to solve the
classical obstacle problems. The schemes are based on the universal
approximation property of neural networks, and the cost functions are taken as
the energy minimization of the obstacle problems. We rigorously prove the
convergence of the two schemes and derive the convergence rates with the number
of neurons $N$. In the simulations, we use two example problems (1-D &amp;amp; 2-D) to
verify the convergence rate of the methods and the quality of the results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xinyue Evelyn Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hao_W/0/1/0/all/0/1&quot;&gt;Wenrui Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Bei Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01763">
<title>Modelling COVID-19 Pandemic Dynamics Using Transparent, Interpretable, Parsimonious and Simulatable (TIPS) Machine Learning Models: A Case Study from Systems Thinking and System Identification Perspectives. (arXiv:2111.01763v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01763</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the outbreak of COVID-19, an astronomical number of publications on the
pandemic dynamics appeared in the literature, of which many use the susceptible
infected removed (SIR) and susceptible exposed infected removed (SEIR) models,
or their variants, to simulate and study the spread of the coronavirus. SIR and
SEIR are continuous-time models which are a class of initial value problems
(IVPs) of ordinary differential equations (ODEs). Discrete-time models such as
regression and machine learning have also been applied to analyze COVID-19
pandemic data (e.g. predicting infection cases), but most of these methods use
simplified models involving a small number of input variables pre-selected
based on a priori knowledge, or use very complicated models (e.g. deep
learning), purely focusing on certain prediction purposes and paying little
attention to the model interpretability. There have been relatively fewer
studies focusing on the investigations of the inherent time-lagged or
time-delayed relationships e.g. between the reproduction number (R number),
infection cases, and deaths, analyzing the pandemic spread from a systems
thinking and dynamic perspective. The present study, for the first time,
proposes using systems engineering and system identification approach to build
transparent, interpretable, parsimonious and simulatable (TIPS) dynamic machine
learning models, establishing links between the R number, the infection cases
and deaths caused by COVID-19. The TIPS models are developed based on the
well-known NARMAX (Nonlinear AutoRegressive Moving Average with eXogenous
inputs) model, which can help better understand the COVID-19 pandemic dynamics.
A case study on the UK COVID-19 data is carried out, and new findings are
detailed. The proposed method and the associated new findings are useful for
better understanding the spread dynamics of the COVID-19 pandemic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1&quot;&gt;Hua-Liang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Billings_S/0/1/0/all/0/1&quot;&gt;S.A. Billings&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01767">
<title>Regularization for Shuffled Data Problems via Exponential Family Priors on the Permutation Group. (arXiv:2111.01767v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01767</link>
<description rdf:parseType="Literal">&lt;p&gt;In the analysis of data sets consisting of (X, Y)-pairs, a tacit assumption
is that each pair corresponds to the same observation unit. If, however, such
pairs are obtained via record linkage of two files, this assumption can be
violated as a result of mismatch error rooting, for example, in the lack of
reliable identifiers in the two files. Recently, there has been a surge of
interest in this setting under the term &quot;Shuffled data&quot; in which the underlying
correct pairing of (X, Y)-pairs is represented via an unknown index
permutation. Explicit modeling of the permutation tends to be associated with
substantial overfitting, prompting the need for suitable methods of
regularization. In this paper, we propose a flexible exponential family prior
on the permutation group for this purpose that can be used to integrate various
structures such as sparse and locally constrained shuffling. This prior turns
out to be conjugate for canonical shuffled data problems in which the
likelihood conditional on a fixed permutation can be expressed as product over
the corresponding (X,Y)-pairs. Inference is based on the EM algorithm in which
the intractable E-step is approximated by the Fisher-Yates algorithm. The
M-step is shown to admit a significant reduction from $n^2$ to $n$ terms if the
likelihood of (X,Y)-pairs has exponential family form as in the case of
generalized linear models. Comparisons on synthetic and real data show that the
proposed approach compares favorably to competing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhenbang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ben_David_E/0/1/0/all/0/1&quot;&gt;Emanuel Ben-David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Slawski_M/0/1/0/all/0/1&quot;&gt;Martin Slawski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01768">
<title>Nearly Optimal Algorithms for Level Set Estimation. (arXiv:2111.01768v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01768</link>
<description rdf:parseType="Literal">&lt;p&gt;The level set estimation problem seeks to find all points in a domain ${\cal
X}$ where the value of an unknown function $f:{\cal X}\rightarrow \mathbb{R}$
exceeds a threshold $\alpha$. The estimation is based on noisy function
evaluations that may be acquired at sequentially and adaptively chosen
locations in ${\cal X}$. The threshold value $\alpha$ can either be
\emph{explicit} and provided a priori, or \emph{implicit} and defined relative
to the optimal function value, i.e. $\alpha = (1-\epsilon)f(x_\ast)$ for a
given $\epsilon &amp;gt; 0$ where $f(x_\ast)$ is the maximal function value and is
unknown. In this work we provide a new approach to the level set estimation
problem by relating it to recent adaptive experimental design methods for
linear bandits in the Reproducing Kernel Hilbert Space (RKHS) setting. We
assume that $f$ can be approximated by a function in the RKHS up to an unknown
misspecification and provide novel algorithms for both the implicit and
explicit cases in this setting with strong theoretical guarantees. Moreover, in
the linear (kernel) setting, we show that our bounds are nearly optimal,
namely, our upper bounds match existing lower bounds for threshold linear
bandits. To our knowledge this work provides the first instance-dependent,
non-asymptotic upper bounds on sample complexity of level-set estimation that
match information theoretic lower bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mason_B/0/1/0/all/0/1&quot;&gt;Blake Mason&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Camilleri_R/0/1/0/all/0/1&quot;&gt;Romain Camilleri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Subhojyoti Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jamieson_K/0/1/0/all/0/1&quot;&gt;Kevin Jamieson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert Nowak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jain_L/0/1/0/all/0/1&quot;&gt;Lalit Jain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01773">
<title>Data-Driven System Identification of 6-DoF Ship Motion in Waves with Neural Networks. (arXiv:2111.01773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2111.01773</link>
<description rdf:parseType="Literal">&lt;p&gt;Critical evaluation and understanding of ship responses in the ocean is
important for not only the design and engineering of future platforms but also
the operation and safety of those that are currently deployed. Simulations or
experiments are typically performed in nominal sea conditions during ship
design or prior to deployment and the results may not be reflective of the
instantaneous state of the vessel and the ocean environment while deployed.
Short-term temporal predictions of ship responses given the current wave
environment and ship state would enable enhanced decision-making onboard for
both manned and unmanned vessels. However, the current state-of-the-art in
numerical hydrodynamic simulation tools are too computationally expensive to be
employed for real-time ship motion forecasting and the computationally
efficient tools are too low fidelity to provide accurate responses. A
methodology is developed with long short-term memory (LSTM) neural networks to
represent the motions of a free running David Taylor Model Basin (DTMB) 5415
destroyer operating at 20 knots in Sea State 7 stern-quartering irregular seas.
Case studies are performed for both course-keeping and turning circle
scenarios. An estimate of the vessel&apos;s encounter frame is made with the
trajectories observed in the training dataset. Wave elevation time histories
are given by artificial wave probes that travel with the estimated encounter
frame and serve as input into the neural network, while the output is the 6-DOF
temporal ship motion response. Overall, the neural network is able to predict
the temporal response of the ship due to unseen waves accurately, which makes
this methodology suitable for system identification and real-time ship motion
forecasting. The methodology, the dependence of model accuracy on wave probe
and training data quantity and the estimated encounter frame are all detailed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_K/0/1/0/all/0/1&quot;&gt;Kevin M. Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maki_K/0/1/0/all/0/1&quot;&gt;Kevin J. Maki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01774">
<title>Emergence and structure of decentralised trade networks around dark web marketplaces. (arXiv:2111.01774v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/2111.01774</link>
<description rdf:parseType="Literal">&lt;p&gt;Dark web marketplaces (DWMs) are online platforms that facilitate illicit
trade among millions of users generating billions of dollars in annual revenue.
Recently, two interview-based studies have suggested that DWMs may also promote
the emergence of direct user-to-user (U2U) trading relationships. Here, we
quantify the scale of, and thoroughly investigate, U2U trading around DWMs by
analysing 31 million Bitcoin transactions among users of 40 DWMs between June
2011 and Jan 2021. We find that half of the DWM users trade through U2U pairs
generating a total trading volume greater than DWMs themselves. We then show
that hundreds of thousands of DWM users form stable trading pairs that are
persistent over time. Users in stable pairs are typically the ones with the
largest trading volume on DWMs. Then, we show that new U2U pairs often form
while both users are active on the same DWM, suggesting the marketplace may
serve as a catalyst for new direct trading relationships. Finally, we reveal
that stable U2U pairs tend to survive DWM closures and that they were not
affected by COVID-19, indicating that their trading activity is resilient to
external shocks. Our work unveils sophisticated patterns of trade emerging in
the dark web and highlights the importance of investigating user behaviour
beyond the immediate buyer-seller network on a single marketplace.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nadini_M/0/1/0/all/0/1&quot;&gt;Matthieu Nadini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bracci_A/0/1/0/all/0/1&quot;&gt;Alberto Bracci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+ElBahrawy_A/0/1/0/all/0/1&quot;&gt;Abeer ElBahrawy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gradwell_P/0/1/0/all/0/1&quot;&gt;Philip Gradwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Teytelboym_A/0/1/0/all/0/1&quot;&gt;Alexander Teytelboym&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Baronchelli_A/0/1/0/all/0/1&quot;&gt;Andrea Baronchelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01777">
<title>A Framework for Real-World Multi-Robot Systems Running Decentralized GNN-Based Policies. (arXiv:2111.01777v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2111.01777</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to
facilitate the learning of complex multi-agent behaviors. Recent work has
demonstrated remarkable performance in tasks such as flocking, multi-agent path
planning and cooperative coverage. However, the policies derived through
GNN-based learning schemes have not yet been deployed to the real-world on
physical multi-robot systems. In this work, we present the design of a system
that allows for fully decentralized execution of GNN-based policies. We create
a framework based on ROS2 and elaborate its details in this paper. We
demonstrate our framework on a case-study that requires tight coordination
between robots, and present first-of-a-kind results that show successful
real-world deployment of GNN-based policies on a decentralized multi-robot
system relying on Adhoc communication. A video demonstration of this case-study
can be found online. https://www.youtube.com/watch?v=COh-WLn4iO4
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blumenkamp_J/0/1/0/all/0/1&quot;&gt;Jan Blumenkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morad_S/0/1/0/all/0/1&quot;&gt;Steven Morad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gielis_J/0/1/0/all/0/1&quot;&gt;Jennifer Gielis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qingbiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prorok_A/0/1/0/all/0/1&quot;&gt;Amanda Prorok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01778">
<title>Location inference on social media data for agile monitoring of public health crises: An application to opioid use and abuse during the Covid-19 pandemic. (arXiv:2111.01778v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2111.01778</link>
<description rdf:parseType="Literal">&lt;p&gt;The Covid-19 pandemic has intersected with the opioid epidemic to create a
unique public health crisis, with the health and economic consequences of the
virus and associated lockdowns compounding pre-existing social and economic
stressors associated with rising opioid and heroin use and abuse. In order to
better understand these interlocking crises, we use social media data to
extract qualitative and quantitative insights on the experiences of opioid
users during the Covid-19 pandemic. In particular, we use an unsupervised
learning approach to create a rich geolocated data source for public health
surveillance and analysis. To do this we first infer the location of 26,000
Reddit users that participate in opiate-related sub-communities (subreddits) by
combining named entity recognition, geocoding, density-based clustering, and
heuristic methods. Our strategy achieves 63 percent accuracy at state-level
location inference on a manually-annotated reference dataset. We then leverage
the geospatial nature of our user cohort to answer policy-relevant questions
about the impact of varying state-level policy approaches that balance economic
versus health concerns during Covid-19. We find that state government
strategies that prioritized economic reopening over curtailing the spread of
the virus created a markedly different environment and outcomes for opioid
users. Our results demonstrate that geospatial social media data can be used
for agile monitoring of complex public health crises.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilby_A/0/1/0/all/0/1&quot;&gt;Angela E. Kilby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denhart_C/0/1/0/all/0/1&quot;&gt;Charlie Denhart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01780">
<title>Game of Life on Graphs. (arXiv:2111.01780v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2111.01780</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a specific graph dynamical system inspired by the famous Conway&apos;s
Game of Life in this work. We study the properties of the dynamical system on
different graphs and introduce a new efficient heuristic for graph isomorphism
testing. We use the evolution of our system to extract features from a graph in
a deterministic way and observe that the extracted features are unique and the
distance induced by that features satisfy triangle inequality for all connected
graphs with up to ten vertices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krechetov_M/0/1/0/all/0/1&quot;&gt;Mikhail Krechetov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01784">
<title>Towards the 5/6-Density Conjecture of Pinwheel Scheduling. (arXiv:2111.01784v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2111.01784</link>
<description rdf:parseType="Literal">&lt;p&gt;Pinwheel Scheduling aims to find a perpetual schedule for unit-length tasks
on a single machine subject to given maximal time spans (a.k.a. frequencies)
between any two consecutive executions of the same task. The density of a
Pinwheel Scheduling instance is the sum of the inverses of these task
frequencies; the 5/6-Conjecture (Chan and Chin, 1993) states that any Pinwheel
Scheduling instance with density at most 5/6 is schedulable. We formalize the
notion of Pareto surfaces for Pinwheel Scheduling and exploit novel structural
insights to engineer an efficient algorithm for computing them. This allows us
to (1) confirm the 5/6-Conjecture for all Pinwheel Scheduling instances with at
most 12 tasks and (2) to prove that a given list of only 23 schedules solves
all schedulable Pinwheel Scheduling instances with at most 5 tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasieniec_L/0/1/0/all/0/1&quot;&gt;Leszek G&amp;#x105;sieniec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_B/0/1/0/all/0/1&quot;&gt;Benjamin Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wild_S/0/1/0/all/0/1&quot;&gt;Sebastian Wild&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01785">
<title>PatchGame: Learning to Signal Mid-level Patches in Referential Games. (arXiv:2111.01785v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2111.01785</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a referential game (a type of signaling game) where two agents
communicate with each other via a discrete bottleneck to achieve a common goal.
In our referential game, the goal of the speaker is to compose a message or a
symbolic representation of &quot;important&quot; image patches, while the task for the
listener is to match the speaker&apos;s message to a different view of the same
image. We show that it is indeed possible for the two agents to develop a
communication protocol without explicit or implicit supervision. We further
investigate the developed protocol and show the applications in speeding up
recent Vision Transformers by using only important patches, and as pre-training
for downstream recognition tasks (e.g., classification). Code available at
https://github.com/kampta/PatchGame.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1&quot;&gt;Kamal Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somepalli_G/0/1/0/all/0/1&quot;&gt;Gowthami Somepalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anubhav Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayasundara_V/0/1/0/all/0/1&quot;&gt;Vinoj Jayasundara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zwicker_M/0/1/0/all/0/1&quot;&gt;Matthias Zwicker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Abhinav Shrivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.01786">
<title>A Recommendation System to Enhance Midwives&apos; Capacities in Low-Income Countries. (arXiv:2111.01786v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2111.01786</link>
<description rdf:parseType="Literal">&lt;p&gt;Maternal and child mortality is a public health problem that
disproportionately affects low- and middle-income countries. Every day, 800
women and 6,700 newborns die from complications related to pregnancy or
childbirth. And for every maternal death, about 20 women suffer serious birth
injuries. However, nearly all of these deaths and negative health outcomes are
preventable. Midwives are key to revert this situation, and thus it is
essential to strengthen their capacities and the quality of their education.
This is the aim of the Safe Delivery App, a digital job aid and learning tool
to enhance the knowledge, confidence and skills of health practitioners. Here,
we use the behavioral logs of the App to implement a recommendation system that
presents each midwife with suitable contents to continue gaining expertise. We
focus on predicting the click-through rate, the probability that a given user
will click on a recommended content. We evaluate four deep learning models and
show that all of them produce highly accurate predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guitart_A/0/1/0/all/0/1&quot;&gt;Anna Guitart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heydari_A/0/1/0/all/0/1&quot;&gt;Afsaneh Heydari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olaleye_E/0/1/0/all/0/1&quot;&gt;Eniola Olaleye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ljubicic_J/0/1/0/all/0/1&quot;&gt;Jelena Ljubicic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rio_A/0/1/0/all/0/1&quot;&gt;Ana Fern&amp;#xe1;ndez del R&amp;#xed;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perianez_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;frica Peri&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bellhouse_L/0/1/0/all/0/1&quot;&gt;Lauren Bellhouse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09719">
<title>Learning convex polyhedra with margin. (arXiv:1805.09719v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09719</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an improved algorithm for {\em quasi-properly} learning convex
polyhedra in the realizable PAC setting from data with a margin. Our learning
algorithm constructs a consistent polyhedron as an intersection of about $t
\log t$ halfspaces with constant-size margins in time polynomial in $t$ (where
$t$ is the number of halfspaces forming an optimal polyhedron). We also
identify distinct generalizations of the notion of margin from hyperplanes to
polyhedra and investigate how they relate geometrically; this result may have
ramifications beyond the learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottlieb_L/0/1/0/all/0/1&quot;&gt;Lee-Ad Gottlieb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_E/0/1/0/all/0/1&quot;&gt;Eran Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1&quot;&gt;Aryeh Kontorovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nivasch_G/0/1/0/all/0/1&quot;&gt;Gabriel Nivasch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.03855">
<title>All those EPPA classes (Strengthenings of the Herwig-Lascar theorem). (arXiv:1902.03855v3 [math.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1902.03855</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we prove a general theorem showing the extension property for
partial automorphisms (EPPA, also called the Hrushovski property) for classes
of structures containing relations and unary functions, optionally equipped
with a permutation group of the language. The proof is elementary,
combinatorial and fully self-contained. Our result is a common strengthening of
the Herwig-Lascar theorem on EPPA for relational classes with forbidden
homomorphisms, the Hodkinson-Otto theorem on EPPA for relational free
amalgamation classes, its strengthening for unary functions by Evans,
Hubi\v{c}ka and Ne\v{s}et\v{r}il and their coherent variants by Siniora and
Solecki. We also prove an EPPA analogue of the main results of J. Hubi\v{c}ka
and J. Ne\v{s}et\v{r}il: All those Ramsey classes (Ramsey classes with closures
and forbidden homomorphisms), thereby establishing a common framework for
proving EPPA and the Ramsey property.
&lt;/p&gt;
&lt;p&gt;Our results have numerous applications, we include a solution of a problem
related to a class constructed by the Hrushovski predimension construction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hubicka_J/0/1/0/all/0/1&quot;&gt;Jan Hubi&amp;#x10d;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Konecny_M/0/1/0/all/0/1&quot;&gt;Mat&amp;#x11b;j Kone&amp;#x10d;n&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nesetril_J/0/1/0/all/0/1&quot;&gt;Jaroslav Ne&amp;#x161;et&amp;#x159;il&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.00715">
<title>Efficient Reinforcement Learning for StarCraft by Abstract Forward Models and Transfer Learning. (arXiv:1903.00715v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.00715</link>
<description rdf:parseType="Literal">&lt;p&gt;Injecting human knowledge is an effective way to accelerate reinforcement
learning (RL). However, these methods are underexplored. This paper presents
our discovery that an abstract forward model (thought-game (TG)) combined with
transfer learning (TL) is an effective way. We take StarCraft II as our study
environment. With the help of a designed TG, the agent can learn a 99% win-rate
on a 64x64 map against the Level-7 built-in AI, using only 1.08 hours in a
single commercial machine. We also show that the TG method is not as
restrictive as it was thought to be. It can work with roughly designed TGs, and
can also be useful when the environment changes. Comparing with previous
model-based RL, we show TG is more effective. We also present a TG hypothesis
that gives the influence of different fidelity levels of TG. For real games
that have unequal state and action spaces, we proposed a novel XfrNet of which
usefulness is validated while achieving a 90% win-rate against the cheating
Level-10 AI. We argue that the TG method might shed light on further studies of
efficient RL with human knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ruo-Ze Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Haifeng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1&quot;&gt;Xiaozhong Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_Z/0/1/0/all/0/1&quot;&gt;Zhen-Jia Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1&quot;&gt;Zitai Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuzhou Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1&quot;&gt;Tong Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1906.05799">
<title>Deep Reinforcement Learning for Cyber Security. (arXiv:1906.05799v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1906.05799</link>
<description rdf:parseType="Literal">&lt;p&gt;The scale of Internet-connected systems has increased considerably, and these
systems are being exposed to cyber attacks more than ever. The complexity and
dynamics of cyber attacks require protecting mechanisms to be responsive,
adaptive, and scalable. Machine learning, or more specifically deep
reinforcement learning (DRL), methods have been proposed widely to address
these issues. By incorporating deep learning into traditional RL, DRL is highly
capable of solving complex, dynamic, and especially high-dimensional cyber
defense problems. This paper presents a survey of DRL approaches developed for
cyber security. We touch on different vital aspects, including DRL-based
security methods for cyber-physical systems, autonomous intrusion detection
techniques, and multiagent DRL-based game theory simulations for defense
strategies against cyber attacks. Extensive discussions and future research
directions on DRL-based cyber security are also given. We expect that this
comprehensive review provides the foundations for and facilitates future
studies on exploring the potential of emerging DRL to cope with increasingly
complex cyber security problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh Thi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddi_V/0/1/0/all/0/1&quot;&gt;Vijay Janapa Reddi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1908.08384">
<title>Covering convex bodies and the Closest Vector Problem. (arXiv:1908.08384v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1908.08384</link>
<description rdf:parseType="Literal">&lt;p&gt;We present algorithms for the $(1+\epsilon)$-approximate version of the
closest vector problem for certain norms. The currently fastest algorithm
(Dadush and Kun 2016) for general norms has running time of $2^{O(n)}
(1/\epsilon)^n$. We improve this substantially in the following two cases. For
$\ell_p$-norms with $p&amp;gt;2$ (resp. $p \in [1,2]$) fixed, we present an algorithm
with a running time of $2^{O(n)} (1/\epsilon)^{n/2}$ (resp. $2^{O(n)}
(1/\epsilon)^{n/p}$). This result is based on a geometric covering problem,
that was introduced in the context of CVP by Eisenbrand et al.: How many convex
bodies are needed to cover the ball of the norm such that, if scaled by two
around their centroids, each one is contained in the $(1+\epsilon)$-scaled
homothet of the norm ball? We provide upper bounds for this problem by
exploiting the \emph{modulus of smoothness} of the $\ell_p$-balls. Applying a
covering scheme, we can boost any constant approximation algorithm for CVP to a
$(1+\epsilon)$-approximation algorithm with the improved run time, either using
a straightforward sampling routine or using the deterministic algorithm of
Dadush for the construction of an epsilon net. The space requirement only
depends on the constant approximation CVP solver used. Furthermore, we
generalise the result of Eisenbrand et al. for the $\ell_\infty$-norm. For
centrally symmetric polytopes (resp. zonotopes) with $O(n)$ facets (resp.
generated by $O(n)$ line segments), we provide a deterministic
$O(\log_2(1/\epsilon))^{O(n)}$ time algorithm. Finally, we establish a
connection between the \emph{modulus of smoothness} and \emph{lattice
sparsification}. Using the enumeration and sparsification tools developped by
Dadush, Kun, Peikert and Vempala, this leads to a simple alternative to the
boosting procedure for CVP under $\ell_p$-norms. This connection might be of
independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naszodi_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe1;rton Nasz&amp;#xf3;di&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venzin_M/0/1/0/all/0/1&quot;&gt;Moritz Venzin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.03438">
<title>Fast Diameter Computation within Split Graphs. (arXiv:1910.03438v5 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1910.03438</link>
<description rdf:parseType="Literal">&lt;p&gt;When can we compute the diameter of a graph in quasi linear time? We address
this question for the class of {\em split graphs}, that we observe to be the
hardest instances for deciding whether the diameter is at most two. We stress
that although the diameter of a non-complete split graph can only be either $2$
or $3$, under the Strong Exponential-Time Hypothesis (SETH) we cannot compute
the diameter of an $n$-vertex $m$-edge split graph in less than quadratic time
-- in the size $n+m$ of the input. Therefore it is worth to study the
complexity of diameter computation on {\em subclasses} of split graphs, in
order to better understand the complexity border. Specifically, we consider the
split graphs with bounded {\em clique-interval number} and their complements,
with the former being a natural variation of the concept of interval number for
split graphs that we introduce in this paper. We first discuss the relations
between the clique-interval number and other graph invariants such as the
classic interval number of graphs, the treewidth, the {\em VC-dimension} and
the {\em stabbing number} of a related hypergraph. Then, in part based on these
above relations, we almost completely settle the complexity of diameter
computation on these subclasses of split graphs: - For the $k$-clique-interval
split graphs, we can compute their diameter in truly subquadratic time if
$k={\cal O}(1)$, and even in quasi linear time if $k=o(\log{n})$ and in
addition a corresponding ordering of the vertices in the clique is given.
However, under SETH this cannot be done in truly subquadratic time for any $k =
\omega(\log{n})$. - For the {\em complements} of $k$-clique-interval split
graphs, we can compute their diameter in truly subquadratic time if $k={\cal
O}(1)$, and even in time ${\cal O}(km)$ if a corresponding ordering of the
vertices in the stable set is given. Again this latter result is optimal under
SETH up to polylogarithmic factors. Our findings raise the question whether a
$k$-clique interval ordering can always be computed in quasi linear time. We
prove that it is the case for $k=1$ and for some subclasses such as
bounded-treewidth split graphs, threshold graphs and comparability split
graphs. Finally, we prove that some important subclasses of split graphs --
including the ones mentioned above -- have a bounded clique-interval number.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ducoffe_G/0/1/0/all/0/1&quot;&gt;Guillaume Ducoffe&lt;/a&gt; (ICI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1&quot;&gt;Michel Habib&lt;/a&gt; (IRIF (UMR\_8243)), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viennot_L/0/1/0/all/0/1&quot;&gt;Laurent Viennot&lt;/a&gt; (GANG)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.05384">
<title>ORCCA: Optimal Randomized Canonical Correlation Analysis. (arXiv:1910.05384v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1910.05384</link>
<description rdf:parseType="Literal">&lt;p&gt;Random features approach has been widely used for kernel approximation in
large-scale machine learning. A number of recent studies have explored
data-dependent sampling of features, modifying the stochastic oracle from which
random features are sampled. While proposed techniques in this realm improve
the approximation, their suitability is often verified on a single learning
task. In this paper, we propose a task-specific scoring rule for selecting
random features, which can be employed for different applications with some
adjustments. We restrict our attention to Canonical Correlation Analysis (CCA),
and we provide a novel, principled guide for finding the score function
maximizing the canonical correlations. We prove that this method, called ORCCA,
can outperform (in expectation) the corresponding Kernel CCA with a default
kernel. Numerical experiments verify that ORCCA is significantly superior than
other approximation techniques in the CCA task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yinsong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahrampour_S/0/1/0/all/0/1&quot;&gt;Shahin Shahrampour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.05674">
<title>Structure-preserving Interpolatory Model Reduction for Port-Hamiltonian Differential-Algebraic Systems. (arXiv:1910.05674v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1910.05674</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine interpolatory model reduction methods that are well-suited for
treating large scale port-Hamiltonian differential-algebraic systems in a way
that is able to preserve and indeed, take advantage of the underlying
structural features of the system. We introduce approaches that incorporate
regularization together with prudent selection of interpolation data. We focus
on linear time-invariant systems and present a systematic treatment of a
variety of model classes that include combinations of index-$1$ and index-$2$
systems, describing in particular how constraints may be represented in the
transfer function and then preserved with interpolatory methods. We propose an
algorithm to generate effective interpolation data and illustrate its
effectiveness via two numerical examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Beattie_C/0/1/0/all/0/1&quot;&gt;Chris A. Beattie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gugercin_S/0/1/0/all/0/1&quot;&gt;Serkan Gugercin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mehrmann_V/0/1/0/all/0/1&quot;&gt;Volker Mehrmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1911.04853">
<title>Spatially-Stationary Model for Holographic MIMO Small-Scale Fading. (arXiv:1911.04853v4 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1911.04853</link>
<description rdf:parseType="Literal">&lt;p&gt;Imagine an array with a massive (possibly uncountably infinite) number of
antennas in a compact space. We refer to a system of this sort as Holographic
MIMO. Given the impressive properties of Massive MIMO, one might expect a
holographic array to realize extreme spatial resolution, incredible energy
efficiency, and unprecedented spectral efficiency. At present, however, its
fundamental limits have not been conclusively established. A major challenge
for the analysis and understanding of such a paradigm shift is the lack of
mathematically tractable and numerically reproducible channel models that
retain some semblance to the physical reality. Detailed physical models are, in
general, too complex for tractable analysis. This paper aims to take a closer
look at this interdisciplinary challenge. Particularly, we consider the
small-scale fading in the far-field, and we model it as a zero-mean,
spatially-stationary, and correlated Gaussian scalar random field.
Physically-meaningful correlation is obtained by requiring that the random
field be consistent with the scalar Helmholtz equation. This formulation leads
directly to a rather simple and exact description of the three-dimensional
small-scale fading as a Fourier plane-wave spectral representation. Suitably
discretized, this leads to a discrete representation for the field as a Fourier
plane-wave series expansion, from which a computationally efficient way to
generate samples of the small-scale fading over spatially-constrained compact
spaces is developed. The connections with the conventional tools of linear
systems theory and Fourier transform are thoroughly discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pizzo_A/0/1/0/all/0/1&quot;&gt;Andrea Pizzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marzetta_T/0/1/0/all/0/1&quot;&gt;Thomas L. Marzetta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanguinetti_L/0/1/0/all/0/1&quot;&gt;Luca Sanguinetti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2001.04385">
<title>Universal Differential Equations for Scientific Machine Learning. (arXiv:2001.04385v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2001.04385</link>
<description rdf:parseType="Literal">&lt;p&gt;In the context of science, the well-known adage &quot;a picture is worth a
thousand words&quot; might well be &quot;a model is worth a thousand datasets.&quot; In this
manuscript we introduce the SciML software ecosystem as a tool for mixing the
information of physical laws and scientific models with data-driven machine
learning approaches. We describe a mathematical object, which we denote
universal differential equations (UDEs), as the unifying framework connecting
the ecosystem. We show how a wide variety of applications, from automatically
discovering biological mechanisms to solving high-dimensional
Hamilton-Jacobi-Bellman equations, can be phrased and efficiently handled
through the UDE formalism and its tooling. We demonstrate the generality of the
software tooling to handle stochasticity, delays, and implicit constraints.
This funnels the wide variety of SciML applications into a core set of training
mechanisms which are highly optimized, stabilized for stiff equations, and
compatible with distributed parallelism and GPU accelerators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rackauckas_C/0/1/0/all/0/1&quot;&gt;Christopher Rackauckas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yingbo Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martensen_J/0/1/0/all/0/1&quot;&gt;Julius Martensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warner_C/0/1/0/all/0/1&quot;&gt;Collin Warner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zubov_K/0/1/0/all/0/1&quot;&gt;Kirill Zubov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Supekar_R/0/1/0/all/0/1&quot;&gt;Rohit Supekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skinner_D/0/1/0/all/0/1&quot;&gt;Dominic Skinner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramadhan_A/0/1/0/all/0/1&quot;&gt;Ali Ramadhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edelman_A/0/1/0/all/0/1&quot;&gt;Alan Edelman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2002.02051">
<title>Robust multigrid methods for nearly incompressible elasticity using macro elements. (arXiv:2002.02051v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2002.02051</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a mesh-independent and parameter-robust multigrid solver for the
Scott-Vogelius discretisation of the nearly incompressible linear elasticity
equations on meshes with a macro element structure. The discretisation achieves
exact representation of the limiting divergence constraint at moderate
polynomial degree. Both the relaxation and multigrid transfer operators exploit
the macro structure for robustness and efficiency. For the relaxation, we use
the existence of local Fortin operators on each macro cell to construct a local
space decomposition with parameter-robust convergence. For the transfer, we
construct a robust prolongation operator by performing small local solves over
each coarse macro cell. The necessity of both components of the algorithm is
confirmed by numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Farrell_P/0/1/0/all/0/1&quot;&gt;Patrick E. Farrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mitchell_L/0/1/0/all/0/1&quot;&gt;Lawrence Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scott_L/0/1/0/all/0/1&quot;&gt;L. Ridgway Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wechsung_F/0/1/0/all/0/1&quot;&gt;Florian Wechsung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2003.08904">
<title>RAB: Provable Robustness Against Backdoor Attacks. (arXiv:2003.08904v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2003.08904</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have shown that deep neural networks (DNNs) are vulnerable to
adversarial attacks, including evasion and backdoor (poisoning) attacks. On the
defense side, there have been intensive efforts on improving both empirical and
provable robustness against evasion attacks; however, provable robustness
against backdoor attacks still remains largely unexplored. In this paper, we
focus on certifying the machine learning model robustness against general
threat models, especially backdoor attacks. We first provide a unified
framework via randomized smoothing techniques and show how it can be
instantiated to certify the robustness against both evasion and backdoor
attacks. We then propose the first robust training process, RAB, to smooth the
trained model and certify its robustness against backdoor attacks. We derive
the robustness bound for machine learning models trained with RAB, and prove
that our robustness bound is tight. In addition, we show that it is possible to
train the robust smoothed models efficiently for simple models such as
K-nearest neighbor classifiers, and we propose an exact smooth-training
algorithm which eliminates the need to sample from a noise distribution for
such models. Empirically, we conduct comprehensive experiments for different
machine learning (ML) models such as DNNs, differentially private DNNs, and
K-NN models on MNIST, CIFAR-10 and ImageNet datasets, and provide the first
benchmark for certified robustness against backdoor attacks. In addition, we
evaluate K-NN models on a spambase tabular dataset to demonstrate the
advantages of the proposed exact algorithm. Both the theoretic analysis and the
comprehensive evaluation on diverse ML models and datasets shed lights on
further robust learning strategies against general training time attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1&quot;&gt;Maurice Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaojun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1&quot;&gt;Bojan Karla&amp;#x161;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2005.11290">
<title>Internal Parametricity for Cubical Type Theory. (arXiv:2005.11290v5 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/2005.11290</link>
<description rdf:parseType="Literal">&lt;p&gt;We define a computational type theory combining the contentful equality
structure of cartesian cubical type theory with internal parametricity
primitives. The combined theory supports both univalence and its relational
equivalent, which we call relativity. We demonstrate the use of the theory by
analyzing polymorphic functions between higher inductive types, observe how
cubical equality regularizes parametric type theory, and examine the
similarities and discrepancies between cubical and parametric type theory,
which are closely related. We also abstract a formal interface to the
computational interpretation and show that this also has a presheaf model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cavallo_E/0/1/0/all/0/1&quot;&gt;Evan Cavallo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harper_R/0/1/0/all/0/1&quot;&gt;Robert Harper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.04202">
<title>Probabilistic Timed Automata with One Clock and Initialised Clock-Dependent Probabilities. (arXiv:2006.04202v5 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/2006.04202</link>
<description rdf:parseType="Literal">&lt;p&gt;Clock-dependent probabilistic timed automata extend classical timed automata
with discrete probabilistic choice, where the probabilities are allowed to
depend on the exact values of the clocks. Previous work has shown that the
quantitative reachability problem for clock-dependent probabilistic timed
automata with at least three clocks is undecidable. In this paper, we consider
the subclass of clock-dependent probabilistic timed automata that have one
clock, that have clock dependencies described by affine functions, and that
satisfy an initialisation condition requiring that, at some point between
taking edges with non-trivial clock dependencies, the clock must have an
integer value. We present an approach for solving in polynomial time
quantitative and qualitative reachability problems of such one-clock
initialised clock-dependent probabilistic timed automata. Our results are
obtained by a transformation to interval Markov decision processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sproston_J/0/1/0/all/0/1&quot;&gt;Jeremy Sproston&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.06555">
<title>Multi-Agent Reinforcement Learning in Stochastic Networked Systems. (arXiv:2006.06555v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.06555</link>
<description rdf:parseType="Literal">&lt;p&gt;We study multi-agent reinforcement learning (MARL) in a stochastic network of
agents. The objective is to find localized policies that maximize the
(discounted) global reward. In general, scalability is a challenge in this
setting because the size of the global state/action space can be exponential in
the number of agents. Scalable algorithms are only known in cases where
dependencies are static, fixed and local, e.g., between neighbors in a fixed,
time-invariant underlying graph. In this work, we propose a Scalable Actor
Critic framework that applies in settings where the dependencies can be
non-local and stochastic, and provide a finite-time error bound that shows how
the convergence rate depends on the speed of information spread in the network.
Additionally, as a byproduct of our analysis, we obtain novel finite-time
convergence results for a general stochastic approximation scheme and for
temporal difference learning with state aggregation, which apply beyond the
setting of MARL in networked systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yiheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_G/0/1/0/all/0/1&quot;&gt;Guannan Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.06721">
<title>Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks. (arXiv:2006.06721v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.06721</link>
<description rdf:parseType="Literal">&lt;p&gt;Backdoor attacks mislead machine-learning models to output an
attacker-specified class when presented a specific trigger at test time. These
attacks require poisoning the training data to compromise the learning
algorithm, e.g., by injecting poisoning samples containing the trigger into the
training set, along with the desired class label. Despite the increasing number
of studies on backdoor attacks and defenses, the underlying factors affecting
the success of backdoor attacks, along with their impact on the learning
algorithm, are not yet well understood. In this work, we aim to shed light on
this issue by unveiling that backdoor attacks induce a smoother decision
function around the triggered samples -- a phenomenon which we refer to as
\textit{backdoor smoothing}. To quantify backdoor smoothing, we define a
measure that evaluates the uncertainty associated to the predictions of a
classifier around the input samples.
&lt;/p&gt;
&lt;p&gt;Our experiments show that smoothness increases when the trigger is added to
the input samples, and that this phenomenon is more pronounced for more
successful attacks.
&lt;/p&gt;
&lt;p&gt;We also provide preliminary evidence that backdoor triggers are not the only
smoothing-inducing patterns, but that also other artificial patterns can be
detected by our approach, paving the way towards understanding the limitations
of current defenses and designing novel ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1&quot;&gt;Kathrin Grosse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Taesung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1&quot;&gt;Battista Biggio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Youngja Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1&quot;&gt;Ian Molloy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.09647">
<title>Regulating algorithmic filtering on social media. (arXiv:2006.09647v4 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2006.09647</link>
<description rdf:parseType="Literal">&lt;p&gt;By filtering the content that users see, social media platforms have the
ability to influence users&apos; perceptions and decisions, from their dining
choices to their voting preferences. This influence has drawn scrutiny, with
many calling for regulations on filtering algorithms, but designing and
enforcing regulations remains challenging. In this work, we examine three
questions. First, given a regulation, how would one design an audit to enforce
it? Second, does the audit impose a performance cost on the platform? Third,
how does the audit affect the content that the platform is incentivized to
filter? In response, we propose a method such that, given a regulation, an
auditor can test whether that regulation is met with only black-box access to
the filtering algorithm. We then turn to the platform&apos;s perspective. The
platform&apos;s goal is to maximize an objective function while meeting regulation.
We find that there are conditions under which the regulation does not place a
high performance cost on the platform and, notably, that content diversity can
play a key role in aligning the interests of the platform and regulators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1&quot;&gt;Sarah H. Cen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1&quot;&gt;Devavrat Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.14841">
<title>Not all Failure Modes are Created Equal: Training Deep Neural Networks for Explicable (Mis)Classification. (arXiv:2006.14841v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.14841</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks are often brittle on image classification tasks and
known to misclassify inputs. While these misclassifications may be inevitable,
all failure modes cannot be considered equal. Certain misclassifications (eg.
classifying the image of a dog to an airplane) can perplex humans and result in
the loss of human trust in the system. Even worse, these errors (eg. a person
misclassified as a primate) can have odious societal impacts. Thus, in this
work, we aim to reduce inexplicable errors. To address this challenge, we first
discuss methods to obtain the class-level semantics that capture the human&apos;s
expectation ($M^h$) regarding which classes are semantically close {\em vs.}
ones that are far away. We show that for popular image benchmarks (like
CIFAR-10, CIFAR-100, ImageNet), class-level semantics can be readily obtained
by leveraging either human subject studies or publicly available human-curated
knowledge bases. Second, we propose the use of Weighted Loss Functions (WLFs)
to penalize misclassifications by the weight of their inexplicability. Finally,
we show that training (or fine-tuning) existing classifiers with the proposed
methods lead to Deep Neural Networks that have (1) comparable top-1 accuracy,
(2) more explicable failure modes on both in-distribution and
out-of-distribution (OOD) test data, and (3) incur significantly less cost in
the gathering of additional human labels compared to existing works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olmo_A/0/1/0/all/0/1&quot;&gt;Alberto Olmo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1&quot;&gt;Sailik Sengupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.06319">
<title>In-place implementation of Quantum-Gimli. (arXiv:2007.06319v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2007.06319</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an in-place implementation of the cryptographic permutation
\textbf{Gimli}, a NIST round 2 candidate for lightweight cryptography, and
provide an upper bound for the required quantum resource in depth and
gate-counts. In particular, we do not use any ancilla qubits and the state that
our circuit produces is not entangled with any input. This offers further
freedom in the usability and allows for a widespread use in different
applications in a plug-and-play manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlieper_L/0/1/0/all/0/1&quot;&gt;Lars Schlieper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.07053">
<title>Unsupervised 3D Human Pose Representation with Viewpoint and Pose Disentanglement. (arXiv:2007.07053v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2007.07053</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a good 3D human pose representation is important for human pose
related tasks, e.g. human 3D pose estimation and action recognition. Within all
these problems, preserving the intrinsic pose information and adapting to view
variations are two critical issues. In this work, we propose a novel Siamese
denoising autoencoder to learn a 3D pose representation by disentangling the
pose-dependent and view-dependent feature from the human skeleton data, in a
fully unsupervised manner. These two disentangled features are utilized
together as the representation of the 3D pose. To consider both the kinematic
and geometric dependencies, a sequential bidirectional recursive network
(SeBiReNet) is further proposed to model the human skeleton data. Extensive
experiments demonstrate that the learned representation 1) preserves the
intrinsic information of human pose, 2) shows good transferability across
datasets and tasks. Notably, our approach achieves state-of-the-art performance
on two inherently different tasks: pose denoising and unsupervised action
recognition. Code and models are available at:
\url{https://github.com/NIEQiang001/unsupervised-human-pose.git}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_Q/0/1/0/all/0/1&quot;&gt;Qiang Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yunhui Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.08792">
<title>Uncertainty Quantification and Deep Ensembles. (arXiv:2007.08792v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2007.08792</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning methods are known to suffer from calibration issues: they
typically produce over-confident estimates. These problems are exacerbated in
the low data regime. Although the calibration of probabilistic models is well
studied, calibrating extremely over-parametrized models in the low-data regime
presents unique challenges. We show that deep-ensembles do not necessarily lead
to improved calibration properties. In fact, we show that standard ensembling
methods, when used in conjunction with modern techniques such as mixup
regularization, can lead to less calibrated models. This text examines the
interplay between three of the most simple and commonly used approaches to
leverage deep learning when data is scarce: data-augmentation, ensembling, and
post-processing calibration methods. Although standard ensembling techniques
certainly help boost accuracy, we demonstrate that the calibration of deep
ensembles relies on subtle trade-offs. We also find that calibration methods
such as temperature scaling need to be slightly tweaked when used with
deep-ensembles and, crucially, need to be executed after the averaging process.
Our simulations indicate that this simple strategy can halve the Expected
Calibration Error (ECE) on a range of benchmark classification problems
compared to standard deep-ensembles in the low data regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rahaman_R/0/1/0/all/0/1&quot;&gt;Rahul Rahaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thiery_A/0/1/0/all/0/1&quot;&gt;Alexandre H. Thiery&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.10174">
<title>Multi-Server Weakly-Private Information Retrieval. (arXiv:2007.10174v3 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/2007.10174</link>
<description rdf:parseType="Literal">&lt;p&gt;Private information retrieval (PIR) protocols ensure that a user can download
a file from a database without revealing any information on the identity of the
requested file to the servers storing the database. While existing protocols
strictly impose that no information is leaked on the file&apos;s identity, this work
initiates the study of the tradeoffs that can be achieved by relaxing the
perfect privacy requirement. We refer to such protocols as weakly-private
information retrieval (WPIR) protocols. In particular, for the case of multiple
noncolluding replicated servers, we study how the download rate, the upload
cost, and the access complexity can be improved when relaxing the full privacy
constraint. To quantify the information leakage on the requested file&apos;s
identity we consider mutual information (MI), worst-case information leakage,
and maximal leakage (MaxL). We present two WPIR schemes, denoted by Scheme A
and Scheme B, based on two recent PIR protocols and show that the download rate
of the former can be optimized by solving a convex optimization problem. We
also show that Scheme A achieves an improved download rate compared to the
recently proposed scheme by Samy et al. under the so-called $\epsilon$-privacy
metric. Additionally, a family of schemes based on partitioning is presented.
Moreover, we provide an information-theoretic converse bound for the maximum
possible download rate for the MI and MaxL privacy metrics under a practical
restriction on the alphabet size of queries and answers. For two servers and
two files, the bound is tight under the MaxL metric, which settles the WPIR
capacity in this particular case. Finally, we compare the performance of the
proposed schemes and their gap to the converse bound.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Yin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Siddhartha Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosnes_E/0/1/0/all/0/1&quot;&gt;Eirik Rosnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amat_A/0/1/0/all/0/1&quot;&gt;Alexandre Graell i Amat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaakobi_E/0/1/0/all/0/1&quot;&gt;Eitan Yaakobi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.05208">
<title>Complexity of Maximizing Convergence Time in Network Consensus Dynamics Subject to Edge Removal. (arXiv:2009.05208v3 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2009.05208</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the consensus interdiction problem (CIP), in which the goal is to
maximize the convergence time of consensus dynamics subject to removing a
limited number of network edges. We first show that CIP can be cast as an
effective resistance interdiction problem (ERIP), in which the goal is to
remove a limited number of network edges to maximize the effective resistance
between a source node and a sink node. We show that ERIP is strongly NP-hard,
even for bipartite graphs of diameter three with fixed edges incident to the
source/sink. We establish the same hardness result for the CIP, hence
correcting some claims in the past literature. We then show that both ERIP and
CIP do not admit polynomial-time approximation schemes, and moreover, they
cannot be approximated up to a (nearly) polynomial factor assuming exponential
time hypothesis. Subsequently, we devise a polynomial-time $mn$-approximation
algorithm for the ERIP that only depends on the number of nodes $n$ and the
number of edges $m$, but is independent of the size of edge resistances.
Finally, using a quadratic program formulation for the CIP, we devise an
approximation algorithm to find a local optimal solution for the CIP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Etesami_S/0/1/0/all/0/1&quot;&gt;S. Rasoul Etesami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.07773">
<title>SideLine: How Delay-Lines (May) Leak Secrets from your SoC. (arXiv:2009.07773v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2009.07773</link>
<description rdf:parseType="Literal">&lt;p&gt;To meet the ever-growing need for performance in silicon devices, SoC
providers have been increasingly relying on software-hardware cooperation. By
controlling hardware resources such as power or clock management from the
software, developers earn the possibility to build more flexible and power
efficient applications. Despite the benefits, these hardware components are now
exposed to software code and can potentially be misused as open-doors to
jeopardize trusted environments, perform privilege escalation or steal
cryptographic secrets. In this work, we introduce SideLine, a novel
side-channel vector based on delay-line components widely implemented in
high-end SoCs. After providing a detailed method on how to access and convert
delay-line data into power consumption information, we demonstrate that these
entities can be used to perform remote power side-channel attacks. We report
experiments carried out on two SoCs from distinct vendors and we recount
several core-vs-core attack scenarios in which an adversary process located in
one processor core aims at eavesdropping the activity of a victim process
located in another core. For each scenario, we demonstrate the adversary
ability to fully recover the secret key of an OpenSSL AES running in the victim
core. Even more detrimental, we show that these attacks are still practicable
if the victim or the attacker program runs over an operating system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gravellier_J/0/1/0/all/0/1&quot;&gt;Joseph Gravellier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutertre_J/0/1/0/all/0/1&quot;&gt;Jean-Max Dutertre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teglia_Y/0/1/0/all/0/1&quot;&gt;Yannick Teglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moundi_P/0/1/0/all/0/1&quot;&gt;Philippe Loubet Moundi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.00300">
<title>OutbreakFlow: Model-based Bayesian inference of disease outbreak dynamics with invertible neural networks and its application to the COVID-19 pandemics in Germany. (arXiv:2010.00300v4 [stat.AP] UPDATED)</title>
<link>http://arxiv.org/abs/2010.00300</link>
<description rdf:parseType="Literal">&lt;p&gt;Mathematical models in epidemiology are an indispensable tool to determine
the dynamics and important characteristics of infectious diseases. Apart from
their scientific merit, these models are often used to inform political
decisions and intervention measures during an ongoing outbreak. However,
reliably inferring the dynamics of ongoing outbreaks by connecting complex
models to real data is still hard and requires either laborious manual
parameter fitting or expensive optimization methods which have to be repeated
from scratch for every application of a given model. In this work, we address
this problem with a novel combination of epidemiological modeling with
specialized neural networks. Our approach entails two computational phases: In
an initial training phase, a mathematical model describing the epidemic is used
as a coach for a neural network, which acquires global knowledge about the full
range of possible disease dynamics. In the subsequent inference phase, the
trained neural network processes the observed data of an actual outbreak and
infers the parameters of the model in order to realistically reproduce the
observed dynamics and reliably predict future progression. With its flexible
framework, our simulation-based approach is applicable to a variety of
epidemiological models. Moreover, since our method is fully Bayesian, it is
designed to incorporate all available prior knowledge about plausible parameter
values and returns complete joint posterior distributions over these
parameters. Application of our method to the early Covid-19 outbreak phase in
Germany demonstrates that we are able to obtain reliable probabilistic
estimates for important disease characteristics, such as generation time,
fraction of undetected infections, likelihood of transmission before symptom
onset, and reporting delays using a very moderate amount of real-world
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Radev_S/0/1/0/all/0/1&quot;&gt;Stefan T. Radev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graw_F/0/1/0/all/0/1&quot;&gt;Frederik Graw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Simiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mutters_N/0/1/0/all/0/1&quot;&gt;Nico T. Mutters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eichel_V/0/1/0/all/0/1&quot;&gt;Vanessa M. Eichel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barnighausen_T/0/1/0/all/0/1&quot;&gt;Till B&amp;#xe4;rnighausen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kothe_U/0/1/0/all/0/1&quot;&gt;Ullrich K&amp;#xf6;the&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.01748">
<title>Policy Learning Using Weak Supervision. (arXiv:2010.01748v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.01748</link>
<description rdf:parseType="Literal">&lt;p&gt;Most existing policy learning solutions require the learning agents to
receive high-quality supervision signals such as well-designed rewards in
reinforcement learning (RL) or high-quality expert demonstrations in behavioral
cloning (BC). These quality supervisions are usually infeasible or
prohibitively expensive to obtain in practice. We aim for a unified framework
that leverages the available cheap weak supervisions to perform policy learning
efficiently. To handle this problem, we treat the &quot;weak supervision&quot; as
imperfect information coming from a peer agent, and evaluate the learning
agent&apos;s policy based on a &quot;correlated agreement&quot; with the peer agent&apos;s policy
(instead of simple agreements). Our approach explicitly punishes a policy for
overfitting to the weak supervision. In addition to theoretical guarantees,
extensive evaluations on tasks including RL with noisy rewards, BC with weak
demonstrations, and standard policy co-training show that our method leads to
substantial performance improvements, especially when the complexity or the
noise of the learning environments is high.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingkang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Hongyi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhaowei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.04030">
<title>Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using Deep Shape Priors. (arXiv:2010.04030v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2010.04030</link>
<description rdf:parseType="Literal">&lt;p&gt;Representing scenes at the granularity of objects is a prerequisite for scene
understanding and decision making. We propose PriSMONet, a novel approach based
on Prior Shape knowledge for learning Multi-Object 3D scene decomposition and
representations from single images. Our approach learns to decompose images of
synthetic scenes with multiple objects on a planar surface into its constituent
scene objects and to infer their 3D properties from a single view. A recurrent
encoder regresses a latent representation of 3D shape, pose and texture of each
object from an input RGB image. By differentiable rendering, we train our model
to decompose scenes from RGB-D images in a self-supervised way. The 3D shapes
are represented continuously in function-space as signed distance functions
which we pre-train from example shapes in a supervised way. These shape priors
provide weak supervision signals to better condition the challenging overall
learning task. We evaluate the accuracy of our model in inferring 3D scene
layout, demonstrate its generative capabilities, assess its generalization to
real images, and point out benefits of the learned representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elich_C/0/1/0/all/0/1&quot;&gt;Cathrin Elich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1&quot;&gt;Martin R. Oswald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1&quot;&gt;Marc Pollefeys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stueckler_J/0/1/0/all/0/1&quot;&gt;Joerg Stueckler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.05178">
<title>Further Investigation of the Survivability of Code Technical Debt Items. (arXiv:2010.05178v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2010.05178</link>
<description rdf:parseType="Literal">&lt;p&gt;Context: Technical Debt (TD) discusses the negative impact of sub-optimal
decisions to cope with the need-for-speed in software development. Code
Technical Debt Items (TDI) are atomic elements of TD that can be observed in
code artefacts. Empirical results on open-source systems demonstrated how
code-smells, which are just one type of TDIs, are introduced and &quot;survive&quot;
during release cycles. However, little is known about whether the results on
the survivability of code-smells hold for other types of code TDIs (i.e., bugs
and vulnerabilities) and in industrial settings. Goal: Understanding the
survivability of code TDIs by conducting an empirical study analysing two
industrial cases and 31 open-source systems from Apache Foundation. Method: We
analysed 133,670 code TDIs (35,703 from the industrial systems) detected by
SonarQube (in 193,196 commits) to assess their survivability using
survivability models. Results: In general, code TDIs tend to remain and linger
for long periods in open-source systems, whereas they are removed faster in
industrial systems. Code TDIs that survive over a certain threshold tend to
remain much longer, which confirms previous results. Our results also suggest
that bugs tend to be removed faster, while code smells and vulnerabilities tend
to survive longer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zabardast_E/0/1/0/all/0/1&quot;&gt;Ehsan Zabardast&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennin_K/0/1/0/all/0/1&quot;&gt;Kwabena Ebo Bennin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Huerta_J/0/1/0/all/0/1&quot;&gt;Javier Gonzalez-Huerta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.08572">
<title>Horizon-independent Preconditioner Design for Linear Predictive Control. (arXiv:2010.08572v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2010.08572</link>
<description rdf:parseType="Literal">&lt;p&gt;First-order optimization solvers, such as the Fast Gradient Method, are
increasingly being used to solve Model Predictive Control problems in
resource-constrained environments. Unfortunately, the convergence rate of these
solvers is significantly affected by the conditioning of the problem data, with
ill-conditioned problems requiring a large number of iterations. To reduce the
number of iterations required, we present a simple method for computing a
horizon-independent preconditioning matrix for the Hessian of the condensed
problem. The preconditioner is based on the block Toeplitz structure of the
Hessian. Horizon-independence allows one to use only the predicted system and
cost matrices to compute the preconditioner, instead of the full Hessian. The
proposed preconditioner has equivalent performance to an optimal preconditioner
in numerical examples, producing speedups between 2x and 9x for the Fast
Gradient Method. Additionally, we derive horizon-independent spectral bounds
for the Hessian in terms of the transfer function of the predicted system, and
show how these can be used to compute a novel horizon-independent bound on the
condition number for the preconditioned Hessian.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+McInerney_I/0/1/0/all/0/1&quot;&gt;Ian McInerney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kerrigan_E/0/1/0/all/0/1&quot;&gt;Eric C. Kerrigan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Constantinides_G/0/1/0/all/0/1&quot;&gt;George A. Constantinides&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.13363">
<title>Provable Memorization via Deep Neural Networks using Sub-linear Parameters. (arXiv:2010.13363v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.13363</link>
<description rdf:parseType="Literal">&lt;p&gt;It is known that $O(N)$ parameters are sufficient for neural networks to
memorize arbitrary $N$ input-label pairs. By exploiting depth, we show that
$O(N^{2/3})$ parameters suffice to memorize $N$ pairs, under a mild condition
on the separation of input points. In particular, deeper networks (even with
width $3$) are shown to memorize more pairs than shallow networks, which also
agrees with the recent line of works on the benefits of depth for function
approximation. We also provide empirical results that support our theoretical
findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sejun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaeho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_C/0/1/0/all/0/1&quot;&gt;Chulhee Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.02609">
<title>Cooperative Learning for P2P Energy Trading via Inverse Optimization and Interval Analysis. (arXiv:2011.02609v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2011.02609</link>
<description rdf:parseType="Literal">&lt;p&gt;Peer-to-peer (P2P) energy systems have recently emerged as a promising
approach for integrating renewable and distributed energy resources into energy
grids to reduce carbon emissions. However, market-clearing energy price and
amounts, resulted from solving optimal P2P energy management problems, might
not be satisfactory for peers/agents. This is because peers/agents in practice
do not know how to set their cost function parameters when participating into
P2P energy markets. To resolve such drawback, this paper proposes a novel
approach, in which an inverse optimization problem is formulated for
peers/agents to cooperatively learn to choose their objective function
parameters, given their intervals of desired energy prices and amounts. The
result is that peers/agents can set their objective function parameters in the
intervals computed analytically from the lower and upper bounds of their energy
price and amounts, if the ratio of their maximum total buying and selling
energy amounts lies in a certain interval subject to be learned by them. A case
study is then carried out, which validates the effectiveness of the proposed
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dinh Hoa Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.11201">
<title>Modular Action Concept Grounding in Semantic Video Prediction. (arXiv:2011.11201v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2011.11201</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works in video prediction have mainly focused on passive forecasting
and low-level action-conditional prediction, which sidesteps the learning of
interaction between agents and objects. We introduce the task of semantic
action-conditional video prediction, which uses semantic action labels to
describe those interactions and can be regarded as an inverse problem of action
recognition. The challenge of this new task primarily lies in how to
effectively inform the model of semantic action information. Inspired by the
idea of Mixture of Experts, we embody each abstract label by a structured
combination of various visual concept learners and propose a novel video
prediction model, Modular Action Concept Network (MAC). Our method is evaluated
on two newly designed synthetic datasets, CLEVR-Building-Blocks and
Sapien-Kitchen, and one real-world dataset called Tower-Creation. Extensive
experiments demonstrate that MAC can correctly condition on given instructions
and generate corresponding future frames without need of bounding boxes. We
further show that the trained model can make out-of-distribution
generalization, be quickly adapted to new object categories and exploit its
learnt features for object detection, showing the progression towards
higher-level cognitive abilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1&quot;&gt;Songhenh Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Easterbrook_S/0/1/0/all/0/1&quot;&gt;Steve Easterbrook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1&quot;&gt;Animesh Garg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.12635">
<title>The Hydrostructure: a Universal Framework for Safe and Complete Algorithms for Genome Assembly. (arXiv:2011.12635v3 [cs.DM] UPDATED)</title>
<link>http://arxiv.org/abs/2011.12635</link>
<description rdf:parseType="Literal">&lt;p&gt;Genome assembly is a fundamental problem in Bioinformatics, requiring to
reconstruct a source genome from an assembly graph built from a set of reads
(short strings sequenced from the genome). A notion of genome assembly solution
is that of an arc-covering walk of the graph. Since assembly graphs admit many
solutions, the goal is to find what is definitely present in all solutions, or
what is safe. Most practical assemblers are based on heuristics having at their
core unitigs, namely paths whose internal nodes have unit in-degree and
out-degree, and which are clearly safe. The long-standing open problem of
finding all the safe parts of the solutions was recently solved [RECOMB 2016]
yielding a 60% increase in contig length. This safe and complete genome
assembly algorithm was followed by other works improving the time bounds, as
well as extending the results for different notions of assembly solution. But
it remained open whether one can be complete also for models of genome assembly
of practical applicability.
&lt;/p&gt;
&lt;p&gt;In this paper we present a universal framework for obtaining safe and
complete algorithms which unify the previous results, while also allowing for
easy generalisations to assembly problems including many practical aspects.
This is based on a novel graph structure, called the hydrostructure of a walk,
which highlights the reachability properties of the graph from the perspective
of the walk. The hydrostructure allows for simple characterisations of the
existing safe walks, and of their new practical versions. Almost all of our
characterisations are directly adaptable to optimal verification algorithms,
and simple enumeration algorithms. Most of these algorithms are also improved
to optimality using an incremental computation procedure and a previous optimal
algorithm of a specific model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cairo_M/0/1/0/all/0/1&quot;&gt;Massimo Cairo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Shahbaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_R/0/1/0/all/0/1&quot;&gt;Romeo Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_S/0/1/0/all/0/1&quot;&gt;Sebastian Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1&quot;&gt;Alexandru I. Tomescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zirondelli_E/0/1/0/all/0/1&quot;&gt;Elia C. Zirondelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.00517">
<title>One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2012.00517</link>
<description rdf:parseType="Literal">&lt;p&gt;Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT&apos;s MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1&quot;&gt;Joni Korpihalkola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1&quot;&gt;Tuomo Sipola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1&quot;&gt;Samir Puuska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1&quot;&gt;Tero Kokkonen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.10496">
<title>Factorization of Binary Matrices: Rank Relations, Uniqueness and Model Selection of Boolean Decomposition. (arXiv:2012.10496v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2012.10496</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of binary matrices are numerous. Representing a matrix as a
mixture of a small collection of latent vectors via low-rank decomposition is
often seen as an advantageous method to interpret and analyze data. In this
work, we examine the factorizations of binary matrices using standard
arithmetic (real and nonnegative) and logical operations (Boolean and
$\mathbb{Z}_2$). We examine the relationships between the different ranks, and
discuss when factorization is unique. In particular, we characterize when a
Boolean factorization $X = W \land H$ has a unique $W$, a unique $H$ (for a
fixed $W$), and when both $W$ and $H$ are unique, given a rank constraint. We
introduce a method for robust Boolean model selection, called BMF$k$, and show
on numerical examples that BMF$k$ not only accurately determines the correct
number of Boolean latent features but reconstruct the pre-determined factors
accurately.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+DeSantis_D/0/1/0/all/0/1&quot;&gt;Derek DeSantis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Skau_E/0/1/0/all/0/1&quot;&gt;Erik Skau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Truong_D/0/1/0/all/0/1&quot;&gt;Duc P. Truong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Alexandrov_B/0/1/0/all/0/1&quot;&gt;Boian Alexandrov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.01484">
<title>QoE-driven Secure Video Transmission in Cloud-edge Collaborative Networks. (arXiv:2101.01484v3 [cs.MM] UPDATED)</title>
<link>http://arxiv.org/abs/2101.01484</link>
<description rdf:parseType="Literal">&lt;p&gt;Video transmission over the backhaul link in cloud-edge collaborative
networks usually suffers security risks, which is ignored in most of the
existing studies. The characteristics that video service can flexibly adjust
the encoding rates and provide acceptable encoding qualities, make the security
requirements more possible to be satisfied but tightly coupled with video
encoding by introducing more restrictions on edge caching. In this paper, by
considering the interaction between video encoding and edge caching, we
investigate the quality of experience (QoE)-driven cross-layer optimization of
secure video transmission over the wireless backhaul link in cloud-edge
collaborative networks. First, we develop a secure transmission model based on
video encoding and edge caching. By employing this model as the security
constraint, then we formulate a QoE-driven joint optimization problem subject
to limited available caching capacity. To solve the optimization problem, we
propose two algorithms: a near-optimal iterative algorithm (EC-VE) and a greedy
algorithm with low computational complexity (Greedy EC-VE). Simulation results
show that our proposed EC-VE can greatly improve user QoE within security
constraints, and the proposed Greedy EC-VE can obtain the tradeoff between QoE
and computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tantan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lijun He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xinyu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.01768">
<title>Multi-Cell, Multi-Channel Scheduling with Probabilistic Per-Packet Real-Time Guarantee. (arXiv:2101.01768v4 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/2101.01768</link>
<description rdf:parseType="Literal">&lt;p&gt;For mission-critical sensing and control applications such as those to be
enabled by 5G Ultra-Reliable, Low-Latency Communications (URLLC), it is
critical to ensure the communication quality of individual packets.
&lt;/p&gt;
&lt;p&gt;Prior studies have considered Probabilistic Per-packet Real-time
Communications (PPRC) guarantees for single-cell, single-channel networks with
implicit deadline constraints, but they have not considered real-world
complexities such as inter-cell interference and multiple communication
channels.
&lt;/p&gt;
&lt;p&gt;Towards ensuring PPRC in multi-cell, multi-channel wireless networks, we
propose a real-time scheduling algorithm based on
\emph{local-deadline-partition (LDP)}. The LDP algorithm is suitable for
distributed implementation, and it ensures probabilistic per-packet real-time
guarantee for multi-cell, multi-channel networks with general deadline
constraints. We also address the associated challenge of the schedulability
test of PPRC traffic. In particular, we propose the concept of \emph{feasible
set} and identify a closed-form sufficient condition for the schedulability of
PPRC traffic.
&lt;/p&gt;
&lt;p&gt;We propose a distributed algorithm for the schedulability test, and the
algorithm includes a procedure for finding the minimum sum work density of
feasible sets which is of interest by itself. We also identify a necessary
condition for the schedulability of PPRC traffic, and use numerical studies to
understand a lower bound on the approximation ratio of the LDP algorithm.
&lt;/p&gt;
&lt;p&gt;We experimentally study the properties of the LDP algorithm and observe that
the PPRC traffic supportable by the LDP algorithm is significantly higher than
that of a state-of-the-art algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1&quot;&gt;Zhibo Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongwei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.06536">
<title>Deep Cox Mixtures for Survival Regression. (arXiv:2101.06536v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.06536</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis is a challenging variation of regression modeling because
of the presence of censoring, where the outcome measurement is only partially
known, due to, for example, loss to follow up. Such problems come up frequently
in medical applications, making survival analysis a key endeavor in
biostatistics and machine learning for healthcare, with Cox regression models
being amongst the most commonly employed models. We describe a new approach for
survival analysis regression models, based on learning mixtures of Cox
regressions to model individual survival distributions. We propose an
approximation to the Expectation Maximization algorithm for this model that
does hard assignments to mixture groups to make optimization efficient. In each
group assignment, we fit the hazard ratios within each group using deep neural
networks, and the baseline hazard for each mixture component
non-parametrically.
&lt;/p&gt;
&lt;p&gt;We perform experiments on multiple real world datasets, and look at the
mortality rates of patients across ethnicity and gender. We emphasize the
importance of calibration in healthcare settings and demonstrate that our
approach outperforms classical and modern survival analysis baselines, both in
terms of discriminative performance and calibration, with large gains in
performance on the minority demographics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1&quot;&gt;Chirag Nagpal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadlowsky_S/0/1/0/all/0/1&quot;&gt;Steve Yadlowsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostamzadeh_N/0/1/0/all/0/1&quot;&gt;Negar Rostamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1&quot;&gt;Katherine Heller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.08862">
<title>Breaking the Deadly Triad with a Target Network. (arXiv:2101.08862v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.08862</link>
<description rdf:parseType="Literal">&lt;p&gt;The deadly triad refers to the instability of a reinforcement learning
algorithm when it employs off-policy learning, function approximation, and
bootstrapping simultaneously. In this paper, we investigate the target network
as a tool for breaking the deadly triad, providing theoretical support for the
conventional wisdom that a target network stabilizes training. We first propose
and analyze a novel target network update rule which augments the commonly used
Polyak-averaging style update with two projections. We then apply the target
network and ridge regularization in several divergent algorithms and show their
convergence to regularized TD fixed points. Those algorithms are off-policy
with linear function approximation and bootstrapping, spanning both policy
evaluation and control, as well as both discounted and average-reward settings.
In particular, we provide the first convergent linear $Q$-learning algorithms
under nonrestrictive and changing behavior policies without bi-level
optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shangtong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Hengshuai Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.11427">
<title>One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction. (arXiv:2101.11427v5 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2101.11427</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional industrial recommenders are usually trained on a single business
domain and then serve for this domain. However, in large commercial platforms,
it is often the case that the recommenders need to make click-through rate
(CTR) predictions for multiple business domains. Different domains have
overlapping user groups and items. Thus, there exist commonalities. Since the
specific user groups have disparity and the user behaviors may change in
various business domains, there also have distinctions. The distinctions result
in domain-specific data distributions, making it hard for a single shared model
to work well on all domains. To learn an effective and efficient CTR model to
handle multiple domains simultaneously, we present Star Topology Adaptive
Recommender (STAR). Concretely, STAR has the star topology, which consists of
the shared centered parameters and domain-specific parameters. The shared
parameters are applied to learn commonalities of all domains, and the
domain-specific parameters capture domain distinction for more refined
prediction. Given requests from different business domains, STAR can adapt its
parameters conditioned on the domain characteristics. The experimental result
from production data validates the superiority of the proposed STAR model.
Since 2020, STAR has been deployed in the display advertising system of
Alibaba, obtaining averaging 8.0% improvement on CTR and 6.0% on RPM (Revenue
Per Mille).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1&quot;&gt;Xiang-Rong Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liqin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Guorui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1&quot;&gt;Xinyao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Binding Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1&quot;&gt;Qiang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Siran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1&quot;&gt;Jingshan Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1&quot;&gt;Hongbo Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoqiang Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.03336">
<title>Machine Learning Applications on Neuroimaging for Diagnosis and Prognosis of Epilepsy: A Review. (arXiv:2102.03336v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.03336</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning is playing an increasingly important role in medical image
analysis, spawning new advances in the clinical application of neuroimaging.
There have been some reviews on machine learning and epilepsy before, and they
mainly focused on electrophysiological signals such as electroencephalography
(EEG) and stereo electroencephalography (SEEG), while neglecting the potential
of neuroimaging in epilepsy research. Neuroimaging has its important advantages
in confirming the range of the epileptic region, which is essential in
presurgical evaluation and assessment after surgery. However, it is difficult
for EEG to locate the accurate epilepsy lesion region in the brain. In this
review, we emphasize the interaction between neuroimaging and machine learning
in the context of epilepsy diagnosis and prognosis. We start with an overview
of epilepsy and typical neuroimaging modalities used in epilepsy clinics, MRI,
DWI, fMRI, and PET. Then, we elaborate two approaches in applying machine
learning methods to neuroimaging data: i) the conventional machine learning
approach combining manual feature engineering and classifiers, ii) the deep
learning approach, such as the convolutional neural networks and autoencoders.
Subsequently, the application of machine learning on epilepsy neuroimaging,
such as segmentation, localization, and lateralization tasks, as well as tasks
directly related to diagnosis and prognosis are looked into in detail. Finally,
we discuss the current achievements, challenges, and potential future
directions in this field, hoping to pave the way for computer-aided diagnosis
and prognosis of epilepsy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jie Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ran_X/0/1/0/all/0/1&quot;&gt;Xuming Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Keyin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1&quot;&gt;Chen Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yi Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Haiyan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Quanying Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.03988">
<title>Ising Model Selection Using $\ell_{1}$-Regularized Linear Regression: A Statistical Mechanics Analysis. (arXiv:2102.03988v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.03988</link>
<description rdf:parseType="Literal">&lt;p&gt;We theoretically analyze the typical learning performance of
$\ell_{1}$-regularized linear regression ($\ell_1$-LinR) for Ising model
selection using the replica method from statistical mechanics. For typical
random regular graphs in the paramagnetic phase, an accurate estimate of the
typical sample complexity of $\ell_1$-LinR is obtained. Remarkably, despite the
model misspecification, $\ell_1$-LinR is model selection consistent with the
same order of sample complexity as $\ell_{1}$-regularized logistic regression
($\ell_1$-LogR), i.e., $M=\mathcal{O}\left(\log N\right)$, where $N$ is the
number of variables of the Ising model. Moreover, we provide an efficient
method to accurately predict the non-asymptotic behavior of $\ell_1$-LinR for
moderate $M, N$, such as precision and recall. Simulations show a fairly good
agreement between theoretical predictions and experimental results, even for
graphs with many loops, which supports our findings. Although this paper mainly
focuses on $\ell_1$-LinR, our method is readily applicable for precisely
characterizing the typical learning performances of a wide class of
$\ell_{1}$-regularized $M$-estimators including $\ell_1$-LogR and interaction
screening.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1&quot;&gt;Xiangming Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obuchi_T/0/1/0/all/0/1&quot;&gt;Tomoyuki Obuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabashima_Y/0/1/0/all/0/1&quot;&gt;Yoshiyuki Kabashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.07092">
<title>Learning Self-Similarity in Space and Time as Generalized Motion for Video Action Recognition. (arXiv:2102.07092v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2102.07092</link>
<description rdf:parseType="Literal">&lt;p&gt;Spatio-temporal convolution often fails to learn motion dynamics in videos
and thus an effective motion representation is required for video understanding
in the wild. In this paper, we propose a rich and robust motion representation
based on spatio-temporal self-similarity (STSS). Given a sequence of frames,
STSS represents each local region as similarities to its neighbors in space and
time. By converting appearance features into relational values, it enables the
learner to better recognize structural patterns in space and time. We leverage
the whole volume of STSS and let our model learn to extract an effective motion
representation from it. The proposed neural block, dubbed SELFY, can be easily
inserted into neural architectures and trained end-to-end without additional
supervision. With a sufficient volume of the neighborhood in space and time, it
effectively captures long-term interaction and fast motion in the video,
leading to robust action recognition. Our experimental analysis demonstrates
its superiority over previous methods for motion modeling as well as its
complementarity to spatio-temporal features from direct convolution. On the
standard action recognition benchmarks, Something-Something-V1 &amp;amp; V2, Diving-48,
and FineGym, the proposed method achieves the state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1&quot;&gt;Heeseung Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Manjin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1&quot;&gt;Suha Kwak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1&quot;&gt;Minsu Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.09759">
<title>Applications of deep learning in traffic congestion detection, prediction and alleviation: A survey. (arXiv:2102.09759v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.09759</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting, predicting, and alleviating traffic congestion are targeted at
improving the level of service of the transportation network. With increasing
access to larger datasets of higher resolution, the relevance of deep learning
for such tasks is increasing. Several comprehensive survey papers in recent
years have summarised the deep learning applications in the transportation
domain. However, the system dynamics of the transportation network vary greatly
between the non-congested state and the congested state -- thereby
necessitating the need for a clear understanding of the challenges specific to
congestion prediction. In this survey, we present the current state of deep
learning applications in the tasks related to detection, prediction, and
alleviation of congestion. Recurring and non-recurring congestion are discussed
separately. Our survey leads us to uncover inherent challenges and gaps in the
current state of research. Finally, we present some suggestions for future
research directions as answers to the identified challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Nishant Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raubal_M/0/1/0/all/0/1&quot;&gt;Martin Raubal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.09775">
<title>Characterizing and Mitigating Self-Admitted Technical Debt in Build Systems. (arXiv:2102.09775v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2102.09775</link>
<description rdf:parseType="Literal">&lt;p&gt;Technical Debt is a metaphor used to describe the situation in which
long-term software artifact quality is traded for short-term goals in software
projects. In recent years, the concept of self-admitted technical debt (SATD)
was proposed, which focuses on debt that is intentionally introduced and
described by developers. Although prior work has made important observations
about admitted technical debt in source code, little is known about SATD in
build systems. In this paper, we set out to better understand the
characteristics of SATD in build systems. To do so, through a qualitative
analysis of 500 SATD comments in the Maven build system of 291 projects, we
characterize SATD by location and rationale (reason and purpose). Our results
show that limitations in tools and libraries, and complexities of dependency
management are the most frequent causes, accounting for 50% and 24% of the
comments. We also find that developers often document SATD as issues to be
fixed later. As a first step towards the automatic detection of SATD rationale,
we train classifiers to detect the two most frequently occurring reasons and
the four most frequently occurring purposes of SATD in the content of comments
in Maven build systems. The classifier performance is promising, achieving an
F1-score of 0.71-0.79. Finally, within 16 identified &apos;ready-to-be-addressed&apos;
SATD instances, the three SATD submitted by pull requests and the five SATD
submitted by issue reports were resolved after developers were made aware. Our
work presents the first step towards understanding technical debt in build
systems and opens up avenues for future work, such as tool support to track and
manage SATD backlogs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1&quot;&gt;Tao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McIntosh_S/0/1/0/all/0/1&quot;&gt;Shane McIntosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hata_H/0/1/0/all/0/1&quot;&gt;Hideaki Hata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kula_R/0/1/0/all/0/1&quot;&gt;Raula Gaikovina Kula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishio_T/0/1/0/all/0/1&quot;&gt;Takashi Ishio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsumoto_K/0/1/0/all/0/1&quot;&gt;Kenichi Matsumoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.09808">
<title>Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.09808</link>
<description rdf:parseType="Literal">&lt;p&gt;Although deep feedforward neural networks share some characteristics with the
primate visual system, a key distinction is their dynamics. Deep nets typically
operate in serial stages wherein each layer completes its computation before
processing begins in subsequent layers. In contrast, biological systems have
cascaded dynamics: information propagates from neurons at all layers in
parallel but transmission occurs gradually over time, leading to speed-accuracy
trade offs even in feedforward architectures. We explore the consequences of
biologically inspired parallel hardware by constructing cascaded ResNets in
which each residual block has propagation delays but all blocks update in
parallel in a stateful manner. Because information transmitted through skip
connections avoids delays, the functional depth of the architecture increases
over time, yielding anytime predictions that improve with internal-processing
time. We introduce a temporal-difference training loss that achieves a strictly
superior speed-accuracy profile over standard losses and enables the cascaded
architecture to outperform state-of-the-art anytime-prediction methods. The
cascaded architecture has intriguing properties, including: it classifies
typical instances more rapidly than atypical instances; it is more robust to
both persistent and transient noise than is a conventional ResNet; and its
time-varying output trace provides a signal that can be exploited to improve
information processing and inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1&quot;&gt;Michael L. Iuzzolino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.10090">
<title>Volunteer contributions to Wikipedia increased during COVID-19 mobility restrictions. (arXiv:2102.10090v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2102.10090</link>
<description rdf:parseType="Literal">&lt;p&gt;Wikipedia, the largest encyclopedia ever created, is a global initiative
driven by volunteer contributions. When the COVID-19 pandemic broke out and
mobility restrictions ensued across the globe, it was unclear whether Wikipedia
volunteers would become less active in the face of the pandemic, or whether
they would rise to meet the increased demand for high-quality information
despite the added stress inflicted by this crisis. Analyzing 223 million edits
contributed from 2018 to 2020 across twelve Wikipedia language editions, we
find that Wikipedia&apos;s global volunteer community responded remarkably to the
pandemic, substantially increasing both productivity and the number of
newcomers who joined the community. For example, contributions to the English
Wikipedia increased by over 20% compared to the expectation derived from
pre-pandemic data. Our work sheds light on the response of a global volunteer
population to the COVID-19 crisis, providing valuable insights into the
behavior of critical online communities under stress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruprechter_T/0/1/0/all/0/1&quot;&gt;Thorsten Ruprechter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1&quot;&gt;Manoel Horta Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_T/0/1/0/all/0/1&quot;&gt;Tiago Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemmerich_F/0/1/0/all/0/1&quot;&gt;Florian Lemmerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strohmaier_M/0/1/0/all/0/1&quot;&gt;Markus Strohmaier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1&quot;&gt;Robert West&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helic_D/0/1/0/all/0/1&quot;&gt;Denis Helic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.11137">
<title>Program Synthesis Guided Reinforcement Learning for Partially Observed Environments. (arXiv:2102.11137v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2102.11137</link>
<description rdf:parseType="Literal">&lt;p&gt;A key challenge for reinforcement learning is solving long-horizon planning
problems. Recent work has leveraged programs to guide reinforcement learning in
these settings. However, these approaches impose a high manual burden on the
user since they must provide a guiding program for every new task. Partially
observed environments further complicate the programming task because the
program must implement a strategy that correctly, and ideally optimally,
handles every possible configuration of the hidden regions of the environment.
We propose a new approach, model predictive program synthesis (MPPS), that uses
program synthesis to automatically generate the guiding programs. It trains a
generative model to predict the unobserved portions of the world, and then
synthesizes a program based on samples from this model in a way that is robust
to its uncertainty. In our experiments, we show that our approach significantly
outperforms non-program-guided approaches on a set of challenging benchmarks,
including a 2D Minecraft-inspired environment where the agent must complete a
complex sequence of subtasks to achieve its goal, and achieves a similar
performance as using handcrafted programs to guide the agent. Our results
demonstrate that our approach can obtain the benefits of program-guided
reinforcement learning without requiring the user to provide a new guiding
program for every new task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yichen David Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inala_J/0/1/0/all/0/1&quot;&gt;Jeevana Priya Inala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1&quot;&gt;Osbert Bastani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yewen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1&quot;&gt;Martin Rinard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.11903">
<title>Neural ranking models for document retrieval. (arXiv:2102.11903v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2102.11903</link>
<description rdf:parseType="Literal">&lt;p&gt;Ranking models are the main components of information retrieval systems.
Several approaches to ranking are based on traditional machine learning
algorithms using a set of hand-crafted features. Recently, researchers have
leveraged deep learning models in information retrieval. These models are
trained end-to-end to extract features from the raw data for ranking tasks, so
that they overcome the limitations of hand-crafted features. A variety of deep
learning models have been proposed, and each model presents a set of neural
network components to extract features that are used for ranking. In this
paper, we compare the proposed models in the literature along different
dimensions in order to understand the major contributions and limitations of
each model. In our discussion of the literature, we analyze the promising
neural components, and propose future research directions. We also show the
analogy between document retrieval and other retrieval tasks where the items to
be ranked are structured documents, answers, images and videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trabelsi_M/0/1/0/all/0/1&quot;&gt;Mohamed Trabelsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhiyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davison_B/0/1/0/all/0/1&quot;&gt;Brian D. Davison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heflin_J/0/1/0/all/0/1&quot;&gt;Jeff Heflin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.00091">
<title>Design and Performance Characterization of RADICAL-Pilot on Leadership-class Platforms. (arXiv:2103.00091v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2103.00091</link>
<description rdf:parseType="Literal">&lt;p&gt;Many extreme scale scientific applications have workloads comprised of a
large number of individual high-performance tasks. The Pilot abstraction
decouples workload specification, resource management, and task execution via
job placeholders and late-binding. As such, suitable implementations of the
Pilot abstraction can support the collective execution of large number of tasks
on supercomputers. We introduce RADICAL-Pilot (RP) as a portable, modular and
extensible pilot-enabled runtime system. We describe RP&apos;s design, architecture
and implementation. We characterize its performance and show its ability to
scalably execute workloads comprised of tens of thousands heterogeneous tasks
on DOE and NSF leadership-class HPC platforms. Specifically, we investigate
RP&apos;s weak/strong scaling with CPU/GPU, single/multi core, (non)MPI tasks and
Python functions when using most of ORNL Summit and TACC Frontera.
RADICAL-Pilot can be used stand-alone, as well as the runtime for third-party
workflow systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merzky_A/0/1/0/all/0/1&quot;&gt;Andre Merzky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turilli_M/0/1/0/all/0/1&quot;&gt;Matteo Turilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Titov_M/0/1/0/all/0/1&quot;&gt;Mikhail Titov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Saadi_A/0/1/0/all/0/1&quot;&gt;Aymen Al-Saadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Shantenu Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.01242">
<title>Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language. (arXiv:2103.01242v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2103.01242</link>
<description rdf:parseType="Literal">&lt;p&gt;Current NLP datasets targeting ambiguity can be solved by a native speaker
with relative ease. We present Cryptonite, a large-scale dataset based on
cryptic crosswords, which is both linguistically complex and naturally sourced.
Each example in Cryptonite is a cryptic clue, a short phrase or sentence with a
misleading surface reading, whose solving requires disambiguating semantic,
syntactic, and phonetic wordplays, as well as world knowledge. Cryptic clues
pose a challenge even for experienced solvers, though top-tier experts can
solve them with almost 100% accuracy. Cryptonite is a challenging task for
current models; fine-tuning T5-Large on 470k cryptic clues achieves only 7.6%
accuracy, on par with the accuracy of a rule-based clue solver (8.6%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efrat_A/0/1/0/all/0/1&quot;&gt;Avia Efrat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1&quot;&gt;Uri Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilman_D/0/1/0/all/0/1&quot;&gt;Dan Kilman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1&quot;&gt;Omer Levy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.03991">
<title>Passing Through Narrow Gaps with Deep Reinforcement Learning. (arXiv:2103.03991v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2103.03991</link>
<description rdf:parseType="Literal">&lt;p&gt;The U.S. Defense Advanced Research Projects Agency (DARPA) Subterranean
Challenge requires teams of robots to traverse difficult and diverse
underground environments. Traversing small gaps is one of the challenging
scenarios that robots encounter. Imperfect sensor information makes it
difficult for classical navigation methods, where behaviours require
significant manual fine tuning. In this paper we present a deep reinforcement
learning method for autonomously navigating through small gaps, where contact
between the robot and the gap may be required. We first learn a gap behaviour
policy to get through small gaps (only centimeters wider than the robot). We
then learn a goal-conditioned behaviour selection policy that determines when
to activate the gap behaviour policy. We train our policies in simulation and
demonstrate their effectiveness with a large tracked robot in simulation and on
the real platform. In simulation experiments, our approach achieves 93\%
success rate when the gap behaviour is activated manually by an operator, and
63\% with autonomous activation using the behaviour selection policy. In real
robot experiments, our approach achieves a success rate of 73\% with manual
activation, and 40\% with autonomous behaviour selection. While we show the
feasibility of our approach in simulation, the difference in performance
between simulated and real world scenarios highlight the difficulty of direct
sim-to-real transfer for deep reinforcement learning policies. In both the
simulated and real world environments alternative methods were unable to
traverse the gap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tidd_B/0/1/0/all/0/1&quot;&gt;Brendan Tidd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosgun_A/0/1/0/all/0/1&quot;&gt;Akansel Cosgun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leitner_J/0/1/0/all/0/1&quot;&gt;Jurgen Leitner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hudson_N/0/1/0/all/0/1&quot;&gt;Nicolas Hudson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.04804">
<title>Detecting quantum entanglement with unsupervised learning. (arXiv:2103.04804v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2103.04804</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum properties, such as entanglement and coherence, are indispensable
resources in various quantum information processing tasks. However, there still
lacks an efficient and scalable way to detecting these useful features,
especially for high-dimensional and multipartite quantum systems. In this work,
we exploit the convexity of samples without the desired quantum features and
design an unsupervised machine learning method to detect the presence of such
features as anomalies. Particularly, in the context of entanglement detection,
we propose a complex-valued neural network composed of pseudo-siamese network
and generative adversarial net, and then train it with only separable states to
construct non-linear witnesses for entanglement. It is shown via numerical
examples, ranging from two-qubit to ten-qubit systems, that our network is able
to achieve high detection accuracy which is above 97.5% on average.Moreover, it
is capable of revealing rich structures of entanglement, such as partial
entanglement among subsystems. Our results are readily applicable to the
detection of other quantum resources such as Bell nonlocality and steerability,
and thus our work could provide a powerful tool to extract quantum features
hidden in multipartite quantum data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiwei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yu Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guofeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Shuming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.11351">
<title>Cross-Dataset Collaborative Learning for Semantic Segmentation in Autonomous Driving. (arXiv:2103.11351v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2103.11351</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic segmentation is an important task for scene understanding in
self-driving cars and robotics, which aims to assign dense labels for all
pixels in the image. Existing work typically improves semantic segmentation
performance by exploring different network architectures on a target dataset.
Little attention has been paid to build a unified system by simultaneously
learning from multiple datasets due to the inherent distribution shift across
different datasets. In this paper, we propose a simple, flexible, and general
method for semantic segmentation, termed Cross-Dataset Collaborative Learning
(CDCL). Our goal is to train a unified model for improving the performance in
each dataset by leveraging information from all the datasets. Specifically, we
first introduce a family of Dataset-Aware Blocks (DAB) as the fundamental
computing units of the network, which help capture homogeneous convolutional
representations and heterogeneous statistics across different datasets. Second,
we present a Dataset Alternation Training (DAT) mechanism to facilitate the
collaborative optimization procedure. We conduct extensive evaluations on
diverse semantic segmentation datasets for autonomous driving. Experiments
demonstrate that our method consistently achieves notable improvements over
prior single-dataset and cross-dataset training methods without introducing
extra FLOPs. Particularly, with the same architecture of PSPNet (ResNet-18),
our method outperforms the single-dataset baseline by 5.65\%, 6.57\%, and
5.79\% mIoU on the validation sets of Cityscapes, BDD100K, CamVid,
respectively. We also apply CDCL for point cloud 3D semantic segmentation and
achieve improved performance, which further validates the superiority and
generality of our method. Code and models will be released.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jinzhang Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1&quot;&gt;Lu Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1&quot;&gt;Yi Shan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.12347">
<title>Shared Latent Space of Font Shapes and Their Noisy Impressions. (arXiv:2103.12347v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2103.12347</link>
<description rdf:parseType="Literal">&lt;p&gt;Styles of typefaces or fonts are often associated with specific impressions,
such as heavy, contemporary, or elegant. This indicates that there are certain
correlations between font shapes and their impressions. To understand the
correlations, this paper realizes a shared latent space where a font and its
impressions are embedded nearby. The difficulty is that the impression words
attached to a font are often very noisy. This is because impression words are
very subjective and diverse. More importantly, some impression words have no
direct relevance to the font shapes and will disturb the realization of the
shared latent space. We, therefore, use DeepSets for enhancing shape-relevant
words and suppressing shape irrelevant words automatically while training the
shared latent space. Quantitative and qualitative experimental results with a
large-scale font-impression dataset demonstrate that the shared latent space by
the proposed method describes the correlation appropriately, especially for the
shape-relevant impression words.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Jihun Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haraguchi_D/0/1/0/all/0/1&quot;&gt;Daichi Haraguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsuda_S/0/1/0/all/0/1&quot;&gt;Seiya Matsuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1&quot;&gt;Akisato Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1&quot;&gt;Seiichi Uchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.13530">
<title>Pricing and Energy Trading in Peer-to-peer Zero Marginal-cost Microgrids. (arXiv:2103.13530v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2103.13530</link>
<description rdf:parseType="Literal">&lt;p&gt;Efforts to utilize 100% renewable energy in community microgrids require new
approaches to energy markets and transactions to efficiently address periods of
scarce energy supply. In this paper we contribute to the promising approach of
peer-to-peer (P2P) energy trading in two main ways: analysis of a centralized,
welfare-maximizing economic dispatch that characterizes optimal price and
allocations, and a novel P2P system for negotiating energy trades that yields
physically feasible and at least weakly Pareto-optimal outcomes. Our main
results are 1) that optimal pricing is insufficient to induce agents with
batteries to take optimal actions, 2) a novel P2P algorithm to addresses this
while keeping private information, 3) a formal proof that this algorithm
converges to the centralized solution in the case of two agents negotiating for
a single period, and 4)numerical simulations of the P2P algorithm performance
with up to 10 agents and 24 periods that show it converges on average to total
welfare within 0.1% of the social optimum in on the order of 10s to 100s of
iterations, increasing with the number of agents, time periods, and total
storage capacity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jonathan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Henriquez_Auba_R/0/1/0/all/0/1&quot;&gt;Rodrigo Henriquez-Auba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poolla_B/0/1/0/all/0/1&quot;&gt;Bala Kameshwar Poolla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Callaway_D/0/1/0/all/0/1&quot;&gt;Duncan S. Callaway&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.01065">
<title>Fairness and Communication-Based Semantics for Session-Typed Languages. (arXiv:2104.01065v2 [cs.PL] UPDATED)</title>
<link>http://arxiv.org/abs/2104.01065</link>
<description rdf:parseType="Literal">&lt;p&gt;We give communication-based semantics and reasoning techniques for Polarized
SILL, a rich session-typed programming language with general recursion. Its
features include channel and code transmission, synchronous and asynchronous
communication, and functional programming. Our contributions are distinguished
by their faithfulness to the process abstraction, i.e., to the premise that
communication is the only observable phenomenon of processes. We give the first
observed communication semantics that supports general recursion and code
transmission. Observed communication semantics define the meaning of processes
in terms of their observed communications. We use this observational semantics
to define experiments on processes, and we give a communication-based testing
equivalences framework for defining observational simulations and equivalences
on processes. This framework captures several natural equivalences, and we show
that one of these coincides with barbed congruence, the canonical notion of
process equivalence.
&lt;/p&gt;
&lt;p&gt;Polarized SILL is defined using a substructural operational semantics based
on multiset rewriting. To ensure that our contributions are well-defined in the
presence of non-termination, we introduce fairness for multiset rewriting
systems. We construct a fair scheduler, we give sufficient conditions for
traces to be fair, and we study the effects of permutation on fair traces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kavanagh_R/0/1/0/all/0/1&quot;&gt;Ryan Kavanagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.02040">
<title>Segmentation of EM showers for neutrino experiments with deep graph neural networks. (arXiv:2104.02040v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2104.02040</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a first-ever algorithm for the reconstruction of multiple
showers from the data collected with electromagnetic (EM) sampling
calorimeters. Such detectors are widely used in High Energy Physics to measure
the energy and kinematics of in-going particles. In this work, we consider the
case when many electrons pass through an Emulsion Cloud Chamber (ECC) brick,
initiating electron-induced electromagnetic showers, which can be the case with
long exposure times or large input particle flux. For example, SHiP experiment
is planning to use emulsion detectors for dark matter search and neutrino
physics investigation. The expected full flux of SHiP experiment is about 10^20
particles over five years. To reduce the cost of the experiment associated with
the replacement of the ECC brick and off-line data taking (emulsion scanning),
it is decided to increase exposure time. Thus, we expect to observe a lot of
overlapping showers, which turn EM showers reconstruction into a challenging
point cloud segmentation problem. Our reconstruction pipeline consists of a
Graph Neural Network that predicts an adjacency matrix and a clustering
algorithm. We propose a new layer type (EmulsionConv) that takes into account
geometrical properties of shower development in ECC brick. For the clustering
of overlapping showers, we use a modified hierarchical density-based clustering
algorithm. Our method does not use any prior information about the incoming
particles and identifies up to 87% of electromagnetic showers in emulsion
detectors. The main test bench for the algorithm for reconstructing
electromagnetic showers is going to be SND@LHC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belavin_V/0/1/0/all/0/1&quot;&gt;Vladislav Belavin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trofimova_E/0/1/0/all/0/1&quot;&gt;Ekaterina Trofimova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ustyuzhanin_A/0/1/0/all/0/1&quot;&gt;Andrey Ustyuzhanin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.05119">
<title>BurstLink: Techniques for Energy-Efficient Conventional and Virtual Reality Video Display. (arXiv:2104.05119v4 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2104.05119</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional planar video streaming is the most popular application in mobile
systems and the rapid growth of 360 video content and virtual reality (VR)
devices are accelerating the adoption of VR video streaming. Unfortunately,
video streaming consumes significant system energy due to the high power
consumption of the system components (e.g., DRAM, display interfaces, and
display panel) involved in this process.
&lt;/p&gt;
&lt;p&gt;We propose BurstLink, a novel system-level technique that improves the energy
efficiency of planar and VR video streaming. BurstLink is based on two key
ideas. First, BurstLink directly transfers a decoded video frame from the host
system to the display panel, bypassing the host DRAM. To this end, we extend
the display panel with a double remote frame buffer (DRFB), instead of the
DRAM&apos;s double frame buffer, so that the system can directly update the DRFB
with a new frame while updating the panel&apos;s pixels with the current frame
stored in the DRFB. Second, BurstLink transfers a complete decoded frame to the
display panel in a single burst, using the maximum bandwidth of modern display
interfaces. Unlike conventional systems where the frame transfer rate is
limited by the pixel-update throughput of the display panel, BurstLink can
always take full advantage of the high bandwidth of modern display interfaces
by decoupling the frame transfer from the pixel update as enabled by the DRFB.
This direct and burst frame transfer of BurstLink significantly reduces energy
consumption in video display by reducing access to the host DRAM and increasing
the system&apos;s residency at idle power states.
&lt;/p&gt;
&lt;p&gt;We evaluate BurstLink using an analytical power model that we rigorously
validate on a real modern mobile system. Our evaluation shows that BurstLink
reduces system energy consumption for 4K planar and VR video streaming by 41%
and 33%, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haj_Yahya_J/0/1/0/all/0/1&quot;&gt;Jawad Haj-Yahya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jisung Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bera_R/0/1/0/all/0/1&quot;&gt;Rahul Bera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luna_J/0/1/0/all/0/1&quot;&gt;Juan G&amp;#xf3;mez Luna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotem_E/0/1/0/all/0/1&quot;&gt;Efraim Rotem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahroodi_T/0/1/0/all/0/1&quot;&gt;Taha Shahroodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeremie Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1&quot;&gt;Onur Mutlu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.07149">
<title>On the Robustness of Intent Classification and Slot Labeling in Goal-oriented Dialog Systems to Real-world Noise. (arXiv:2104.07149v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2104.07149</link>
<description rdf:parseType="Literal">&lt;p&gt;Intent Classification (IC) and Slot Labeling (SL) models, which form the
basis of dialogue systems, often encounter noisy data in real-word
environments. In this work, we investigate how robust IC/SL models are to noisy
data. We collect and publicly release a test-suite for seven common noise types
found in production human-to-bot conversations (abbreviations, casing,
misspellings, morphological variants, paraphrases, punctuation and synonyms).
On this test-suite, we show that common noise types substantially degrade the
IC accuracy and SL F1 performance of state-of-the-art BERT-based IC/SL models.
By leveraging cross-noise robustness transfer -- training on one noise type to
improve robustness on another noise type -- we design aggregate
data-augmentation approaches that increase the model performance across all
seven noise types by +10.8% for IC accuracy and +15 points for SL F1 on
average. To the best of our knowledge, this is the first work to present a
single IC/SL model that is robust to a wide range of noise phenomena.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1&quot;&gt;Sailik Sengupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krone_J/0/1/0/all/0/1&quot;&gt;Jason Krone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1&quot;&gt;Saab Mansour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.09330">
<title>Beyond tight deadlines: what are the business causes for technical debt?. (arXiv:2104.09330v4 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2104.09330</link>
<description rdf:parseType="Literal">&lt;p&gt;What are the business causes behind tight deadlines? What drives the
prioritization of features that pushes quality matters to the back burner? We
conducted a survey with 71 experienced practitioners and did a thematic
analysis of the open-ended answers to the question: &quot;Could you give examples of
how business may contribute to technical debt?&quot; Business-related causes were
organized into two categories: pure-business and business/IT gap, and they were
related to &apos;tight deadlines&apos; and &apos;features over quality&apos;, the most frequently
cited management reasons for technical debt. We contribute a cause-effect model
which relates the various business causes of technical debt to each other and
explains their impact on technical debt.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeida_R/0/1/0/all/0/1&quot;&gt;Rodrigo Rebou&amp;#xe7;as de Almeida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Treude_C/0/1/0/all/0/1&quot;&gt;Christoph Treude&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulesza_U/0/1/0/all/0/1&quot;&gt;Uir&amp;#xe1; Kulesza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.12820">
<title>Universal Off-Policy Evaluation. (arXiv:2104.12820v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2104.12820</link>
<description rdf:parseType="Literal">&lt;p&gt;When faced with sequential decision-making problems, it is often useful to be
able to predict what would happen if decisions were made using a new policy.
Those predictions must often be based on data collected under some previously
used decision-making rule. Many previous methods enable such off-policy (or
counterfactual) estimation of the expected value of a performance measure
called the return. In this paper, we take the first steps towards a universal
off-policy estimator (UnO) -- one that provides off-policy estimates and
high-confidence bounds for any parameter of the return distribution. We use UnO
for estimating and simultaneously bounding the mean, variance,
quantiles/median, inter-quantile range, CVaR, and the entire cumulative
distribution of returns. Finally, we also discuss Uno&apos;s applicability in
various settings, including fully observable, partially observable (i.e., with
unobserved confounders), Markovian, non-Markovian, stationary, smoothly
non-stationary, and discrete distribution shifts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandak_Y/0/1/0/all/0/1&quot;&gt;Yash Chandak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1&quot;&gt;Scott Niekum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1&quot;&gt;Bruno Castro da Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Learned_Miller_E/0/1/0/all/0/1&quot;&gt;Erik Learned-Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_P/0/1/0/all/0/1&quot;&gt;Philip S. Thomas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.01924">
<title>Novelty Detection and Analysis of Traffic Scenario Infrastructures in the Latent Space of a Vision Transformer-Based Triplet Autoencoder. (arXiv:2105.01924v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2105.01924</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting unknown and untested scenarios is crucial for scenario-based
testing. Scenario-based testing is considered to be a possible approach to
validate autonomous vehicles. A traffic scenario consists of multiple
components, with infrastructure being one of it. In this work, a method to
detect novel traffic scenarios based on their infrastructure images is
presented. An autoencoder triplet network provides latent representations for
infrastructure images which are used for outlier detection. The triplet
training of the network is based on the connectivity graphs of the
infrastructure. By using the proposed architecture, expert-knowledge is used to
shape the latent space such that it incorporates a pre-defined similarity in
the neighborhood relationships of an autoencoder. An ablation study on the
architecture is highlighting the importance of the triplet autoencoder
combination. The best performing architecture is based on vision transformers,
a convolution-free attention-based network. The presented method outperforms
other state-of-the-art outlier detection approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wurst_J/0/1/0/all/0/1&quot;&gt;Jonas Wurst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramanian_L/0/1/0/all/0/1&quot;&gt;Lakshman Balasubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botsch_M/0/1/0/all/0/1&quot;&gt;Michael Botsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Utschick_W/0/1/0/all/0/1&quot;&gt;Wolfgang Utschick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.02716">
<title>Noether&apos;s Learning Dynamics: Role of Symmetry Breaking in Neural Networks. (arXiv:2105.02716v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2105.02716</link>
<description rdf:parseType="Literal">&lt;p&gt;In nature, symmetry governs regularities, while symmetry breaking brings
texture. In artificial neural networks, symmetry has been a central design
principle to efficiently capture regularities in the world, but the role of
symmetry breaking is not well understood. Here, we develop a theoretical
framework to study the &quot;geometry of learning dynamics&quot; in neural networks, and
reveal a key mechanism of explicit symmetry breaking behind the efficiency and
stability of modern neural networks. To build this understanding, we model the
discrete learning dynamics of gradient descent using a continuous-time
Lagrangian formulation, in which the learning rule corresponds to the kinetic
energy and the loss function corresponds to the potential energy. Then, we
identify &quot;kinetic symmetry breaking&quot; (KSB), the condition when the kinetic
energy explicitly breaks the symmetry of the potential function. We generalize
Noether&apos;s theorem known in physics to take into account KSB and derive the
resulting motion of the Noether charge: &quot;Noether&apos;s Learning Dynamics&quot; (NLD).
Finally, we apply NLD to neural networks with normalization layers and reveal
how KSB introduces a mechanism of &quot;implicit adaptive optimization&quot;,
establishing an analogy between learning dynamics induced by normalization
layers and RMSProp. Overall, through the lens of Lagrangian mechanics, we have
established a theoretical foundation to discover geometric design principles
for the learning dynamics of neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1&quot;&gt;Hidenori Tanaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kunin_D/0/1/0/all/0/1&quot;&gt;Daniel Kunin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.06742">
<title>Cybersecurity Anomaly Detection in Adversarial Environments. (arXiv:2105.06742v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2105.06742</link>
<description rdf:parseType="Literal">&lt;p&gt;The proliferation of interconnected battlefield information-sharing devices,
known as the Internet of Battlefield Things (IoBT), introduced several security
challenges. Inherent to the IoBT operating environment is the practice of
adversarial machine learning, which attempts to circumvent machine learning
models. This work examines the feasibility of cost-effective unsupervised
learning and graph-based methods for anomaly detection in the network intrusion
detection system setting, and also leverages an ensemble approach to supervised
learning of the anomaly detection problem. We incorporate a realistic
adversarial training mechanism when training supervised models to enable strong
classification performance in adversarial environments. The results indicate
that the unsupervised and graph-based methods were outperformed in detecting
anomalies (malicious activity) by the supervised stacking ensemble method with
two levels. This model consists of three different classifiers in the first
level, followed by either a Naive Bayes or Decision Tree classifier for the
second level. The model maintains an F1-score above 0.97 for malicious samples
across all tested level two classifiers. Notably, Naive Bayes is the fastest
level two classifier averaging 1.12 seconds while Decision Tree maintains the
highest AUC score of 0.98.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bierbrauer_D/0/1/0/all/0/1&quot;&gt;David A. Bierbrauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1&quot;&gt;Alexander Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kritzer_W/0/1/0/all/0/1&quot;&gt;Will Kritzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastian_N/0/1/0/all/0/1&quot;&gt;Nathaniel D. Bastian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.07608">
<title>Hamiltonian Cycle Problem is in P. (arXiv:2105.07608v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2105.07608</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we present the first deterministic polynomial time algorithm
for determining the existence of a Hamiltonian cycle and finding a Hamiltonian
cycle in general graphs. Our algorithm can also resolve the Hamiltonian path
problem in the traceable graphs. The space complexity of our algorithm is
O(n^4). The time complexity are theoretically O(n^5*d^2) on average and
O(n^6*d^2) in the worst case respectively, where d is the maximum degree of
vertex. With parallel computing, the space complexity can be improved to O(n^3)
and the time complexity to O(n^3*d^2) on average and O(n^4*d^2) in the worst
case. We construct the corresponding path hologram transformed from the
original graph and compute the path set, which is a collection of segment sets
consisting of all the vertices located on the same segment layer among all the
longest basic paths, of every vertex with dynamic programming. The path
hologram is a multi-segment graph with the vertex &amp;lt;u, k&amp;gt; where u is a vertex
and k is the segment layer of u in the path hologram. To ensure each path
stored in the path set is legal and each segment set of the path set contains
only valid vertices, the key strategy of our method is the &quot;consecutive&quot;
deleting-replenishing operations recursively on the left/right action field of
a vertex, respectively. The greatest contribution of our method is the path set
in which all the legal paths can be stored in O(n^2) space for a complete graph
of order n. In fact, our algorithm can be directly applied to the original
graph. Besides, our algorithm can deal with the finite general graphs including
undirected, directed, and mixed. As a result, the well-known problem HCP in NPC
can be now resolved practically in deterministic polynomial time for general
graphs in the worst case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_A/0/1/0/all/0/1&quot;&gt;Aimin Hou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.09680">
<title>KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2105.09680</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE
is a collection of 8 Korean natural language understanding (NLU) tasks,
including Topic Classification, SemanticTextual Similarity, Natural Language
Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing,
Machine Reading Comprehension, and Dialogue State Tracking. We build all of the
tasks from scratch from diverse source corpora while respecting copyrights, to
ensure accessibility for anyone without any restrictions. With ethical
considerations in mind, we carefully design annotation protocols. Along with
the benchmark tasks and data, we provide suitable evaluation metrics and
fine-tuning recipes for pretrained language models for each task. We
furthermore release the pretrained language models (PLM), KLUE-BERT and
KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby
facilitate future research. We make a few interesting observations from the
preliminary experiments using the proposed KLUE benchmark suite, already
demonstrating the usefulness of this new benchmark suite. First, we find
KLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and
existing open-source Korean PLMs. Second, we see minimal degradation in
performance even when we replace personally identifiable information from the
pretraining corpus, suggesting that privacy and NLU capability are not at odds
with each other. Lastly, we find that using BPE tokenization in combination
with morpheme-level pre-tokenization is effective in tasks involving
morpheme-level tagging, detection and generation. In addition to accelerating
Korean NLP research, our comprehensive documentation on creating KLUE will
facilitate creating similar resources for other languages in the future. KLUE
is available at https://klue-benchmark.com.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sungjoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1&quot;&gt;Jihyung Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sungdong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1&quot;&gt;Won Ik Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jiyoon Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jangwon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Chisung Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junseong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yongsook Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1&quot;&gt;Taehwan Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Juhyun Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Sungwon Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1&quot;&gt;Younghoon Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1&quot;&gt;Inkwon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1&quot;&gt;Sangwoo Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dongjun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyunwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Myeonghwa Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1&quot;&gt;Seongbo Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1&quot;&gt;Seungwon Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sunkyoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1&quot;&gt;Kyungtae Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jongwon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1&quot;&gt;Kyumin Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jamin Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seonghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1&quot;&gt;Lucy Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1&quot;&gt;Alice Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1&quot;&gt;Jung-Woo Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.11066">
<title>Policy Mirror Descent for Regularized Reinforcement Learning: A Generalized Framework with Linear Convergence. (arXiv:2105.11066v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2105.11066</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy optimization, which learns the policy of interest by maximizing the
value function via large-scale optimization techniques, lies at the heart of
modern reinforcement learning (RL). In addition to value maximization, other
practical considerations arise commonly as well, including the need of
encouraging exploration, and that of ensuring certain structural properties of
the learned policy due to safety, resource and operational constraints. These
considerations can often be accounted for by resorting to regularized RL, which
augments the target value function with a structure-promoting regularization
term. Focusing on an infinite-horizon discounted Markov decision process, this
paper proposes a generalized policy mirror descent (GPMD) algorithm for solving
regularized RL. As a generalization of policy mirror descent Lan (2021), the
proposed algorithm accommodates a general class of convex regularizers as well
as a broad family of Bregman divergence in cognizant of the regularizer in use.
We demonstrate that our algorithm converges linearly over an entire range of
learning rates, in a dimension-free fashion, to the global solution, even when
the regularizer lacks strong convexity and smoothness. In addition, this linear
convergence feature is provably stable in the face of inexact policy evaluation
and imperfect policy updates. Numerical experiments are provided to corroborate
the applicability and appealing performance of GPMD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1&quot;&gt;Wenhao Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1&quot;&gt;Shicong Cen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Baihe Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.11367">
<title>FedScale: Benchmarking Model and System Performance of Federated Learning at Scale. (arXiv:2105.11367v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2105.11367</link>
<description rdf:parseType="Literal">&lt;p&gt;We present FedScale, a diverse set of challenging and realistic benchmark
datasets to facilitate scalable, comprehensive, and reproducible federated
learning (FL) research. FedScale datasets are large-scale, encompassing a
diverse range of important FL tasks, such as image classification, object
detection, word prediction, and speech recognition. For each dataset, we
provide a unified evaluation protocol using realistic data splits and
evaluation metrics. To meet the pressing need for reproducing realistic FL at
scale, we have also built an efficient evaluation platform to simplify and
standardize the process of FL experimental setup and model evaluation. Our
evaluation platform provides flexible APIs to implement new FL algorithms and
includes new execution backends with minimal developer efforts. Finally, we
perform in-depth benchmark experiments on these datasets. Our experiments
suggest fruitful opportunities in heterogeneity-aware co-optimizations of the
system and statistical efficiency under realistic FL characteristics. FedScale
is open-source with permissive licenses and actively maintained, and we welcome
feedback and contributions from the community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1&quot;&gt;Fan Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1&quot;&gt;Yinwei Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiangfeng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhyastha_H/0/1/0/all/0/1&quot;&gt;Harsha V. Madhyastha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1&quot;&gt;Mosharaf Chowdhury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.12122">
<title>Optical coherent dot-product chip for sophisticated deep learning regression. (arXiv:2105.12122v2 [cs.ET] UPDATED)</title>
<link>http://arxiv.org/abs/2105.12122</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical implementations of neural networks (ONNs) herald the next-generation
high-speed and energy-efficient deep learning computing by harnessing the
technical advantages of large bandwidth and high parallelism of optics.
However, due to the problems of incomplete numerical domain, limited hardware
scale, or inadequate numerical accuracy, the majority of existing ONNs were
studied for basic classification tasks. Given that regression is a fundamental
form of deep learning and accounts for a large part of current artificial
intelligence applications, it is necessary to master deep learning regression
for further development and deployment of ONNs. Here, we demonstrate a
silicon-based optical coherent dot-product chip (OCDC) capable of completing
deep learning regression tasks. The OCDC adopts optical fields to carry out
operations in complete real-value domain instead of in only positive domain.
Via reusing, a single chip conducts matrix multiplications and convolutions in
neural networks of any complexity. Also, hardware deviations are compensated
via in-situ backpropagation control provided the simplicity of chip
architecture. Therefore, the OCDC meets the requirements for sophisticated
regression tasks and we successfully demonstrate a representative neural
network, the AUTOMAP (a cutting-edge neural network model for image
reconstruction). The quality of reconstructed images by the OCDC and a 32-bit
digital computer is comparable. To the best of our knowledge, there is no
precedent of performing such state-of-the-art regression tasks on ONN chip. It
is anticipated that the OCDC can promote novel accomplishment of ONNs in modern
AI applications including autonomous driving, natural language processing, and
scientific study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shaofu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_H/0/1/0/all/0/1&quot;&gt;Haowen Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhike Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1&quot;&gt;Sicheng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1&quot;&gt;Bowen Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xingjun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jianguo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1&quot;&gt;Weiwen Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.13133">
<title>Modeling of unsaturated flow through porous media using meshless methods. (arXiv:2105.13133v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2105.13133</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we focus on the modelling of infiltration process in porous
media. We use the meshless techniques for efficiently solving the Richards
equation which describes unsaturated water flow through soils. The design of
approximate numerical methods for the Richards equation remains computationally
challenging and requires the development of efficient numerical techniques.
This difficulty is mainly due to the nonlinearity of the unsaturated hydraulic
conductivity and the capillary pressure function. In this study, we develop a
new method based on the localized radial basis function (RBF) and the Kirchhoff
transformation technique in order to solve Richards equation in one and
two-dimensional homogeneous medium. Our approach using the multiquadric radial
basis function allows us to reduce the computational time and provide accurate
numerical solutions. The proposed method does not require mesh generation.
Picard&apos;s iterations are used to linearize the resulting nonlinear problem
obtained using the Kirchhoff transformation technique. The numerical
simulations show the capability of the proposed numerical techniques in
predicting the dynamics of water through unsaturated soils.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Boujoudar_M/0/1/0/all/0/1&quot;&gt;Mohamed Boujoudar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Beljadid_A/0/1/0/all/0/1&quot;&gt;Abdelaziz Beljadid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Taik_A/0/1/0/all/0/1&quot;&gt;Ahmed Taik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.02383">
<title>PoDT: A Secure Multi-chains Consensus Scheme Against Diverse Miners Behaviors Attacks in Blockchain Networks. (arXiv:2106.02383v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2106.02383</link>
<description rdf:parseType="Literal">&lt;p&gt;As cross-chain technologies make the interactions among different blockchains
(hereinafter &quot;chains&quot;) possible, multi-chains consensus is becoming more and
more important in blockchain networks. However, more attention has been paid to
the single-chain consensus schemes. The multi-chains consensus with trusted
miners participation has been not considered, thus offering opportunities for
malicious users to launch Diverse Miners Behaviors (DMB) attacks on different
chains. DMB attackers can be friendly in the consensus process of some chains
called mask-chains to enhance trust value, while on other chains called
kill-chains they engage in destructive behaviors of network. In this paper, we
propose a multi-chains consensus scheme named as Proof-of-DiscTrust (PoDT) to
defend against DMB attacks. Distinctive trust idea (DiscTrust) is introduced to
evaluate the trust value of each user concerning different chains. A dynamic
behaviors prediction scheme is designed to strengthen DiscTrust to prevent
intensive DMB attackers who maintain high trust by alternately creating true or
false blocks on kill-chains. On this basis, a trusted miners selection
algorithm for multi-chains can be achieved at a round of block creation.
Experimental results show that PoDT is secure against DMB attacks and more
effective than traditional consensus schemes in multi-chains environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenbo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jingyu Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.02473">
<title>GasHisSDB: A New Gastric Histopathology Image Dataset for Computer Aided Diagnosis of Gastric Cancer. (arXiv:2106.02473v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2106.02473</link>
<description rdf:parseType="Literal">&lt;p&gt;Background and Objective: Gastric cancer has turned out to be the fifth most
common cancer globally, and early detection of gastric cancer is essential to
save lives. Histopathological examination of gastric cancer is the gold
standard for the diagnosis of gastric cancer. However, computer-aided
diagnostic techniques are challenging to evaluate due to the scarcity of
publicly available gastric histopathology image datasets. Methods: In this
paper, a noble publicly available Gastric Histopathology Sub-size Image
Database (GasHisSDB) is published to identify classifiers&apos; performance.
Specifically, two types of data are included: normal and abnormal, with a total
of 245,196 tissue case images. In order to prove that the methods of different
periods in the field of image classification have discrepancies on GasHisSDB,
we select a variety of classifiers for evaluation. Seven classical machine
learning classifiers, three Convolutional Neural Network classifiers, and a
novel transformer-based classifier are selected for testing on image
classification tasks. Results: This study performed extensive experiments using
traditional machine learning and deep learning methods to prove that the
methods of different periods have discrepancies on GasHisSDB. Traditional
machine learning achieved the best accuracy rate of 86.08% and a minimum of
just 41.12%. The best accuracy of deep learning reached 96.47% and the lowest
was 86.21%. Accuracy rates vary significantly across classifiers. Conclusions:
To the best of our knowledge, it is the first publicly available gastric cancer
histopathology dataset containing a large number of images for weakly
supervised learning. We believe that GasHisSDB can attract researchers to
explore new algorithms for the automated diagnosis of gastric cancer, which can
help physicians and patients in the clinical setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Weiming Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahaman_M/0/1/0/all/0/1&quot;&gt;Md Mamunur Rahaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jiquan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Haoyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wanli Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Changhao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yudong Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hongzan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1&quot;&gt;Marcin Grzegorzek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.03632">
<title>Quantifying and Improving Transferability in Domain Generalization. (arXiv:2106.03632v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.03632</link>
<description rdf:parseType="Literal">&lt;p&gt;Out-of-distribution generalization is one of the key challenges when
transferring a model from the lab to the real world. Existing efforts mostly
focus on building invariant features among source and target domains. Based on
invariant features, a high-performing classifier on source domains could
hopefully behave equally well on a target domain. In other words, the invariant
features are \emph{transferable}. However, in practice, there are no perfectly
transferable features, and some algorithms seem to learn &quot;more transferable&quot;
features than others. How can we understand and quantify such
\emph{transferability}? In this paper, we formally define transferability that
one can quantify and compute in domain generalization. We point out the
difference and connection with common discrepancy measures between domains,
such as total variation and Wasserstein distance. We then prove that our
transferability can be estimated with enough samples and give a new upper bound
for the target error based on our transferability. Empirically, we evaluate the
transferability of the feature embeddings learned by existing algorithms for
domain generalization. Surprisingly, we find that many algorithms are not quite
learning transferable features, although few could still survive. In light of
this, we propose a new algorithm for learning transferable features and test it
over various benchmark datasets, including RotatedMNIST, PACS, Office-Home and
WILDS-FMoW. Experimental results show that the proposed algorithm achieves
consistent improvement over many state-of-the-art algorithms, corroborating our
theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guojun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Han Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yaoliang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.03898">
<title>SPANet: Generalized Permutationless Set Assignment for Particle Physics using Symmetry Preserving Attention. (arXiv:2106.03898v2 [hep-ex] UPDATED)</title>
<link>http://arxiv.org/abs/2106.03898</link>
<description rdf:parseType="Literal">&lt;p&gt;The creation of unstable heavy particles at the Large Hadron Collider is the
most direct way to address some of the deepest open questions in physics.
Collisions typically produce variable-size sets of observed particles which
have inherent ambiguities complicating the assignment of observed particles to
the decay products of the heavy particles. Current strategies for tackling
these challenges in the physics community ignore the physical symmetries of the
decay products and consider all possible assignment permutations and do not
scale to complex configurations. Attention based deep learning methods for
sequence modelling have achieved state-of-the-art performance in natural
language processing, but they lack built-in mechanisms to deal with the unique
symmetries found in physical set-assignment problems. We introduce a novel
method for constructing symmetry-preserving attention networks which reflect
the problem&apos;s natural invariances to efficiently find assignments without
evaluating all permutations. This general approach is applicable to arbitrarily
complex configurations and significantly outperforms current methods, improving
reconstruction efficiency between 19\% - 35\% on typical benchmark problems
while decreasing inference time by two to five orders of magnitude on the most
complex events, making many important and previously intractable cases
tractable.
&lt;/p&gt;
&lt;p&gt;A full code repository containing a general library, the specific
configuration used, and a complete dataset release, are avaiable at
https://github.com/Alexanders101/SPANet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Shmakov_A/0/1/0/all/0/1&quot;&gt;Alexander Shmakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Fenton_M/0/1/0/all/0/1&quot;&gt;Michael James Fenton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Ho_T/0/1/0/all/0/1&quot;&gt;Ta-Wei Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Hsu_S/0/1/0/all/0/1&quot;&gt;Shih-Chieh Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Whiteson_D/0/1/0/all/0/1&quot;&gt;Daniel Whiteson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Baldi_P/0/1/0/all/0/1&quot;&gt;Pierre Baldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.04031">
<title>Balancing Asymptotic and Transient Efficiency Guarantees in Set Covering Games. (arXiv:2106.04031v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2106.04031</link>
<description rdf:parseType="Literal">&lt;p&gt;Game theoretic approaches have gained traction as robust methodologies for
designing distributed local algorithms that induce a desired overall system
configuration in multi-agent settings. However, much of the emphasis in these
approaches is on providing asymptotic guarantees on the performance of a
network of agents, and there is a gap in the study of efficiency guarantees
along transients of these distributed algorithms. Therefore, in this paper, we
study the transient efficiency guarantees of a natural game-theoretic algorithm
in the class of set covering games, which have been used to model a variety of
applications. Our main results characterize the optimal utility design that
maximizes the guaranteed efficiency along the transient of the natural
dynamics. Furthermore, we characterize the Pareto-optimal frontier with regards
to guaranteed efficiency in the transient and the asymptote under a class of
game-theoretic designs. Surprisingly, we show that there exists an extreme
trade-off between the long-term and short-term guarantees in that an
asymptotically optimal game-theoretic design can perform arbitrarily bad in the
transient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Konda_R/0/1/0/all/0/1&quot;&gt;Rohit Konda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chandan_R/0/1/0/all/0/1&quot;&gt;Rahul Chandan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Grimsman_D/0/1/0/all/0/1&quot;&gt;David Grimsman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Marden_J/0/1/0/all/0/1&quot;&gt;Jason R. Marden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.04169">
<title>On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2106.04169</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision transformers (ViTs) process input images as sequences of patches via
self-attention; a radically different architecture than convolutional neural
networks (CNNs). This makes it interesting to study the adversarial feature
space of ViT models and their transferability. In particular, we observe that
adversarial patterns found via conventional adversarial attacks show very low
black-box transferability even for large ViT models. However, we show that this
phenomenon is only due to the sub-optimal attack procedures that do not
leverage the true representation potential of ViTs. A deep ViT is composed of
multiple blocks, with a consistent architecture comprising of self-attention
and feed-forward layers, where each block is capable of independently producing
a class token. Formulating an attack using only the last class token
(conventional approach) does not directly leverage the discriminative
information stored in the earlier tokens, leading to poor adversarial
transferability of ViTs. Using the compositional nature of ViT models, we
enhance the transferability of existing attacks by introducing two novel
strategies specific to the architecture of ViT models. (i) Self-Ensemble: We
propose a method to find multiple discriminative pathways by dissecting a
single ViT model into an ensemble of networks. This allows explicitly utilizing
class-specific information at each ViT block. (ii) Token Refinement: We then
propose to refine the tokens to further enhance the discriminative capacity at
each block of ViT. Our token refinement systematically combines the class
tokens with structural information preserved within the patch tokens. An
adversarial attack, when applied to such refined tokens within the ensemble of
classifiers found in a single vision transformer, has significantly higher
transferability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1&quot;&gt;Muzammal Naseer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1&quot;&gt;Kanchana Ranasinghe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Salman Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1&quot;&gt;Fahad Shahbaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1&quot;&gt;Fatih Porikli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.04537">
<title>Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks. (arXiv:2106.04537v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.04537</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are powerful machines for visual pattern recognition,
but reasoning tasks that are easy for humans may still be difficult for neural
models. Humans possess the ability to extrapolate reasoning strategies learned
on simple problems to solve harder examples, often by thinking for longer. For
example, a person who has learned to solve small mazes can easily extend the
very same search techniques to solve much larger mazes by spending more time.
In computers, this behavior is often achieved through the use of algorithms,
which scale to arbitrarily hard problem instances at the cost of more
computation. In contrast, the sequential computing budget of feed-forward
neural networks is limited by their depth, and networks trained on simple
problems have no way of extending their reasoning to accommodate harder
problems. In this work, we show that recurrent networks trained to solve simple
problems with few recurrent steps can indeed solve much more complex problems
simply by performing additional recurrences during inference. We demonstrate
this algorithmic behavior of recurrent networks on prefix sum computation,
mazes, and chess. In all three domains, networks trained on simple problem
instances are able to extend their reasoning abilities at test time simply by
&quot;thinking for longer.&quot;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1&quot;&gt;Avi Schwarzschild&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borgnia_E/0/1/0/all/0/1&quot;&gt;Eitan Borgnia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arjun Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Furong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishkin_U/0/1/0/all/0/1&quot;&gt;Uzi Vishkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1&quot;&gt;Micah Goldblum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.04627">
<title>Densely connected normalizing flows. (arXiv:2106.04627v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.04627</link>
<description rdf:parseType="Literal">&lt;p&gt;Normalizing flows are bijective mappings between inputs and latent
representations with a fully factorized distribution. They are very attractive
due to exact likelihood valuation and efficient sampling. However, their
effective capacity is often insufficient since the bijectivity constraint
limits the model width. We address this issue by incrementally padding
intermediate representations with noise. We precondition the noise in
accordance with previous invertible units, which we describe as cross-unit
coupling. Our invertible glow-like modules increase the model expressivity by
fusing a densely connected block with Nystrom self-attention. We refer to our
architecture as DenseFlow since both cross-unit and intra-module couplings rely
on dense connectivity. Experiments show significant improvements due to the
proposed contributions and reveal state-of-the-art density estimation under
moderate computing budgets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1&quot;&gt;Matej Grci&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1&quot;&gt;Ivan Grubi&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1&quot;&gt;Sini&amp;#x161;a &amp;#x160;egvi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.05378">
<title>Parameter and Feature Selection in Stochastic Linear Bandits. (arXiv:2106.05378v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.05378</link>
<description rdf:parseType="Literal">&lt;p&gt;We study two model selection settings in stochastic linear bandits (LB). In
the first setting, which we refer to as feature selection, the expected reward
of the LB problem is in the linear span of at least one of $M$ feature maps
(models). In the second setting, the reward parameter of the LB problem is
arbitrarily selected from $M$ models represented as (possibly) overlapping
balls in $\mathbb R^d$. However, the agent only has access to misspecified
models, i.e., estimates of the centers and radii of the balls. We refer to this
setting as parameter selection. For each setting, we develop and analyze an
algorithm that is based on a reduction from bandits to full-information
problems. This allows us to obtain regret bounds that are not worse (up to a
$\sqrt{\log M}$ factor) than the case where the true model is known. The regret
of our parameter selection algorithm also scales logarithmically with model
uncertainty. Finally, we empirically show the effectiveness of our algorithms
using synthetic and real-world experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moradipari_A/0/1/0/all/0/1&quot;&gt;Ahmadreza Moradipari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turan_B/0/1/0/all/0/1&quot;&gt;Berkay Turan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1&quot;&gt;Mahnoosh Alizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghavamzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.05386">
<title>Artificial Intelligence in Drug Discovery: Applications and Techniques. (arXiv:2106.05386v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.05386</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) has been transforming the practice of drug
discovery in the past decade. Various AI techniques have been used in a wide
range of applications, such as virtual screening and drug design. In this
survey, we first give an overview on drug discovery and discuss related
applications, which can be reduced to two major tasks, i.e., molecular property
prediction and molecule generation. We then discuss common data resources,
molecule representations and benchmark platforms. Furthermore, to summarize the
progress of AI in drug discovery, we present the relevant AI techniques
including model architectures and learning paradigms in the papers surveyed. We
expect that this survey will serve as a guide for researchers who are
interested in working at the interface of artificial intelligence and drug
discovery. We also provide a GitHub repository
(https://github.com/dengjianyuan/Survey_AI_Drug_Discovery) with the collection
of papers and codes, if applicable, as a learning resource, which is regularly
updated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jianyuan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhibo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ojima_I/0/1/0/all/0/1&quot;&gt;Iwao Ojima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1&quot;&gt;Dimitris Samaras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fusheng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.06306">
<title>A survey on Functional Encryption. (arXiv:2106.06306v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2106.06306</link>
<description rdf:parseType="Literal">&lt;p&gt;Functional Encryption (FE) expands traditional public-key encryption in two
different ways: it supports fine-grained access control and allows learning a
function of the encrypted data. In this paper, we review all FE classes,
describing their functionalities and main characteristics. In particular, we
mention several schemes for each class, providing their security assumptions
and comparing their properties. To our knowledge, this is the first survey that
encompasses the entire FE family.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mascia_C/0/1/0/all/0/1&quot;&gt;Carla Mascia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sala_M/0/1/0/all/0/1&quot;&gt;Massimiliano Sala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villa_I/0/1/0/all/0/1&quot;&gt;Irene Villa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.06308">
<title>The Complexity of Sparse Tensor PCA. (arXiv:2106.06308v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.06308</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of sparse tensor principal component analysis: given a
tensor $\pmb Y = \pmb W + \lambda x^{\otimes p}$ with $\pmb W \in
\otimes^p\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover
the $k$-sparse unit vector $x \in \mathbb{R}^n$. The model captures both sparse
PCA (in its Wigner form) and tensor PCA.
&lt;/p&gt;
&lt;p&gt;For the highly sparse regime of $k \leq \sqrt{n}$, we present a family of
algorithms that smoothly interpolates between a simple polynomial-time
algorithm and the exponential-time exhaustive search algorithm. For any $1 \leq
t \leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio
$\lambda \geq \tilde{\mathcal{O}} (\sqrt{t} \cdot (k/t)^{p/2})$ in time
$\tilde{\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for
the matrix settings (in both the polynomial-time and sub-exponential time
regimes).
&lt;/p&gt;
&lt;p&gt;Our results naturally extend to the case of $r$ distinct $k$-sparse signals
with disjoint supports, with guarantees that are independent of the number of
spikes. Even in the restricted case of sparse PCA, known algorithms only
recover the sparse vectors for $\lambda \geq \tilde{\mathcal{O}}(k \cdot r)$
while our algorithms require $\lambda \geq \tilde{\mathcal{O}}(k)$.
&lt;/p&gt;
&lt;p&gt;Finally, by analyzing the low-degree likelihood ratio, we complement these
algorithmic results with rigorous evidence illustrating the trade-offs between
signal-to-noise ratio and running time. This lower bound captures the known
lower bounds for both sparse PCA and tensor PCA. In this general model, we
observe a more intricate three-way trade-off between the number of samples $n$,
the sparsity $k$, and the tensor power $p$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1&quot;&gt;Davin Choo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1&quot;&gt;Tommaso d&amp;#x27;Orsi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.07085">
<title>Survey: Image Mixing and Deleting for Data Augmentation. (arXiv:2106.07085v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2106.07085</link>
<description rdf:parseType="Literal">&lt;p&gt;Data augmentation has been widely used to improve deep nerual networks
performance. Numerous approaches are suggested, for example, dropout,
regularization and image augmentation, to avoid over-ftting and enhancing
generalization of neural networks. One of the sub-area within data augmentation
is image mixing and deleting. This specific type of augmentation either mixes
two images or delete image regions to hide or make certain characteristics of
images confusing for the network to force it to emphasize on overall structure
of object in image. The model trained with this approach has shown to perform
and generalize well as compared to one trained without imgage mixing or
deleting. Additional benefit achieved with this method of training is
robustness against image corruptions. Due to its low compute cost and success
in recent past, many techniques of image mixing and deleting are proposed. This
paper provides detailed review on these devised approaches, dividing
augmentation strategies in three main categories cut and delete, cut and mix
and mixup. The second part of paper emprically evaluates these approaches for
image classification, finegrained image recognition and object detection where
it is shown that this category of data augmentation improves the overall
performance for deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naveed_H/0/1/0/all/0/1&quot;&gt;Humza Naveed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.07504">
<title>Characterizing the risk of fairwashing. (arXiv:2106.07504v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.07504</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairwashing refers to the risk that an unfair black-box model can be
explained by a fairer model through post-hoc explanation manipulation. In this
paper, we investigate the capability of fairwashing attacks by analyzing their
fidelity-unfairness trade-offs. In particular, we show that fairwashed
explanation models can generalize beyond the suing group (i.e., data points
that are being explained), meaning that a fairwashed explainer can be used to
rationalize subsequent unfair decisions of a black-box model. We also
demonstrate that fairwashing attacks can transfer across black-box models,
meaning that other black-box models can perform fairwashing without explicitly
using their predictions. This generalization and transferability of fairwashing
attacks imply that their detection will be difficult in practice. Finally, we
propose an approach to quantify the risk of fairwashing, which is based on the
computation of the range of the unfairness of high-fidelity explainers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aivodji_U/0/1/0/all/0/1&quot;&gt;Ulrich A&amp;#xef;vodji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arai_H/0/1/0/all/0/1&quot;&gt;Hiromi Arai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gambs_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Gambs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hara_S/0/1/0/all/0/1&quot;&gt;Satoshi Hara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.08208">
<title>SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2106.08208</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive gradient methods have shown excellent performances for solving many
machine learning problems. Although multiple adaptive methods were recently
studied, they mainly focus on either empirical or theoretical aspects and also
only work for specific problems by using some specific adaptive learning rates.
It is desired to design a universal framework for practical algorithms of
adaptive gradients with theoretical guarantee to solve general problems. To
fill this gap, we propose a faster and universal framework of adaptive
gradients (i.e., SUPER-ADAM) by introducing a universal adaptive matrix that
includes most existing adaptive gradient forms. Moreover, our framework can
flexibly integrate the momentum and variance reduced techniques. In particular,
our novel framework provides the convergence analysis support for adaptive
gradient methods under the nonconvex setting. In theoretical analysis, we prove
that our SUPER-ADAM algorithm can achieve the best known complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms. Code is available at
https://github.com/LIJUNYI95/SuperAdam
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Feihu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Junyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.09012">
<title>A learning agent that acquires social norms from public sanctions in decentralized multi-agent settings. (arXiv:2106.09012v3 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/2106.09012</link>
<description rdf:parseType="Literal">&lt;p&gt;Society is characterized by the presence of a variety of social norms:
collective patterns of sanctioning that can prevent miscoordination and
free-riding. Inspired by this, we aim to construct learning dynamics where
potentially beneficial social norms can emerge. Since social norms are
underpinned by sanctioning, we introduce a training regime where agents can
access all sanctioning events but learning is otherwise decentralized. This
setting is technologically interesting because sanctioning events may be the
only available public signal in decentralized multi-agent systems where reward
or policy-sharing is infeasible or undesirable. To achieve collective action in
this setting we construct an agent architecture containing a classifier module
that categorizes observed behaviors as approved or disapproved, and a
motivation to punish in accord with the group. We show that social norms emerge
in multi-agent systems containing this agent and investigate the conditions
under which this helps them achieve socially beneficial outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinitsky_E/0/1/0/all/0/1&quot;&gt;Eugene Vinitsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koster_R/0/1/0/all/0/1&quot;&gt;Raphael K&amp;#xf6;ster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agapiou_J/0/1/0/all/0/1&quot;&gt;John P. Agapiou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duenez_Guzman_E/0/1/0/all/0/1&quot;&gt;Edgar Du&amp;#xe9;&amp;#xf1;ez-Guzm&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vezhnevets_A/0/1/0/all/0/1&quot;&gt;Alexander Sasha Vezhnevets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibo_J/0/1/0/all/0/1&quot;&gt;Joel Z. Leibo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.09779">
<title>Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.09779</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of federated learning (FL) in the absence of a
trustworthy server/clients. In this setting, each client needs to ensure the
privacy of its own data without relying on the server or other clients. We
study local differential privacy (LDP) and provide tight upper and lower bounds
that establish the minimax optimal rates (up to logarithms) for LDP
convex/strongly convex federated stochastic optimization. Our rates match the
optimal statistical rates in certain practical parameter regimes (&quot;privacy for
free&quot;). Second, we develop a novel time-varying noisy SGD algorithm, leading to
the first non-trivial LDP risk bounds for FL with non-i.i.d. clients. Third, we
consider the special case where each client&apos;s loss function is empirical and
develop an accelerated LDP FL algorithm to improve communication complexity
compared to existing works. We also provide matching lower bounds, establishing
the optimality of our algorithm for convex/strongly convex settings. Fourth,
with a secure shuffler to anonymize client reports (but without a trusted
server), our algorithm attains the optimal central DP rates for stochastic
convex/strongly convex optimization, thereby achieving optimality in the local
and central models simultaneously. Our upper bounds quantify the role of
network communication reliability in performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1&quot;&gt;Andrew Lowy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1&quot;&gt;Meisam Razaviyayn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.13008">
<title>Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting. (arXiv:2106.13008v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.13008</link>
<description rdf:parseType="Literal">&lt;p&gt;Extending the forecasting time is a critical demand for real applications,
such as extreme weather early warning and long-term energy consumption
planning. This paper studies the long-term forecasting problem of time series.
Prior Transformer-based models adopt various self-attention mechanisms to
discover the long-range dependencies. However, intricate temporal patterns of
the long-term future prohibit the model from finding reliable dependencies.
Also, Transformers have to adopt the sparse versions of point-wise
self-attentions for long series efficiency, resulting in the information
utilization bottleneck. Going beyond Transformers, we design Autoformer as a
novel decomposition architecture with an Auto-Correlation mechanism. We break
with the pre-processing convention of series decomposition and renovate it as a
basic inner block of deep models. This design empowers Autoformer with
progressive decomposition capacities for complex time series. Further, inspired
by the stochastic process theory, we design the Auto-Correlation mechanism
based on the series periodicity, which conducts the dependencies discovery and
representation aggregation at the sub-series level. Auto-Correlation
outperforms self-attention in both efficiency and accuracy. In long-term
forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative
improvement on six benchmarks, covering five practical applications: energy,
traffic, economics, weather and disease. Code is available at this repository:
\url{https://github.com/thuml/Autoformer}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Haixu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiehui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianmin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1&quot;&gt;Mingsheng Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.14564">
<title>Two-point AG codes from the Beelen-Montanucci maximal curve. (arXiv:2106.14564v2 [math.AG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.14564</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we investigate two-point algebraic-geometry codes (AG codes)
coming from the Beelen-Montanucci (BM) maximal curve. We study properties of
certain two-point Weierstrass semigroups of the curve and use them for
determining a lower bound on the minimum distance of such codes. AG codes with
better parameters with respect to comparable two-point codes from the
Garcia-G\&quot;uneri-Stichtenoth (GGS) curve are discovered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Landi_L/0/1/0/all/0/1&quot;&gt;Leonardo Landi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Vicino_L/0/1/0/all/0/1&quot;&gt;Lara Vicino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.14568">
<title>Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity. (arXiv:2106.14568v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.14568</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works on sparse neural networks have demonstrated the possibility to
train a sparse subnetwork independently from scratch, to match the performance
of its corresponding dense network. However, identifying such sparse
subnetworks (winning tickets) either involves a costly iterative
train-prune-retrain process (e.g., Lottery Ticket Hypothesis) or an
over-extended training time (e.g., Dynamic Sparse Training). In this work, we
draw a unique connection between sparse neural network training and the deep
ensembling technique, yielding a novel ensemble learning framework called
FreeTickets. Instead of starting from a dense network, FreeTickets randomly
initializes a sparse subnetwork and then trains the subnetwork while
dynamically adjusting its sparse mask, resulting in many diverse sparse
subnetworks throughout the training process. FreeTickets is defined as the
ensemble of these sparse subnetworks freely obtained during this one-pass,
sparse-to-sparse training, which uses only a fraction of the computational
resources required by the vanilla dense training. Moreover, despite being an
ensemble of models, FreeTickets has even fewer parameters and training FLOPs
compared to a single dense model: this seemingly counter-intuitive outcome is
due to the high sparsity of each subnetwork. FreeTickets is observed to
demonstrate a significant all-round improvement compared to standard dense
baselines, in prediction accuracy, uncertainty estimation, robustness, and
efficiency. FreeTickets easily outperforms the naive deep ensemble with
ResNet50 on ImageNet using only a quarter of the training FLOPs required by the
latter. Our results provide insights into the strength of sparse neural
networks and suggest that the benefits of sparsity go way beyond the usually
expected inference efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianlong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atashgahi_Z/0/1/0/all/0/1&quot;&gt;Zahra Atashgahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaohan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokar_G/0/1/0/all/0/1&quot;&gt;Ghada Sokar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mocanu_E/0/1/0/all/0/1&quot;&gt;Elena Mocanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1&quot;&gt;Mykola Pechenizkiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1&quot;&gt;Decebal Constantin Mocanu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.15916">
<title>Communication conditions in virtual acoustic scenes in an underground station. (arXiv:2106.15916v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2106.15916</link>
<description rdf:parseType="Literal">&lt;p&gt;Underground stations are a common communication situation in towns: we talk
with friends or colleagues, listen to announcements or shop for titbits while
background noise and reverberation are challenging communication. Here, we
perform an acoustical analysis of two communication scenes in an underground
station in Munich and test speech intelligibility. The acoustical conditions
were measured in the station and are compared to simulations in the real-time
Simulated Open Field Environment (rtSOFE). We compare binaural room impulse
responses measured with an artificial head in the station to modeled impulse
responses for free-field auralization via 60 loudspeakers in the rtSOFE. We
used the image source method to model early reflections and a set of
multi-microphone recordings to model late reverberation. The first
communication scene consists of 12 equidistant (1.6 m) horizontally spaced
source positions around a listener, simulating different direction-dependent
spatial unmasking conditions. The second scene mimics an approaching speaker
across six radially spaced source positions (from 1 m to 10 m) with varying
direct sound level and thus direct-to-reverberant energy. The acoustic
parameters of the underground station show a moderate amount of reverberation
(T30 in octave bands was between 2.3 s and 0.6 s and early-decay times between
1.46 s and 0.46 s). The binaural and energetic parameters of the auralization
were in a close match to the measurement. Measured speech reception thresholds
were within the error of the speech test, letting us to conclude that the
auralized simulation reproduces acoustic and perceptually relevant parameters
for speech intelligibility with high accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hladek_L/0/1/0/all/0/1&quot;&gt;&amp;#x13d;ubo&amp;#x161; Hl&amp;#xe1;dek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ewert_S/0/1/0/all/0/1&quot;&gt;Stephan D. Ewert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seeber_B/0/1/0/all/0/1&quot;&gt;Bernhard U. Seeber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.16122">
<title>Zombies in the Loop? Humans Trust Untrustworthy AI-Advisors for Ethical Decisions. (arXiv:2106.16122v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2106.16122</link>
<description rdf:parseType="Literal">&lt;p&gt;Departing from the claim that AI needs to be trustworthy, we find that
ethical advice from an AI-powered algorithm is trusted even when its users know
nothing about its training data and when they learn information about it that
warrants distrust. We conducted online experiments where the subjects took the
role of decision-makers who received advice from an algorithm on how to deal
with an ethical dilemma. We manipulated the information about the algorithm and
studied its influence. Our findings suggest that AI is overtrusted rather than
distrusted. We suggest digital literacy as a potential remedy to ensure the
responsible use of AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krugel_S/0/1/0/all/0/1&quot;&gt;Sebastian Kr&amp;#xfc;gel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostermaier_A/0/1/0/all/0/1&quot;&gt;Andreas Ostermaier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uhl_M/0/1/0/all/0/1&quot;&gt;Matthias Uhl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.16187">
<title>Reinforcement Learning based Disease Progression Model for Alzheimer&apos;s Disease. (arXiv:2106.16187v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.16187</link>
<description rdf:parseType="Literal">&lt;p&gt;We model Alzheimer&apos;s disease (AD) progression by combining differential
equations (DEs) and reinforcement learning (RL) with domain knowledge. DEs
provide relationships between some, but not all, factors relevant to AD. We
assume that the missing relationships must satisfy general criteria about the
working of the brain, for e.g., maximizing cognition while minimizing the cost
of supporting cognition. This allows us to extract the missing relationships by
using RL to optimize an objective (reward) function that captures the above
criteria. We use our model consisting of DEs (as a simulator) and the trained
RL agent to predict individualized 10-year AD progression using baseline (year
0) features on synthetic and real data. The model was comparable or better at
predicting 10-year cognition trajectories than state-of-the-art learning-based
models. Our interpretable model demonstrated, and provided insights into,
&quot;recovery/compensatory&quot; processes that mitigate the effect of AD, even though
those processes were not explicitly encoded in the model. Our framework
combines DEs with RL for modelling AD progression and has broad applicability
for understanding other neurological disorders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saboo_K/0/1/0/all/0/1&quot;&gt;Krishnakant V. Saboo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhary_A/0/1/0/all/0/1&quot;&gt;Anirudh Choudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yurui Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Worrell_G/0/1/0/all/0/1&quot;&gt;Gregory A. Worrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1&quot;&gt;David T. Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1&quot;&gt;Ravishankar K. Iyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.00820">
<title>Robust multigrid techniques for augmented Lagrangian preconditioning of incompressible Stokes equations with extreme viscosity variations. (arXiv:2107.00820v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2107.00820</link>
<description rdf:parseType="Literal">&lt;p&gt;We present augmented Lagrangian Schur complement preconditioners and robust
multigrid methods for incompressible Stokes problems with extreme viscosity
variations. Such Stokes systems arise, for instance, upon linearization of
nonlinear viscous flow problems, and they can have severely inhomogeneous and
anisotropic coefficients. Using an augmented Lagrangian formulation for the
incompressibility constraint makes the Schur complement easier to approximate,
but results in a nearly singular (1,1)-block in the Stokes system. We present
eigenvalue estimates for the quality of the Schur complement approximation. To
cope with the near-singularity of the (1,1)-block, we extend a multigrid scheme
with a discretization-dependent smoother and transfer operators from
triangular/tetrahedral to the quadrilateral/hexahedral finite element
discretizations $[\mathbb{Q}_k]^d\times \mathbb{P}_{k-1}^{\text{disc}}$, $k\geq
2$, $d=2,3$. Using numerical examples with scalar and with anisotropic
fourth-order tensor viscosity arising from linearization of a viscoplastic
constitutive relation, we confirm the robustness of the multigrid scheme and
the overall efficiency of the solver. We present scalability results using up
to 28,672 parallel tasks for problems with up to 1.6 billion unknowns and a
viscosity contrast up to ten orders of magnitude.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shih_Y/0/1/0/all/0/1&quot;&gt;Yu-hsuan Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stadler_G/0/1/0/all/0/1&quot;&gt;Georg Stadler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wechsung_F/0/1/0/all/0/1&quot;&gt;Florian Wechsung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.02071">
<title>fMBN-E: Efficient Unsupervised Network Structure Ensemble and Selection for Clustering. (arXiv:2107.02071v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.02071</link>
<description rdf:parseType="Literal">&lt;p&gt;It is known that unsupervised nonlinear dimensionality reduction and
clustering is sensitive to the selection of hyperparameters, particularly for
deep learning based methods, which hinder its practical use. How to select a
proper network structure that may be dramatically different in different
applications is a hard issue for deep models, given little prior knowledge of
data. In this paper, we explore ensemble learning and selection techniques for
automatically determining the optimal network structure of a deep model, named
multilayer bootstrap networks (MBN). Specifically, we first propose an MBN
ensemble (MBN-E) algorithm which concatenates the sparse outputs of a set of
MBN base models with different network structures into a new representation.
Because training an ensemble of MBN is expensive, we propose a fast version of
MBN-E (fMBN-E), which replaces the step of random data resampling in MBN-E by
the resampling of random similarity scores. Theoretically, fMBN-E is even
faster than a single standard MBN. Then, we take the new representation
produced by MBN-E as a reference for selecting the optimal MBN base models. Two
kinds of ensemble selection criteria, named optimization-like selection
criteria and distribution divergence criteria, are applied. Importantly, MBN-E
and its ensemble selection techniques maintain the simple formulation of MBN
that is based on one-nearest-neighbor learning, and reach the state-of-the-art
performance without manual hyperparameter tuning. fMBN-E is empirically even
hundreds of times faster than MBN-E without suffering performance degradation.
The source code is available at &lt;a href=&quot;http://www.xiaolei-zhang.net/mbn-e.htm.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao-Lei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.02397">
<title>Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed Number of Neurons. (arXiv:2107.02397v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.02397</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops simple feed-forward neural networks that achieve the
universal approximation property for all continuous functions with a fixed
finite number of neurons. These neural networks are simple because they are
designed with a simple and computable continuous activation function $\sigma$
leveraging a triangular-wave function and a softsign function. We prove that
$\sigma$-activated networks with width $36d(2d+1)$ and depth $11$ can
approximate any continuous function on a $d$-dimensioanl hypercube within an
arbitrarily small error. Hence, for supervised learning and its related
regression problems, the hypothesis space generated by these networks with a
size not smaller than $36d(2d+1)\times 11$ is dense in the space of continuous
functions. Furthermore, classification functions arising from image and signal
classification are in the hypothesis space generated by $\sigma$-activated
networks with width $36d(2d+1)$ and depth $12$, when there exist pairwise
disjoint closed bounded subsets of $\mathbb{R}^d$ such that the samples of the
same class are located in the same subset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zuowei Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haizhao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shijun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.02909">
<title>Deep Mesh Prior: Unsupervised Mesh Restoration using Graph Convolutional Networks. (arXiv:2107.02909v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2107.02909</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses mesh restoration problems, i.e., denoising and
completion, by learning self-similarity in an unsupervised manner. For this
purpose, the proposed method, which we refer to as Deep Mesh Prior, uses a
graph convolutional network on meshes to learn the self-similarity. The network
takes a single incomplete mesh as input data and directly outputs the
reconstructed mesh without being trained using large-scale datasets. Our method
does not use any intermediate representations such as an implicit field because
the whole process works on a mesh. We demonstrate that our unsupervised method
performs equally well or even better than the state-of-the-art methods using
large-scale datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hattori_S/0/1/0/all/0/1&quot;&gt;Shota Hattori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yatagawa_T/0/1/0/all/0/1&quot;&gt;Tatsuya Yatagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ohtake_Y/0/1/0/all/0/1&quot;&gt;Yutaka Ohtake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suzuki_H/0/1/0/all/0/1&quot;&gt;Hiromasa Suzuki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.03461">
<title>Comparing Machine Learning based Segmentation Models on Jet Fire Radiation Zones. (arXiv:2107.03461v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2107.03461</link>
<description rdf:parseType="Literal">&lt;p&gt;Risk assessment is relevant in any workplace, however there is a degree of
unpredictability when dealing with flammable or hazardous materials so that
detection of fire accidents by itself may not be enough. An example of this is
the impingement of jet fires, where the heat fluxes of the flame could reach
nearby equipment and dramatically increase the probability of a domino effect
with catastrophic results. Because of this, the characterization of such fire
accidents is important from a risk management point of view. One such
characterization would be the segmentation of different radiation zones within
the flame, so this paper presents an exploratory research regarding several
traditional computer vision and Deep Learning segmentation approaches to solve
this specific problem. A data set of propane jet fires is used to train and
evaluate the different approaches and given the difference in the distribution
of the zones and background of the images, different loss functions, that seek
to alleviate data imbalance, are also explored. Additionally, different metrics
are correlated to a manual ranking performed by experts to make an evaluation
that closely resembles the expert&apos;s criteria. The Hausdorff Distance and
Adjusted Random Index were the metrics with the highest correlation and the
best results were obtained from the UNet architecture with a Weighted
Cross-Entropy Loss. These results can be used in future research to extract
more geometric information from the segmentation masks or could even be
implemented on other types of fire accidents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Guerrero_C/0/1/0/all/0/1&quot;&gt;Carmina P&amp;#xe9;rez-Guerrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palacios_A/0/1/0/all/0/1&quot;&gt;Adriana Palacios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ochoa_Ruiz_G/0/1/0/all/0/1&quot;&gt;Gilberto Ochoa-Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mata_C/0/1/0/all/0/1&quot;&gt;Christian Mata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Mendoza_M/0/1/0/all/0/1&quot;&gt;Miguel Gonzalez-Mendoza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falcon_Morales_L/0/1/0/all/0/1&quot;&gt;Luis Eduardo Falc&amp;#xf3;n-Morales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.03955">
<title>On Margins and Derandomisation in PAC-Bayes. (arXiv:2107.03955v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.03955</link>
<description rdf:parseType="Literal">&lt;p&gt;We give a general recipe for derandomising PAC-Bayesian bounds using margins,
with the critical ingredient being that our randomised predictions concentrate
around some value. The tools we develop straightforwardly lead to margin bounds
for various classifiers, including linear prediction -- a class that includes
boosting and the support vector machine -- single-hidden-layer neural networks
with an unusual \(\erf\) activation function, and deep ReLU networks. Further,
we extend to partially-derandomised predictors where only some of the
randomness is removed, letting us extend bounds to cases where the
concentration properties of our predictors are otherwise poor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biggs_F/0/1/0/all/0/1&quot;&gt;Felix Biggs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guedj_B/0/1/0/all/0/1&quot;&gt;Benjamin Guedj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.07451">
<title>Data vs classifiers, who wins?. (arXiv:2107.07451v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.07451</link>
<description rdf:parseType="Literal">&lt;p&gt;The experiments covered by Machine Learning (ML) must consider two important
aspects to assess the performance of a model: datasets and algorithms. Robust
benchmarks are needed to evaluate the best classifiers. For this, one can adopt
gold standard benchmarks available in public repositories. However, it is
common not to consider the complexity of the dataset when evaluating. This work
proposes a new assessment methodology based on the combination of Item Response
Theory (IRT) and Glicko-2, a rating system mechanism generally adopted to
assess the strength of players (e.g., chess). For each dataset in a benchmark,
the IRT is used to estimate the ability of classifiers, where good classifiers
have good predictions for the most difficult test instances. Tournaments are
then run for each pair of classifiers so that Glicko-2 updates performance
information such as rating value, rating deviation and volatility for each
classifier. A case study was conducted hereby which adopted the OpenML-CC18
benchmark as the collection of datasets and pool of various classification
algorithms for evaluation. Not all datasets were observed to be really useful
for evaluating algorithms, where only 10% were considered really difficult.
Furthermore, the existence of a subset containing only 50% of the original
amount of OpenML-CC18 was verified, which is equally useful for algorithm
evaluation. Regarding the algorithms, the methodology proposed herein
identified the Random Forest as the algorithm with the best innate ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_L/0/1/0/all/0/1&quot;&gt;Lucas F. F. Cardoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_V/0/1/0/all/0/1&quot;&gt;Vitor C. A. Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frances_R/0/1/0/all/0/1&quot;&gt;Regiane S. Kawasaki Franc&amp;#xea;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prudencio_R/0/1/0/all/0/1&quot;&gt;Ricardo B. C. Prud&amp;#xea;ncio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_R/0/1/0/all/0/1&quot;&gt;Ronnie C. O. Alves&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.07994">
<title>Property-Aware Relation Networks for Few-Shot Molecular Property Prediction. (arXiv:2107.07994v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.07994</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular property prediction plays a fundamental role in drug discovery to
identify candidate molecules with target properties. However, molecular
property prediction is essentially a few-shot problem which makes it hard to
use regular machine learning models. In this paper, we propose a Property-Aware
Relation networks (PAR) to handle this problem. In comparison to existing
works, we leverage the fact that both relevant substructures and relationships
among molecules change across different molecular properties. We first
introduce a property-aware embedding function to transform the generic
molecular embeddings to substructure-aware space relevant to the target
property. Further, we design an adaptive relation graph learning module to
jointly estimate molecular relation graph and refine molecular embeddings
w.r.t. the target property, such that the limited labels can be effectively
propagated among similar molecules. We adopt a meta-learning strategy where the
parameters are selectively updated within tasks in order to model generic and
property-aware knowledge separately. Extensive experiments on benchmark
molecular property prediction datasets show that PAR consistently outperforms
existing methods and can obtain property-aware molecular embeddings and model
molecular relation graph properly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yaqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1&quot;&gt;Abulikemu Abuduweili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Quanming Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1&quot;&gt;Dejing Dou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.09834">
<title>Communication lower bounds for nested bilinear algorithms. (arXiv:2107.09834v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2107.09834</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop lower bounds on communication in the memory hierarchy or between
processors for nested bilinear algorithms, such as Strassen&apos;s algorithm for
matrix multiplication. We build on a previous framework that establishes
communication lower bounds by use of the rank expansion, or the minimum rank of
any fixed size subset of columns of a matrix, for each of the three matrices
encoding the bilinear algorithm. This framework provides lower bounds for any
way of computing a bilinear algorithm, which encompasses a larger space of
algorithms than by fixing a particular dependency graph. Nested bilinear
algorithms include fast recursive algorithms for convolution, matrix
multiplication, and contraction of tensors with symmetry. Two bilinear
algorithms can be nested by taking Kronecker products between their encoding
matrices. Our main result is a lower bound on the rank expansion of a matrix
constructed by a Kronecker product derived from lower bounds on the rank
expansion of the Kronecker product&apos;s operands. To prove this bound, we map a
subset of columns from a submatrix to a 2D grid, collapse them into a dense
grid, expand the grid, and use the size of the expanded grid to bound the
number of linearly independent columns of the submatrix. We apply the rank
expansion lower bounds to obtain novel communication lower bounds for nested
Toom-Cook convolution, Strassen&apos;s algorithm, and fast algorithms for partially
symmetric contractions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ju_C/0/1/0/all/0/1&quot;&gt;Caleb Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomonik_E/0/1/0/all/0/1&quot;&gt;Edgar Solomonik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.11786">
<title>Deep Learning-based Frozen Section to FFPE Translation. (arXiv:2107.11786v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2107.11786</link>
<description rdf:parseType="Literal">&lt;p&gt;Frozen sectioning (FS) is the preparation method of choice for microscopic
evaluation of tissues during surgical operations. The high speed of the
procedure allows pathologists to rapidly assess the key microscopic features,
such as tumour margins and malignant status to guide surgical decision-making
and minimise disruptions to the course of the operation. However, FS is prone
to introducing many misleading artificial structures (histological artefacts),
such as nuclear ice crystals, compression, and cutting artefacts, hindering
timely and accurate diagnostic judgement of the pathologist. Additional
training and prolonged experience is often required to make highly effective
and time-critical diagnosis on frozen sections. On the other hand, the gold
standard tissue preparation technique of formalin-fixation and
paraffin-embedding (FFPE) provides significantly superior image quality, but is
a very time-consuming process (12-48 hours), making it unsuitable for
intra-operative use. In this paper, we propose an artificial intelligence (AI)
method that improves FS image quality by computationally transforming
frozen-sectioned whole-slide images (FS-WSIs) into whole-slide FFPE-style
images in minutes. AI-FFPE rectifies FS artefacts with the guidance of an
attention mechanism that puts a particular emphasis on artefacts while
utilising a self-regularization mechanism established between FS input image
and synthesized FFPE-style image that preserves clinically relevant features.
As a result, AI-FFPE method successfully generates FFPE-style images without
significantly extending tissue processing time and consequently improves
diagnostic accuracy. We demonstrate the efficacy of AI-FFPE on lung and brain
frozen sections using a variety of different qualitative and quantitative
metrics including visual Turing tests from 20 board certified pathologists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ozyoruk_K/0/1/0/all/0/1&quot;&gt;Kutsev Bengisu Ozyoruk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Can_S/0/1/0/all/0/1&quot;&gt;Sermet Can&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gokceler_G/0/1/0/all/0/1&quot;&gt;Guliz Irem Gokceler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Basak_K/0/1/0/all/0/1&quot;&gt;Kayhan Basak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Demir_D/0/1/0/all/0/1&quot;&gt;Derya Demir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Serin_G/0/1/0/all/0/1&quot;&gt;Gurdeniz Serin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hacisalihoglu_U/0/1/0/all/0/1&quot;&gt;Uguray Payam Hacisalihoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kurtulus_E/0/1/0/all/0/1&quot;&gt;Emirhan Kurtulu&amp;#x15f;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Darbaz_B/0/1/0/all/0/1&quot;&gt;Berkan Darbaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_M/0/1/0/all/0/1&quot;&gt;Ming Y. Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tiffany Y. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Williamson_D/0/1/0/all/0/1&quot;&gt;Drew F. K. Williamson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yilmaz_F/0/1/0/all/0/1&quot;&gt;Funda Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mahmood_F/0/1/0/all/0/1&quot;&gt;Faisal Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Turan_M/0/1/0/all/0/1&quot;&gt;Mehmet Turan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.12922">
<title>Griffin: Rethinking Sparse Optimization for Deep Learning Architectures. (arXiv:2107.12922v3 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2107.12922</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper examines the design space trade-offs of DNNs accelerators aiming
to achieve competitive performance and efficiency metrics for all four
combinations of dense or sparse activation/weight tensors. To do so, we
systematically examine the overheads of supporting sparsity on top of an
optimized dense core. These overheads are modeled based on parameters that
indicate how a multiplier can borrow a nonzero operation from the neighboring
multipliers or future cycles. As a result of this exploration, we identify a
few promising designs that perform better than prior work. Our findings suggest
that even the best design targeting dual sparsity yields a 20%-30% drop in
power efficiency when performing on single sparse models, i.e., those with only
sparse weight or sparse activation tensors. We found that one can reuse
resources of the same core to maintain high performance and efficiency when
running single sparsity or dense models. We call this hybrid architecture
Griffin. Griffin is 1.2, 3.0, 3.1, and 1.4X more power-efficient than
state-of-the-art sparse architectures, for dense, weight-only sparse,
activation-only sparse, and dual sparse models, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jong Hoon Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafiee_A/0/1/0/all/0/1&quot;&gt;Ali Shafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedram_A/0/1/0/all/0/1&quot;&gt;Ardavan Pedram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdel_Aziz_H/0/1/0/all/0/1&quot;&gt;Hamzah Abdel-Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Ling Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassoun_J/0/1/0/all/0/1&quot;&gt;Joseph Hassoun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.13875">
<title>Spatio-temporal graph neural networks for multi-site PV power forecasting. (arXiv:2107.13875v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.13875</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate forecasting of solar power generation with fine temporal and spatial
resolution is vital for the operation of the power grid. However,
state-of-the-art approaches that combine machine learning with numerical
weather predictions (NWP) have coarse resolution. In this paper, we take a
graph signal processing perspective and model multi-site photovoltaic (PV)
production time series as signals on a graph to capture their spatio-temporal
dependencies and achieve higher spatial and temporal resolution forecasts. We
present two novel graph neural network models for deterministic multi-site PV
forecasting dubbed the graph-convolutional long short term memory (GCLSTM) and
the graph-convolutional transformer (GCTrafo) models. These methods rely solely
on production data and exploit the intuition that PV systems provide a dense
network of virtual weather stations. The proposed methods were evaluated in two
data sets for an entire year: 1) production data from 304 real PV systems, and
2) simulated production of 1000 PV systems, both distributed over Switzerland.
The proposed models outperform state-of-the-art multi-site forecasting methods
for prediction horizons of six hours ahead. Furthermore, the proposed models
outperform state-of-the-art single-site methods with NWP as inputs on horizons
up to four hours ahead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeunovic_J/0/1/0/all/0/1&quot;&gt;Jelena Simeunovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schubnel_B/0/1/0/all/0/1&quot;&gt;Baptiste Schubnel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alet_P/0/1/0/all/0/1&quot;&gt;Pierre-Jean Alet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carrillo_R/0/1/0/all/0/1&quot;&gt;Rafael E. Carrillo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.00238">
<title>Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction. (arXiv:2108.00238v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2108.00238</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding complex social interactions among agents is a key challenge for
trajectory prediction. Most existing methods consider the interactions between
pairwise traffic agents or in a local area, while the nature of interactions is
unlimited, involving an uncertain number of agents and non-local areas
simultaneously. Besides, they treat heterogeneous traffic agents the same,
namely those among agents of different categories, while neglecting people&apos;s
diverse reaction patterns toward traffic agents in ifferent categories. To
address these problems, we propose a simple yet effective Unlimited
Neighborhood Interaction Network (UNIN), which predicts trajectories of
heterogeneous agents in multiple categories. Specifically, the proposed
unlimited neighborhood interaction module generates the fused-features of all
agents involved in an interaction simultaneously, which is adaptive to any
number of agents and any range of interaction area. Meanwhile, a hierarchical
graph attention module is proposed to obtain category-to-category interaction
and agent-to-agent interaction. Finally, parameters of a Gaussian Mixture Model
are estimated for generating the future trajectories. Extensive experimental
results on benchmark datasets demonstrate a significant performance improvement
of our method over the state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1&quot;&gt;Fang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Le Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sanping Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1&quot;&gt;Wei Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1&quot;&gt;Zhenxing Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1&quot;&gt;Nanning Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1&quot;&gt;Gang Hua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.00376">
<title>The Aging Effect in Evolving Scientific Citation Networks. (arXiv:2108.00376v2 [physics.soc-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2108.00376</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of citation networks is of interest to the scientific community.
However, the underlying mechanism driving individual citation behavior remains
imperfectly understood, despite the recent proliferation of quantitative
research methods. Traditional network models normally use graph theory to
consider articles as nodes and citations as pairwise relationships between
them. In this paper, we propose an alternative evolutionary model based on
hypergraph theory in which one hyperedge can have an arbitrary number of nodes,
combined with an aging effect to reflect the temporal dynamics of scientific
citation behavior. Both theoretical approximate solution and simulation
analysis of the model are developed and validated using two benchmark datasets
from different disciplines, i.e. publications of the American Physical Society
(APS) and the Digital Bibliography &amp;amp; Library Project (DBLP). Further analysis
indicates that the attraction of early publications will decay exponentially.
Moreover, the experimental results show that the aging effect indeed has a
significant influence on the description of collective citation patterns.
Shedding light on the complex dynamics driving these mechanisms facilitates the
understanding of the laws governing scientific evolution and the quantitative
evaluation of scientific outputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hu_F/0/1/0/all/0/1&quot;&gt;Feng Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhan_X/0/1/0/all/0/1&quot;&gt;Xiu-Xiu Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yinzuo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chuang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haixing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zi-Ke Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.00559">
<title>A Machine-Learning-Based Direction-of-Origin Filter for the Identification of Radio Frequency Interference in the Search for Technosignatures. (arXiv:2108.00559v2 [astro-ph.IM] UPDATED)</title>
<link>http://arxiv.org/abs/2108.00559</link>
<description rdf:parseType="Literal">&lt;p&gt;Radio frequency interference (RFI) mitigation remains a major challenge in
the search for radio technosignatures. Typical mitigation strategies include a
direction-of-origin (DoO) filter, where a signal is classified as RFI if it is
detected in multiple directions on the sky. These classifications generally
rely on estimates of signal properties, such as frequency and frequency drift
rate. Convolutional neural networks (CNNs) offer a promising complement to
existing filters because they can be trained to analyze dynamic spectra
directly, instead of relying on inferred signal properties. In this work, we
compiled several data sets consisting of labeled pairs of images of dynamic
spectra, and we designed and trained a CNN that can determine whether or not a
signal detected in one scan is also present in another scan. This CNN-based DoO
filter outperforms both a baseline 2D correlation model as well as existing DoO
filters over a range of metrics, with precision and recall values of 99.15% and
97.81%, respectively. We found that the CNN reduces the number of signals
requiring visual inspection after the application of traditional DoO filters by
a factor of 6-16 in nominal situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pinchuk_P/0/1/0/all/0/1&quot;&gt;Pavlo Pinchuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Margot_J/0/1/0/all/0/1&quot;&gt;Jean-Luc Margot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.01192">
<title>Multi-objective Recurrent Neural Networks Optimization for the Edge -- a Quantization-based Approach. (arXiv:2108.01192v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2108.01192</link>
<description rdf:parseType="Literal">&lt;p&gt;The compression of deep learning models is of fundamental importance in
deploying such models to edge devices. Incorporating hardware model and
application constraints during compression maximizes the benefits but makes it
specifically designed for one case. Therefore, the compression needs to be
automated. Searching for the optimal compression method parameters is
considered an optimization problem. This article introduces a Multi-Objective
Hardware-Aware Quantization (MOHAQ) method, which considers both hardware
efficiency and inference error as objectives for mixed-precision quantization.
The proposed method makes the evaluation of candidate solutions in a large
search space feasible by relying on two steps. First, post-training
quantization is applied for fast solution evaluation. Second, we propose a
search technique named &quot;beacon-based search&quot; to retrain selected solutions only
in the search space and use them as beacons to know the effect of retraining on
other solutions. To evaluate the optimization potential, we chose a speech
recognition model using the TIMIT dataset. The model is based on Simple
Recurrent Unit (SRU) due to its considerable speedup over other recurrent
units. We applied our method to run on two platforms: SiLago and Bitfusion.
Experimental evaluations showed that SRU can be compressed up to 8x by
post-training quantization without any significant increase in the error and up
to 12x with only a 1.5 percentage point increase in error. On SiLago, the
inference-only search found solutions that achieve 80\% and 64\% of the maximum
possible speedup and energy saving, respectively, with a 0.5 percentage point
increase in the error. On Bitfusion, with a constraint of a small SRAM size,
beacon-based search reduced the error gain of inference-only search by 4
percentage points and increased the possible reached speedup to be 47x compared
to the Bitfusion baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezk_N/0/1/0/all/0/1&quot;&gt;Nesma M. Rezk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nordstrom_T/0/1/0/all/0/1&quot;&gt;Tomas Nordstr&amp;#xf6;m&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stathis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Stathis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ul_Abdin_Z/0/1/0/all/0/1&quot;&gt;Zain Ul-Abdin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aksoy_E/0/1/0/all/0/1&quot;&gt;Eren Erdal Aksoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemani_A/0/1/0/all/0/1&quot;&gt;Ahmed Hemani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.01598">
<title>Secure and Efficient Blockchain based Knowledge Sharing for Intelligent Connected Vehicles. (arXiv:2108.01598v5 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/2108.01598</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of Intelligent Connected Vehicles (ICVs) shows great potential
for future intelligent traffic systems, enhancing both traffic safety and road
efficiency. However, the ICVs relying on data driven perception and driving
models face many challenges, including the lack of comprehensive knowledge to
deal with complicated driving context. In this paper, we are motivated to
investigate cooperative knowledge sharing for ICVs. We propose a secure and
efficient directed acyclic graph (DAG) blockchain based knowledge sharing
framework, aiming to cater for the micro-transaction based vehicular networks.
The framework can realize both local and cross-regional knowledge sharing.
Then, the framework is applied to autonomous driving applications, wherein
machine learning based models for autonomous driving control can be shared. A
lightweight tip selection algorithm (TSA) is proposed for the DAG based
knowledge sharing framework to achieve consensus and identity verification for
cross-regional vehicles. To enhance model accuracy as well as minimizing
bandwidth consumption, an adaptive asynchronous distributed learning (ADL)
based scheme is proposed for model uploading and downloading. Experiment
results show that the blockchain based knowledge sharing is secure, and it can
resist attacks from malicious users. In addition, the proposed adaptive ADL
scheme can enhance driving safety related performance compared to several
existing algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_H/0/1/0/all/0/1&quot;&gt;Haoye Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1&quot;&gt;Supeng Leng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jianhua He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.02430">
<title>Deep Neural Networks and PIDE discretizations. (arXiv:2108.02430v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2108.02430</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose neural networks that tackle the problems of
stability and field-of-view of a Convolutional Neural Network (CNN). As an
alternative to increasing the network&apos;s depth or width to improve performance,
we propose integral-based spatially nonlocal operators which are related to
global weighted Laplacian, fractional Laplacian and inverse fractional
Laplacian operators that arise in several problems in the physical sciences.
The forward propagation of such networks is inspired by partial
integro-differential equations (PIDEs). We test the effectiveness of the
proposed neural architectures on benchmark image classification datasets and
semantic segmentation tasks in autonomous driving. Moreover, we investigate the
extra computational costs of these dense operators and the stability of forward
propagation of the proposed neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohn_B/0/1/0/all/0/1&quot;&gt;Bastian Bohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griebel_M/0/1/0/all/0/1&quot;&gt;Michael Griebel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_D/0/1/0/all/0/1&quot;&gt;Dinesh Kannan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.02842">
<title>Multimodal Meta-Learning for Time Series Regression. (arXiv:2108.02842v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2108.02842</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown the efficiency of deep learning models such as Fully
Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with
Time Series Regression (TSR) problems. These models sometimes need a lot of
data to be able to generalize, yet the time series are sometimes not long
enough to be able to learn patterns. Therefore, it is important to make use of
information across time series to improve learning. In this paper, we will
explore the idea of using meta-learning for quickly adapting model parameters
to new short-history time series by modifying the original idea of Model
Agnostic Meta-Learning (MAML) \cite{finn2017model}. Moreover, based on prior
work on multimodal MAML \cite{vuorio2019multimodal}, we propose a method for
conditioning parameters of the model through an auxiliary network that encodes
global information of the time series to extract meta-features. Finally, we
apply the data to time series of different domains, such as pollution
measurements, heart-rate sensors, and electrical battery data. We show
empirically that our proposed meta-learning method learns TSR with few data
fast and outperforms the baselines in 9 of 12 experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1&quot;&gt;Sebastian Pineda Arango&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinrich_F/0/1/0/all/0/1&quot;&gt;Felix Heinrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhusudhanan_K/0/1/0/all/0/1&quot;&gt;Kiran Madhusudhanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1&quot;&gt;Lars Schmidt-Thieme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.03272">
<title>iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. (arXiv:2108.03272v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2108.03272</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
&lt;a href=&quot;http://svl.stanford.edu/igibson/.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengshu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Fei Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1&quot;&gt;Roberto Mart&amp;#xed;n-Mart&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1&quot;&gt;Michael Lingelbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Sanjana Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1&quot;&gt;Bokui Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1&quot;&gt;Kent Vainio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1&quot;&gt;Cem Gokmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dharan_G/0/1/0/all/0/1&quot;&gt;Gokul Dharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1&quot;&gt;Tanish Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1&quot;&gt;Andrey Kurenkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;C. Karen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1&quot;&gt;Hyowon Gweon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.03458">
<title>Scientific X-ray. (arXiv:2108.03458v4 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2108.03458</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of modern science and technology has spawned rich
scientific topics to research and endless production of literature in them.
Just like X-ray imaging in medicine, can we intuitively identify the
development limit and internal evolution pattern of scientific topic from the
relationship of massive knowledge? To answer this question, we collect 71431
seminal articles of topics that cover 16 disciplines and their citation data,
and extracts the &quot;idea tree&quot; of each topic to restore the structure of the
development of 71431 topic networks from scratch. We define the Knowledge
Entropy (KE) metric, and the contribution of high knowledge entropy nodes to
increase the depth of the idea tree is regarded as the basis for topic
development. By observing &quot;X-ray images&quot; of topics, We find two interesting
phenomena: (1) Even though the scale of topics may increase unlimitedly, there
is an insurmountable cap of topic development: the depth of the idea tree does
not exceed 6 jumps, which coincides with the classical &quot;Six Degrees of
Separation&quot;! (2) It is difficult for a single article to contribute more than 3
jumps to the depth of its topic, to this end, the continuing increase in the
depth of the idea tree needs to be motivated by the influence relay of multiple
high knowledge entropy nodes. Through substantial statistical fits, we derive a
unified quantitative relationship between the change in topic depth ${\Delta
D}^t(v)$ and the change in knowledge entropy over time ${KE}^t\left(v\right)$
of the article $v$ driving the increase in depth in the topic: ${\Delta D}^t(v)
\approx \log \frac{KE^{t}(v)}{\left(t-t_{0}\right)^{1.8803}}$ , which can
effectively portray evolution patterns of topics and predict their development
potential. The various phenomena found by scientific x-ray may provide a new
paradigm for explaining and understanding the evolution of science and
technology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinbing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_L/0/1/0/all/0/1&quot;&gt;Luoyi Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chenghu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.07931">
<title>Learning Federated Representations and Recommendations with Limited Negatives. (arXiv:2108.07931v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2108.07931</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep retrieval models are widely used for learning entity representations and
recommendations. Federated learning provides a privacy-preserving way to train
these models without requiring centralization of user data. However, federated
deep retrieval models usually perform much worse than their centralized
counterparts due to non-IID (independent and identically distributed) training
data on clients, an intrinsic property of federated learning that limits
negatives available for training. We demonstrate that this issue is distinct
from the commonly studied client drift problem. This work proposes
batch-insensitive losses as a way to alleviate the non-IID negatives issue for
federated movie recommendations. We explore a variety of techniques and
identify that batch-insensitive losses can effectively improve the performance
of federated deep retrieval models, increasing the relative recall of the
federated model by up to 93.15% and reducing the relative gap in recall between
it and a centralized model from 27.22% - 43.14% to 0.53% - 2.42%. We also
open-source our code framework to accelerate further research and applications
of federated deep retrieval models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_L/0/1/0/all/0/1&quot;&gt;Lin Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1&quot;&gt;Karan Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1&quot;&gt;Ellie X. Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1&quot;&gt;Sushant Prakash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.07945">
<title>A Tighter Relation Between Hereditary Discrepancy and Determinant Lower Bound. (arXiv:2108.07945v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2108.07945</link>
<description rdf:parseType="Literal">&lt;p&gt;In seminal work, Lov\&apos;asz, Spencer, and Vesztergombi [European J. Combin.,
1986] proved a lower bound for the hereditary discrepancy of a matrix $A \in
\mathbb{R}^{m \times n}$ in terms of the maximum $|\det(B)|^{1/k}$ over all $k
\times k$ submatrices $B$ of $A$. We show algorithmically that this determinant
lower bound can be off by at most a factor of $O(\sqrt{\log (m) \cdot \log
(n)})$, improving over the previous bound of $O(\log(mn) \cdot \sqrt{\log
(n)})$ given by Matou\v{s}ek [Proc. of the AMS, 2013]. Our result immediately
implies $\mathrm{herdisc}(\mathcal{F}_1 \cup \mathcal{F}_2) \leq O(\sqrt{\log
(m) \cdot \log (n)}) \cdot \max(\mathrm{herdisc}(\mathcal{F}_1),
\mathrm{herdisc}(\mathcal{F}_2))$, for any two set systems $\mathcal{F}_1,
\mathcal{F}_2$ over $[n]$ satisfying $|\mathcal{F}_1 \cup \mathcal{F}_2| = m$.
Our bounds are tight up to constants when $m = O(\mathrm{poly}(n))$ due to a
construction of P\&apos;alv\&quot;olgyi [Discrete Comput. Geom., 2010] or the
counterexample to Beck&apos;s three permutation conjecture by Newman, Neiman and
Nikolov [FOCS, 2012].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haotian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reis_V/0/1/0/all/0/1&quot;&gt;Victor Reis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.08282">
<title>OACAL: Finding Module-consistent Specifications to Secure Systems from Weakened User Obligations. (arXiv:2108.08282v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2108.08282</link>
<description rdf:parseType="Literal">&lt;p&gt;Users interacting with a system through UI are typically obliged to perform
their actions in a pre-determined order, to successfully achieve certain
functional goals. However, such obligations are often not followed strictly by
users, which may lead to the violation to security properties, especially in
security-critical systems. To improve the security with the awareness of
unexpected user behaviors, a system can be redesigned to a more robust one by
changing the order of actions in its specification. Meanwhile, we anticipate
that the functionalities would remain consistent following the modifications.
In this paper, we propose an efficient algorithm to automatically produce
specification revisions tackling the attack scenarios caused by weakened user
obligations. By our algorithm, all the revisions would be generated to maintain
the integrity of the functionalities using a novel recomposition approach.
Then, the eligible revisions that can satisfy the security requirements would
be efficiently spotted by a hybrid approach combining model checking and
machine learning techniques. We evaluate our algorithm by comparing its
performance with a state-of-the-art approach regarding their coverage and
searching speed of the desirable revisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1&quot;&gt;Pengcheng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tei_K/0/1/0/all/0/1&quot;&gt;Kenji Tei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.10629">
<title>Improving Generalization of Batch Whitening by Convolutional Unit Optimization. (arXiv:2108.10629v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2108.10629</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch Whitening is a technique that accelerates and stabilizes training by
transforming input features to have a zero mean (Centering) and a unit variance
(Scaling), and by removing linear correlation between channels (Decorrelation).
In commonly used structures, which are empirically optimized with Batch
Normalization, the normalization layer appears between convolution and
activation function. Following Batch Whitening studies have employed the same
structure without further analysis; even Batch Whitening was analyzed on the
premise that the input of a linear layer is whitened. To bridge the gap, we
propose a new Convolutional Unit that is in line with the theory, and our
method generally improves the performance of Batch Whitening. Moreover, we show
the inefficacy of the original Convolutional Unit by investigating rank and
correlation of features. As our method is employable off-the-shelf whitening
modules, we use Iterative Normalization (IterNorm), the state-of-the-art
whitening module, and obtain significantly improved performance on five image
classification datasets: CIFAR-10, CIFAR-100, CUB-200-2011, Stanford Dogs, and
ImageNet. Notably, we verify that our method improves stability and performance
of whitening when using large learning rate, group size, and iteration number.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1&quot;&gt;Yooshin Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1&quot;&gt;Hanbyel Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Youngsoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junmo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.11224">
<title>Multi-domain semantic segmentation with overlapping labels. (arXiv:2108.11224v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2108.11224</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep supervised models have an unprecedented capacity to absorb large
quantities of training data. Hence, training on many datasets becomes a method
of choice towards graceful degradation in unusual scenes. Unfortunately,
different datasets often use incompatible labels. For instance, the Cityscapes
road class subsumes all driving surfaces, while Vistas defines separate classes
for road markings, manholes etc. We address this challenge by proposing a
principled method for seamless learning on datasets with overlapping classes
based on partial labels and probabilistic loss. Our method achieves competitive
within-dataset and cross-dataset generalization, as well as ability to learn
visual concepts which are not separately labeled in any of the training
datasets. Experiments reveal competitive or state-of-the-art performance on two
multi-domain dataset collections and on the WildDash 2 benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bevandic_P/0/1/0/all/0/1&quot;&gt;Petra Bevandi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orsic_M/0/1/0/all/0/1&quot;&gt;Marin Or&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1&quot;&gt;Ivan Grubi&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saric_J/0/1/0/all/0/1&quot;&gt;Josip &amp;#x160;ari&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1&quot;&gt;Sini&amp;#x161;a &amp;#x160;egvi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.12188">
<title>A High-Fidelity Flow Solver for Unstructured Meshes on Field-Programmable Gate Arrays. (arXiv:2108.12188v3 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2108.12188</link>
<description rdf:parseType="Literal">&lt;p&gt;The impending termination of Moore&apos;s law motivates the search for new forms
of computing to continue the performance scaling we have grown accustomed to.
Among the many emerging Post-Moore computing candidates, perhaps none is as
salient as the Field-Programmable Gate Array (FPGA), which offers the means of
specializing and customizing the hardware to the computation at hand.
&lt;/p&gt;
&lt;p&gt;In this work, we design a custom FPGA-based accelerator for a computational
fluid dynamics (CFD) code. Unlike prior work -- which often focuses on
accelerating small kernels -- we target the entire Poisson solver on
unstructured meshes based on the high-fidelity spectral element method (SEM)
used in modern state-of-the-art CFD systems. We model our accelerator using an
analytical performance model based on the I/O cost of the algorithm. We
empirically evaluate our accelerator on a state-of-the-art Intel Stratix 10
FPGA in terms of performance and power consumption and contrast it against
existing solutions on general-purpose processors (CPUs). Finally, we propose a
data movement-reducing technique where we compute geometric factors on the fly,
which yields significant (700+ Gflop/s) single-precision performance and an
upwards of 2x reduction in runtime for the local evaluation of the Laplace
operator.
&lt;/p&gt;
&lt;p&gt;We end the paper by discussing the challenges and opportunities of using
reconfigurable architecture in the future, particularly in the light of
emerging (not yet available) technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karp_M/0/1/0/all/0/1&quot;&gt;Martin Karp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Podobas_A/0/1/0/all/0/1&quot;&gt;Artur Podobas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenter_T/0/1/0/all/0/1&quot;&gt;Tobias Kenter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jansson_N/0/1/0/all/0/1&quot;&gt;Niclas Jansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plessl_C/0/1/0/all/0/1&quot;&gt;Christian Plessl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlatter_P/0/1/0/all/0/1&quot;&gt;Philipp Schlatter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markidis_S/0/1/0/all/0/1&quot;&gt;Stefano Markidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.12486">
<title>Renting Servers in the Cloud: The Case of Equal Duration Jobs. (arXiv:2108.12486v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2108.12486</link>
<description rdf:parseType="Literal">&lt;p&gt;Renting servers in the cloud is a generalization of the bin packing problem,
motivated by job allocation to servers in cloud computing applications. Jobs
arrive in an online manner, and need to be assigned to servers; their duration
and size are known at the time of arrival. There is an infinite supply of
identical servers, each having one unit of computational capacity per unit of
time. A server can be rented at any time and continues to be rented until all
jobs assigned to it finish. The cost of an assignment is the sum of durations
of rental periods of all servers. The goal is to assign jobs to servers to
minimize the overall cost while satisfying server capacity constraints. We
focus on analyzing two natural algorithms, NextFit and FirstFit, for the case
of jobs of equal duration. It is known that the competitive ratio of NextFit
and FirstFit are at most 3 and 4 respectively for this case. We prove a tight
bound of 2 on the competitive ratio of NextFit. For FirstFit, we establish a
lower bound of 2.519 on the competitive ratio, even when jobs have only two
distinct arrival times. For the case when jobs have arrival times 0 and 1 and
duration 2, we show a lower bound of 1.89 and an upper bound of 2 on the strict
competitive ratio of FirstFit. Finally, using the weight function technique, we
obtain stronger results for the case of uniform servers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masoori_M/0/1/0/all/0/1&quot;&gt;Mahtab Masoori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanan_L/0/1/0/all/0/1&quot;&gt;Lata Narayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pankratov_D/0/1/0/all/0/1&quot;&gt;Denis Pankratov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.01135">
<title>Sequence-to-Sequence Learning with Latent Neural Grammars. (arXiv:2109.01135v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2109.01135</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.03100">
<title>Optimal Stroke Learning with Policy Gradient Approach for Robotic Table Tennis. (arXiv:2109.03100v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2109.03100</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to play table tennis is a challenging task for robots, as a wide
variety of strokes required. Recent advances have shown that deep Reinforcement
Learning (RL) is able to successfully learn the optimal actions in a simulated
environment. However, the applicability of RL in real scenarios remains limited
due to the high exploration effort. In this work, we propose a realistic
simulation environment in which multiple models are built for the dynamics of
the ball and the kinematics of the robot. Instead of training an end-to-end RL
model, a novel policy gradient approach with TD3 backbone is proposed to learn
the racket strokes based on the predicted state of the ball at the hitting
time. In the experiments, we show that the proposed approach significantly
outperforms the existing RL methods in simulation. Furthermore, to cross the
domain from simulation to reality, we adopt an efficient retraining method and
test it in three real scenarios. The resulting success rate is 98% and the
distance error is around 24.9 cm. The total training time is about 1.5 hours.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yapeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tebbe_J/0/1/0/all/0/1&quot;&gt;Jonas Tebbe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1&quot;&gt;Andreas Zell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.05112">
<title>Improved Latent Tree Induction with Distant Supervision via Span Constraints. (arXiv:2109.05112v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2109.05112</link>
<description rdf:parseType="Literal">&lt;p&gt;For over thirty years, researchers have developed and analyzed methods for
latent tree induction as an approach for unsupervised syntactic parsing.
Nonetheless, modern systems still do not perform well enough compared to their
supervised counterparts to have any practical use as structural annotation of
text. In this work, we present a technique that uses distant supervision in the
form of span constraints (i.e. phrase bracketing) to improve performance in
unsupervised constituency parsing. Using a relatively small number of span
constraints we can substantially improve the output from DIORA, an already
competitive unsupervised parsing system. Compared with full parse tree
annotation, span constraints can be acquired with minimal effort, such as with
a lexicon derived from Wikipedia, to find exact text matches. Our experiments
show span constraints based on entities improves constituency parsing on
English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to
any domain where span constraints are easily attainable, and as a case study we
demonstrate its effectiveness by parsing biomedical text from the CRAFT
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drozdov_A/0/1/0/all/0/1&quot;&gt;Andrew Drozdov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jay Yoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OGorman_T/0/1/0/all/0/1&quot;&gt;Tim O&amp;#x27;Gorman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rongali_S/0/1/0/all/0/1&quot;&gt;Subendhu Rongali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finkbeiner_D/0/1/0/all/0/1&quot;&gt;Dylan Finkbeiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1&quot;&gt;Shilpa Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1&quot;&gt;Mohit Iyyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1&quot;&gt;Andrew McCallum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.05466">
<title>Graph Attention Network Based Single-Pixel Compressive Direction of Arrival Estimation. (arXiv:2109.05466v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2109.05466</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a single-pixel compressive direction of arrival
(DoA) estimation technique leveraging a graph attention network (GAT)-based
deep-learning framework. The physical layer compression is achieved using a
coded-aperture technique, probing the spectrum of far-field sources that are
incident on the aperture using a set of spatio-temporally incoherent modes.
This information is then encoded and compressed into the channel of the
coded-aperture. The coded-aperture is based on a metasurface antenna design and
it works as a receiver, exhibiting a single-channel and replacing the
conventional multichannel raster scan-based solutions for DoA estimation. The
GAT network enables the compressive DoA estimation framework to learn the DoA
information directly from the measurements acquired using the coded-aperture.
This step eliminates the need for an additional reconstruction step and
significantly simplifies the processing layer to achieve DoA estimation. We
show that the presented GAT integrated single-pixel radar framework can
retrieve high fidelity DoA information even under relatively low
signal-to-noise ratio (SNR) levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tekbiyik_K/0/1/0/all/0/1&quot;&gt;K&amp;#xfc;r&amp;#x15f;at Tekb&amp;#x131;y&amp;#x131;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yurduseven_O/0/1/0/all/0/1&quot;&gt;Okan Yurduseven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kurt_G/0/1/0/all/0/1&quot;&gt;G&amp;#xfc;ne&amp;#x15f; Karabulut Kurt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.06610">
<title>Statistical limits of dictionary learning: random matrix theory and the spectral replica method. (arXiv:2109.06610v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/2109.06610</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider increasingly complex models of matrix denoising and dictionary
learning in the Bayes-optimal setting, in the challenging regime where the
matrices to infer have a rank growing linearly with the system size. This is in
contrast with most existing literature concerned with the low-rank (i.e.,
constant-rank) regime. We first consider a class of rotationally invariant
matrix denoising problems whose mutual information and minimum mean-square
error are computable using standard techniques from random matrix theory. Next,
we analyze the more challenging models of dictionary learning. To do so we
introduce a novel combination of the replica method from statistical mechanics
together with random matrix theory, coined spectral replica method. It allows
us to conjecture variational formulas for the mutual information between hidden
representations and the noisy data of the dictionary learning problem, as well
as for the overlaps quantifying the optimal reconstruction error. The proposed
methods reduce the number of degrees of freedom from $\Theta(N^2)$ (matrix
entries) to $\Theta(N)$ (eigenvalues or singular values), and yield Coulomb gas
representations of the mutual information which are reminiscent of matrix
models in physics. The main ingredients are the use of
HarishChandra-Itzykson-Zuber spherical integrals combined with a new replica
symmetric decoupling ansatz at the level of the probability distributions of
eigenvalues (or singular values) of certain overlap matrices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbier_J/0/1/0/all/0/1&quot;&gt;Jean Barbier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macris_N/0/1/0/all/0/1&quot;&gt;Nicolas Macris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.07103">
<title>Automatic Symmetry Discovery with Lie Algebra Convolutional Network. (arXiv:2109.07103v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.07103</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing equivariant neural networks require prior knowledge of the symmetry
group and discretization for continuous groups. We propose to work with Lie
algebras (infinitesimal generators) instead of Lie groups. Our model, the Lie
algebra convolutional network (L-conv) can automatically discover symmetries
and does not require discretization of the group. We show that L-conv can serve
as a building block to construct any group equivariant feedforward
architecture. Both CNNs and Graph Convolutional Networks can be expressed as
L-conv with appropriate groups. We discover direct connections between L-conv
and physics: (1) group invariant loss generalizes field theory (2)
Euler-Lagrange equation measures the robustness, and (3) equivariance leads to
conservation laws and Noether current.These connections open up new avenues for
designing more general equivariant networks and applying them to important
problems in physical sciences
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehmamy_N/0/1/0/all/0/1&quot;&gt;Nima Dehmamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1&quot;&gt;Robin Walters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yanchen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dashun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Rose Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.07950">
<title>Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection. (arXiv:2109.07950v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2109.07950</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increased deployment of face recognition systems in our daily lives,
face presentation attack detection (PAD) is attracting much attention and
playing a key role in securing face recognition systems. Despite the great
performance achieved by the hand-crafted and deep-learning-based methods in
intra-dataset evaluations, the performance drops when dealing with unseen
scenarios. In this work, we propose a dual-stream convolution neural networks
(CNNs) framework. One stream adapts four learnable frequency filters to learn
features in the frequency domain, which are less influenced by variations in
sensors/illuminations. The other stream leverages the RGB images to complement
the features of the frequency domain. Moreover, we propose a hierarchical
attention module integration to join the information from the two streams at
different stages by considering the nature of deep features in different layers
of the CNN. The proposed method is evaluated in the intra-dataset and
cross-dataset setups, and the results demonstrate that our proposed approach
enhances the generalizability in most experimental setups in comparison to
state-of-the-art, including the methods designed explicitly for domain
adaption/shift problems. We successfully prove the design of our proposed PAD
solution in a step-wise ablation study that involves our proposed learnable
frequency decomposition, our hierarchical attention module design, and the used
loss function. Training codes and pre-trained models are publicly released
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1&quot;&gt;Meiling Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1&quot;&gt;Naser Damer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1&quot;&gt;Florian Kirchbuchner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1&quot;&gt;Arjan Kuijper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.08113">
<title>MeLT: Message-Level Transformer with Masked Document Representations as Pre-Training for Stance Detection. (arXiv:2109.08113v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2109.08113</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of natural language processing is focused on leveraging large capacity
language models, typically trained over single messages with a task of
predicting one or more tokens. However, modeling human language at
higher-levels of context (i.e., sequences of messages) is under-explored. In
stance detection and other social media tasks where the goal is to predict an
attribute of a message, we have contextual data that is loosely semantically
connected by authorship. Here, we introduce Message-Level Transformer (MeLT) --
a hierarchical message-encoder pre-trained over Twitter and applied to the task
of stance prediction. We focus on stance prediction as a task benefiting from
knowing the context of the message (i.e., the sequence of previous messages).
The model is trained using a variant of masked-language modeling; where instead
of predicting tokens, it seeks to generate an entire masked (aggregated)
message vector via reconstruction loss. We find that applying this pre-trained
masked message-level transformer to the downstream task of stance detection
achieves F1 performance of 67%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matero_M/0/1/0/all/0/1&quot;&gt;Matthew Matero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soni_N/0/1/0/all/0/1&quot;&gt;Nikita Soni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1&quot;&gt;Niranjan Balasubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1&quot;&gt;H. Andrew Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.09010">
<title>Augmenting semantic lexicons using word embeddings and transfer learning. (arXiv:2109.09010v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2109.09010</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentiment-aware intelligent systems are essential to a wide array of
applications. These systems are driven by language models which broadly fall
into two paradigms: Lexicon-based and contextual. Although recent contextual
models are increasingly dominant, we still see demand for lexicon-based models
because of their interpretability and ease of use. For example, lexicon-based
models allow researchers to readily determine which words and phrases
contribute most to a change in measured sentiment. A challenge for any
lexicon-based approach is that the lexicon needs to be routinely expanded with
new words and expressions. Here, we propose two models for automatic lexicon
expansion. Our first model establishes a baseline employing a simple and
shallow neural network initialized with pre-trained word embeddings using a
non-contextual approach. Our second model improves upon our baseline, featuring
a deep Transformer-based network that brings to bear word definitions to
estimate their lexical polarity. Our evaluation shows that both models are able
to score new words with a similar accuracy to reviewers from Amazon Mechanical
Turk, but at a fraction of the cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alshaabi_T/0/1/0/all/0/1&quot;&gt;Thayer Alshaabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oort_C/0/1/0/all/0/1&quot;&gt;Colin M. Van Oort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fudolig_M/0/1/0/all/0/1&quot;&gt;Mikaela Irene Fudolig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1&quot;&gt;Michael V. Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danforth_C/0/1/0/all/0/1&quot;&gt;Christopher M. Danforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodds_P/0/1/0/all/0/1&quot;&gt;Peter Sheridan Dodds&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.09390">
<title>Socially Supervised Representation Learning: the Role of Subjectivity in Learning Efficient Representations. (arXiv:2109.09390v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2109.09390</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite its rise as a prominent solution to the data inefficiency of today&apos;s
machine learning models, self-supervised learning has yet to be studied from a
purely multi-agent perspective. In this work, we propose that aligning internal
subjective representations, which naturally arise in a multi-agent setup where
agents receive partial observations of the same underlying environmental state,
can lead to more data-efficient representations. We propose that multi-agent
environments, where agents do not have access to the observations of others but
can communicate within a limited range, guarantees a common context that can be
leveraged in individual representation learning. The reason is that subjective
observations necessarily refer to the same subset of the underlying
environmental states and that communication about these states can freely offer
a supervised signal. To highlight the importance of communication, we refer to
our setting as \textit{socially supervised representation learning}. We present
a minimal architecture comprised of a population of autoencoders, where we
define loss functions, capturing different aspects of effective communication,
and examine their effect on the learned representations. We show that our
proposed architecture allows the emergence of aligned representations. The
subjectivity introduced by presenting agents with distinct perspectives of the
environment state contributes to learning abstract representations that
outperform those learned by a single autoencoder and a population of
autoencoders, presented with identical perspectives of the environment state.
Altogether, our results demonstrate how communication from subjective
perspectives can lead to the acquisition of more abstract representations in
multi-agent systems, opening promising perspectives for future research at the
intersection of representation learning and emergent communication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_J/0/1/0/all/0/1&quot;&gt;Julius Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nisioti_E/0/1/0/all/0/1&quot;&gt;Eleni Nisioti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Moulin-Frier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.10187">
<title>Oriented Object Detection in Aerial Images Based on Area Ratio of Parallelogram. (arXiv:2109.10187v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2109.10187</link>
<description rdf:parseType="Literal">&lt;p&gt;Oriented object detection is a challenging task in aerial images since the
objects in aerial images are displayed in arbitrary directions and are
frequently densely packed. The mainstream detectors describe rotating objects
using a five-parament or eight-parament representations, which suffer from
representation ambiguity for orientated object definition. In this paper, we
propose a novel representation method based on area ratio of parallelogram,
called ARP. Specifically, ARP regresses the minimum bounding rectangle of the
oriented object and three area ratios. Three area ratios include the area ratio
of a directed object to the smallest circumscribed rectangle and two
parallelograms to the minimum circumscribed rectangle. It simplifies offset
learning and eliminates the issue of angular periodicity or label point
sequences for oriented objects. To further remedy the confusion issue of nearly
horizontal objects, the area ratio between the object and its minimal
circumscribed rectangle is employed to guide the selection of horizontal or
oriented detection for each object. Moreover, the rotated efficient
Intersection over Union (R-EIoU) loss with horizontal bounding box and three
area ratios are designed to optimize the bounding box regression for rotating
objects. Experimental results on remote sensing datasets, including HRSC2016,
DOTA, and UCAS-AOD, show that our method achieves superior detection
performance than many state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xinyi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1&quot;&gt;Mi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiangping Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_L/0/1/0/all/0/1&quot;&gt;Linlin Ou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.11808">
<title>A dynamic programming algorithm for informative measurements and near-optimal path-planning. (arXiv:2109.11808v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.11808</link>
<description rdf:parseType="Literal">&lt;p&gt;An informative measurement is the most efficient way to gain information
about an unknown state. We give a first-principles derivation of a
general-purpose dynamic programming algorithm that returns a sequence of
informative measurements by sequentially maximizing the entropy of possible
measurement outcomes. This algorithm can be used by an autonomous agent or
robot to decide where best to measure next, planning a path corresponding to an
optimal sequence of informative measurements. This algorithm is applicable to
states and controls that are continuous or discrete, and agent dynamics that is
either stochastic or deterministic; including Markov decision processes. Recent
results from approximate dynamic programming and reinforcement learning,
including on-line approximations such as rollout and Monte Carlo tree search,
allow an agent or robot to solve the measurement task in real-time. The
resulting near-optimal solutions include non-myopic paths and measurement
sequences that can generally outperform, sometimes substantially, commonly-used
greedy heuristics such as maximizing the entropy of each measurement outcome.
This is demonstrated for a global search problem, where on-line planning with
an extended local search is found to reduce the number of measurements in the
search by half.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loxley_P/0/1/0/all/0/1&quot;&gt;Peter N. Loxley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_K/0/1/0/all/0/1&quot;&gt;Ka Wai Cheung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.11999">
<title>Mining Shape Expressions with ShapeIt. (arXiv:2109.11999v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2109.11999</link>
<description rdf:parseType="Literal">&lt;p&gt;We present ShapeIt, a tool for mining specifications of cyber-physical
systems (CPS) from their real-valued behaviors. The learned specifications are
in the form of linear shape expressions, a declarative formal specification
language suitable to express behavioral properties over real-valued signals. A
linear shape expression is a regular expression composed of parameterized lines
as atomic symbols with symbolic constraints on the line parameters. We present
here the architecture of our tool along with the different steps of the
specification mining algorithm. We also describe the usage of the tool
demonstrating its applicability on several case studies from different
application domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartocci_E/0/1/0/all/0/1&quot;&gt;Ezio Bartocci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1&quot;&gt;Jyotirmoy Deshmukh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mateis_C/0/1/0/all/0/1&quot;&gt;Cristinel Mateis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nesterini_E/0/1/0/all/0/1&quot;&gt;Eleonora Nesterini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nickovic_D/0/1/0/all/0/1&quot;&gt;Dejan Nickovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1&quot;&gt;Xin Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.00318">
<title>MATE: Multi-Attribute Table Extraction. (arXiv:2110.00318v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/2110.00318</link>
<description rdf:parseType="Literal">&lt;p&gt;A core operation in data discovery is to find joinable tables for a given
table. Real-world tables include both unary and n-ary join keys. However,
existing table discovery systems are optimized for unary joins. These systems
are ineffective and slow in the existence of n-ary keys due to a large number
of false positives. In this paper, we introduce MATE, a table discovery system
that leverages a novel hash-based index that enables n-ary join discovery
through a space-efficient super key. We design a filtering layer that uses a
novel hash, XASH. This hash function encodes the syntactic features of all
column values and aggregates them into a super key, which allows the system to
efficiently prune tables with non-joinable rows. Our join discovery system
leads to up to 6300x fewer false positives and 370x faster table discovery in
comparison to state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmailoghli_M/0/1/0/all/0/1&quot;&gt;Mahdi Esmailoghli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quiane_Ruiz_J/0/1/0/all/0/1&quot;&gt;Jorge-Arnulfo Quian&amp;#xe9;-Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abedjan_Z/0/1/0/all/0/1&quot;&gt;Ziawasch Abedjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.00841">
<title>Transfer Learning Approaches for Knowledge Discovery in Grid-based Geo-Spatiotemporal Data. (arXiv:2110.00841v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.00841</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting and meticulously analyzing geo-spatiotemporal features is crucial
to recognize intricate underlying causes of natural events, such as floods.
Limited evidence about hidden factors leading to climate change makes it
challenging to predict regional water discharge accurately. In addition, the
explosive growth in complex geo-spatiotemporal environment data that requires
repeated learning by the state-of-the-art neural networks for every new region
emphasizes the need for new computationally efficient methods, advanced
computational resources, and extensive training on a massive amount of
available monitored data. We, therefore, propose HydroDeep, an effectively
reusable pretrained model to address this problem of transferring knowledge
from one region to another by effectively capturing their intrinsic
geo-spatiotemporal variance. Further, we present four transfer learning
approaches on HydroDeep for spatiotemporal interpretability that improve
Nash-Sutcliffe efficiency by 9% to 108% in new regions with a 95% reduction in
time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1&quot;&gt;Aishwarya Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jien Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chaoqun Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1&quot;&gt;Ali Jannesari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.01445">
<title>Robust and Decomposable Average Precision for Image Retrieval. (arXiv:2110.01445v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.01445</link>
<description rdf:parseType="Literal">&lt;p&gt;In image retrieval, standard evaluation metrics rely on score ranking, e.g.
average precision (AP). In this paper, we introduce a method for robust and
decomposable average precision (ROADMAP) addressing two major challenges for
end-to-end training of deep neural networks with AP: non-differentiability and
non-decomposability. Firstly, we propose a new differentiable approximation of
the rank function, which provides an upper bound of the AP loss and ensures
robust training. Secondly, we design a simple yet effective loss function to
reduce the decomposability gap between the AP in the whole training set and its
averaged batch approximation, for which we provide theoretical guarantees.
Extensive experiments conducted on three image retrieval datasets show that
ROADMAP outperforms several recent AP approximation methods and highlight the
importance of our two contributions. Finally, using ROADMAP for training deep
models yields very good performances, outperforming state-of-the-art results on
the three datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramzi_E/0/1/0/all/0/1&quot;&gt;Elias Ramzi&lt;/a&gt; (CNAM, CEDRIC - VERTIGO), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thome_N/0/1/0/all/0/1&quot;&gt;Nicolas Thome&lt;/a&gt; (CNAM, CEDRIC - VERTIGO), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rambour_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Rambour&lt;/a&gt; (CNAM, CEDRIC - VERTIGO), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Audebert_N/0/1/0/all/0/1&quot;&gt;Nicolas Audebert&lt;/a&gt; (CNAM, CEDRIC - VERTIGO), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bitot_X/0/1/0/all/0/1&quot;&gt;Xavier Bitot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.01705">
<title>Let there be a clock on the beach: Reducing Object Hallucination in Image Captioning. (arXiv:2110.01705v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.01705</link>
<description rdf:parseType="Literal">&lt;p&gt;Explaining an image with missing or non-existent objects is known as object
bias (hallucination) in image captioning. This behaviour is quite common in the
state-of-the-art captioning models which is not desirable by humans. To
decrease the object hallucination in captioning, we propose three simple yet
efficient training augmentation method for sentences which requires no new
training data or increase in the model size. By extensive analysis, we show
that the proposed methods can significantly diminish our models&apos; object bias on
hallucination metrics. Moreover, we experimentally demonstrate that our methods
decrease the dependency on the visual features. All of our code, configuration
files and model weights will be made public.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biten_A/0/1/0/all/0/1&quot;&gt;Ali Furkan Biten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1&quot;&gt;Lluis Gomez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzas_D/0/1/0/all/0/1&quot;&gt;Dimosthenis Karatzas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.01895">
<title>Investigating the Impact of Pre-trained Language Models on Dialog Evaluation. (arXiv:2110.01895v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2110.01895</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, there is a surge of interest in applying pre-trained language
models (Pr-LM) in automatic open-domain dialog evaluation. Pr-LMs offer a
promising direction for addressing the multi-domain evaluation challenge. Yet,
the impact of different Pr-LMs on the performance of automatic metrics is not
well-understood. This paper examines 8 different Pr-LMs and studies their
impact on three typical automatic dialog evaluation metrics across three
different dialog evaluation benchmarks. Specifically, we analyze how the choice
of Pr-LMs affects the performance of automatic metrics. Extensive correlation
analyses on each of the metrics are performed to assess the effects of
different Pr-LMs along various axes, including pre-training objectives, dialog
evaluation criteria, model size, and cross-dataset robustness. This study
serves as the first comprehensive assessment of the effects of different Pr-LMs
on automatic dialog evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1&quot;&gt;Luis Fernando D&amp;#x27;Haro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedrichs_T/0/1/0/all/0/1&quot;&gt;Thomas Friedrichs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haizhou Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.02473">
<title>The Power of Contrast for Feature Learning: A Theoretical Analysis. (arXiv:2110.02473v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.02473</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive learning has achieved state-of-the-art performance in various
self-supervised learning tasks and even outperforms its supervised counterpart.
Despite its empirical success, theoretical understanding of why contrastive
learning works is still limited. In this paper, (i) we provably show that
contrastive learning outperforms autoencoder, a classical unsupervised learning
method, for both feature recovery and downstream tasks; (ii) we also illustrate
the role of labeled data in supervised contrastive learning. This provides
theoretical support for recent findings that contrastive learning with labels
improves the performance of learned representations in the in-domain downstream
task, but it can harm the performance in transfer learning. We verify our
theory with numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1&quot;&gt;Wenlong Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhun Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakada_R/0/1/0/all/0/1&quot;&gt;Ryumei Nakada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1&quot;&gt;James Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Linjun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.03083">
<title>Vision-based Excavator Activity Analysis and Safety Monitoring System. (arXiv:2110.03083v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.03083</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an excavator activity analysis and safety
monitoring system, leveraging recent advancements in deep learning and computer
vision. Our proposed system detects the surrounding environment and the
excavators while estimating the poses and actions of the excavators. Compared
to previous systems, our method achieves higher accuracy in object detection,
pose estimation, and action recognition tasks. In addition, we build an
excavator dataset using the Autonomous Excavator System (AES) on the waste
disposal recycle scene to demonstrate the effectiveness of our system. We also
evaluate our method on a benchmark construction dataset. The experimental
results show that the proposed action recognition approach outperforms the
state-of-the-art approaches on top-1 accuracy by about 5.18%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Sibo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liangjun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.03469">
<title>Federated Learning from Small Datasets. (arXiv:2110.03469v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.03469</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning allows multiple parties to collaboratively train a joint
model without sharing local data. This enables applications of machine learning
in settings of inherently distributed, undisclosable data such as in the
medical domain. In practice, joint training is usually achieved by aggregating
local models, for which local training objectives have to be in expectation
similar to the joint (global) objective. Often, however, local datasets are so
small that local objectives differ greatly from the global objective, resulting
in federated learning to fail. We propose a novel approach that intertwines
model aggregations with permutations of local models. The permutations expose
each local model to a daisy chain of local datasets resulting in more efficient
training in data-sparse domains. This enables training on extremely small local
datasets, such as patient data across hospitals, while retaining the training
efficiency and privacy benefits of federated learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamp_M/0/1/0/all/0/1&quot;&gt;Michael Kamp&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1&quot;&gt;Jonas Fischer&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1&quot;&gt;Jilles Vreeken&lt;/a&gt; (1) ((1) CISPA Helmholtz Center for Information Security, (2) Max Planck Institute for Informatics)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.03485">
<title>Cartoon Explanations of Image Classifiers. (arXiv:2110.03485v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2110.03485</link>
<description rdf:parseType="Literal">&lt;p&gt;We present CartoonX (Cartoon Explanation), a novel model-agnostic explanation
method tailored towards image classifiers and based on the rate-distortion
explanation (RDE) framework. Natural images are roughly piece-wise smooth
signals -- also called cartoon images -- and tend to be sparse in the wavelet
domain. CartoonX is the first explanation method to exploit this by requiring
its explanations to be sparse in the wavelet domain, thus extracting the
\emph{relevant piece-wise smooth} part of an image instead of relevant
pixel-sparse regions. We demonstrate experimentally that CartoonX is not only
highly interpretable due to its piece-wise smooth nature but also particularly
apt at explaining misclassifications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolek_S/0/1/0/all/0/1&quot;&gt;Stefan Kolek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc Anh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1&quot;&gt;Ron Levie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1&quot;&gt;Gitta Kutyniok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.05076">
<title>A Closer Look at Prototype Classifier for Few-shot Image Classification. (arXiv:2110.05076v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.05076</link>
<description rdf:parseType="Literal">&lt;p&gt;The prototypical network is a prototype classifier based on meta-learning and
is widely used for few-shot learning because it classifies unseen examples by
constructing class-specific prototypes without adjusting hyper-parameters
during meta-testing. Interestingly, recent research has attracted a lot of
attention, showing that a linear classifier with fine-tuning, which does not
use a meta-learning algorithm, performs comparably with the prototypical
network. However, fine-tuning requires additional hyper-parameters when
adapting a model to a new environment. In addition, although the purpose of
few-shot learning is to enable the model to quickly adapt to a new environment,
fine-tuning needs to be applied every time a new class appears, making fast
adaptation difficult. In this paper, we analyze how a prototype classifier
works equally well without fine-tuning and meta-learning. We experimentally
found that directly using the feature vector extracted using standard
pre-trained models to construct a prototype classifier in meta-testing does not
perform as well as the prototypical network and linear classifiers with
fine-tuning and feature vectors of pre-trained models. Thus, we derive a novel
generalization bound for the prototypical network and show that focusing on the
variance of the norm of a feature vector can improve performance. We
experimentally investigated several normalization methods for minimizing the
variance of the norm and found that the same performance can be obtained by
using the L2 normalization and embedding space transformation without
fine-tuning or meta-learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_M/0/1/0/all/0/1&quot;&gt;Mingcheng Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.07067">
<title>Offline Reinforcement Learning for Autonomous Driving with Safety and Exploration Enhancement. (arXiv:2110.07067v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2110.07067</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) is a powerful data-driven control method that has
been largely explored in autonomous driving tasks. However, conventional RL
approaches learn control policies through trial-and-error interactions with the
environment and therefore may cause disastrous consequences such as collisions
when testing in real-world traffic. Offline RL has recently emerged as a
promising framework to learn effective policies from previously-collected,
static datasets without the requirement of active interactions, making it
especially appealing for autonomous driving applications. Despite promising,
existing offline RL algorithms such as Batch-Constrained deep Q-learning (BCQ)
generally lead to rather conservative policies with limited exploration
efficiency. To address such issues, this paper presents an enhanced BCQ
algorithm by employing a learnable parameter noise scheme in the perturbation
model to increase the diversity of observed actions. In addition, a
Lyapunov-based safety enhancement strategy is incorporated to constrain the
explorable state space within a safe region. Experimental results in highway
and parking traffic scenarios show that our approach outperforms the
conventional RL method, as well as state-of-the-art offline RL algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1&quot;&gt;Tianyu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kaian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhaojian Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.07554">
<title>Looper: An end-to-end ML platform for product decisions. (arXiv:2110.07554v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.07554</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern software systems and products increasingly rely on machine learning
models to make data-driven decisions based on interactions with users and
systems, e.g., compute infrastructure. For broader adoption, this practice must
(i) accommodate software engineers without ML backgrounds, and (ii) provide
mechanisms to optimize for product goals. In this work, we describe general
principles and a specific end-to-end ML platform, Looper, which offers
easy-to-use APIs for decision-making and feedback collection. Looper supports
the full end-to-end ML lifecycle from online data collection to model training,
deployment, inference, and extends support to evaluation and tuning against
product goals. We outline the platform architecture and overall impact of
production deployment -- Looper currently hosts 700 ML models and makes 6
million decisions per second. We also describe the learning curve and summarize
experiences of platform adopters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1&quot;&gt;Igor L. Markov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hanson Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasturi_N/0/1/0/all/0/1&quot;&gt;Nitya Kasturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shaun Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuen_S/0/1/0/all/0/1&quot;&gt;Sze Wai Yuen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrard_M/0/1/0/all/0/1&quot;&gt;Mia Garrard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1&quot;&gt;Sarah Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zehui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glotov_I/0/1/0/all/0/1&quot;&gt;Igor Glotov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1&quot;&gt;Tanvi Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Boshuang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Peng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xiaowen Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Michael Belkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uryasev_S/0/1/0/all/0/1&quot;&gt;Sal Uryasev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howie_S/0/1/0/all/0/1&quot;&gt;Sam Howie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bakshy_E/0/1/0/all/0/1&quot;&gt;Eytan Bakshy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1&quot;&gt;Norm Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.08642">
<title>Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement Learning. (arXiv:2110.08642v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.08642</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient methods have become popular in multi-agent reinforcement
learning, but they suffer from high variance due to the presence of
environmental stochasticity and exploring agents (i.e., non-stationarity),
which is potentially worsened by the difficulty in credit assignment. As a
result, there is a need for a method that is not only capable of efficiently
solving the above two problems but also robust enough to solve a variety of
tasks. To this end, we propose a new multi-agent policy gradient method, called
Robust Local Advantage (ROLA) Actor-Critic. ROLA allows each agent to learn an
individual action-value function as a local critic as well as ameliorating
environment non-stationarity via a novel centralized training approach based on
a centralized critic. By using this local critic, each agent calculates a
baseline to reduce variance on its policy gradient estimation, which results in
an expected advantage action-value over other agents&apos; choices that implicitly
improves credit assignment. We evaluate ROLA across diverse benchmarks and show
its robustness and effectiveness over a number of state-of-the-art multi-agent
policy gradient algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yuchen Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1&quot;&gt;Xueguang Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Christopher Amato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.09113">
<title>Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.09113</link>
<description rdf:parseType="Literal">&lt;p&gt;Salt and pepper noise removal is a common inverse problem in image
processing. Traditional denoising methods have two limitations. First, noise
characteristics are often not described accurately. For example, the noise
location information is often ignored and the sparsity of the salt and pepper
noise is often described by L1 norm, which cannot illustrate the sparse
variables clearly. Second, conventional methods separate the contaminated image
into a recovered image and a noise part, thus resulting in recovering an image
with unsatisfied smooth parts and detail parts. In this study, we introduce a
noise detection strategy to determine the position of the noise, and a
non-convex sparsity regularization depicted by Lp quasi-norm is employed to
describe the sparsity of the noise, thereby addressing the first limitation.
The morphological component analysis framework with stationary Framelet
transform is adopted to decompose the processed image into cartoon, texture,
and noise parts to resolve the second limitation. Then, the alternating
direction method of multipliers (ADMM) is employed to solve the proposed model.
Finally, experiments are conducted to verify the proposed method and compare it
with some current state-of-the-art denoising methods. The experimental results
show that the proposed method can remove salt and pepper noise while preserving
the details of the processed image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yingpin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yuming Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lingzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Huiying Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jianhua Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chaoqun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yanping Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.09469">
<title>Hybrid PUF: A Novel Way to Enhance the Security of Classical PUFs. (arXiv:2110.09469v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2110.09469</link>
<description rdf:parseType="Literal">&lt;p&gt;Physical unclonable functions provide a unique &apos;fingerprint&apos; to a physical
entity by exploiting the inherent physical randomness. With the help of quantum
information theory, this paper proposes solutions to protect PUFs against
machine learning-based attacks. Here, based on the querying capability, we
first divide the adversaries into two classes, namely adaptive and weak
adversaries. We also modify an existing security notion, universal
unforgeability, to capture the power of those two classes of adversaries. We
then introduce the notion of a hybrid PUF, using a classical PUF and quantum
conjugate coding. This construction encodes the output of a classical PUF in
non-orthogonal quantum states. We show that the indistinguishability of those
states can significantly enhance the security of the classical PUFs against
weak adversaries. Moreover, we show that learning the underlying classical PUF
from the outputs of our HPUF construction is at least as hard as learning the
classical PUF from its random noisy outputs. To prevent the adversaries from
querying the PUFs adaptively, we borrow ideas from a classical lockdown
technique and apply them to our hybrid PUF. We show that the hybrid PUFs,
together with the lockdown technique, termed as hybrid locked PUF, can provide
a secure client authentication protocol against adaptive adversaries and are
implementable with the current day quantum communication technology. Moreover,
we show that HLPUF allows the server to reuse the challenges for further client
authentication, providing an efficient solution for running a PUF-based client
authentication protocol for a longer period while maintaining a small-sized
challenge-response pairs database on the server-side. Finally, we explore the
lockdown technique with quantum PUF and show that the direct adaptation of the
classical lockdown technique will not work with the fully quantum PUFs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chakraborty_K/0/1/0/all/0/1&quot;&gt;Kaushik Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Doosti_M/0/1/0/all/0/1&quot;&gt;Mina Doosti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Arapinis_M/0/1/0/all/0/1&quot;&gt;Myrto Arapinis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kashefi_E/0/1/0/all/0/1&quot;&gt;Elham Kashefi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.10332">
<title>AI-Based Detection, Classification and Prediction/Prognosis in Medical Imaging: Towards Radiophenomics. (arXiv:2110.10332v3 [physics.med-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2110.10332</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) techniques have significant potential to enable
effective, robust and automated image phenotyping including identification of
subtle patterns. AI-based detection searches the image space to find the
regions of interest based on patterns and features. There is a spectrum of
tumor histologies from benign to malignant that can be identified by AI-based
classification approaches using image features. The extraction of minable
information from images gives way to the field of radiomics and can be explored
via explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics
analysis has the potential to be utilized as a noninvasive technique for the
accurate characterization of tumors to improve diagnosis and treatment
monitoring. This work reviews AI-based techniques, with a special focus on
oncological PET and PET/CT imaging, for different detection, classification,
and prediction/prognosis tasks. We also discuss needed efforts to enable the
translation of AI techniques to routine clinical workflows, and potential
improvements and complementary techniques such as the use of natural language
processing on electronic health records and neuro-symbolic AI techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yousefirizi_F/0/1/0/all/0/1&quot;&gt;Fereshteh Yousefirizi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Decazes_P/0/1/0/all/0/1&quot;&gt;Pierre Decazes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Amyar_A/0/1/0/all/0/1&quot;&gt;Amine Amyar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ruan_S/0/1/0/all/0/1&quot;&gt;Su Ruan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Saboury_B/0/1/0/all/0/1&quot;&gt;Babak Saboury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rahmim_A/0/1/0/all/0/1&quot;&gt;Arman Rahmim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.10349">
<title>Distributed Reinforcement Learning for Privacy-Preserving Dynamic Edge Caching. (arXiv:2110.10349v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.10349</link>
<description rdf:parseType="Literal">&lt;p&gt;Mobile edge computing (MEC) is a prominent computing paradigm which expands
the application fields of wireless communication. Due to the limitation of the
capacities of user equipments and MEC servers, edge caching (EC) optimization
is crucial to the effective utilization of the caching resources in MEC-enabled
wireless networks. However, the dynamics and complexities of content
popularities over space and time as well as the privacy preservation of users
pose significant challenges to EC optimization. In this paper, a
privacy-preserving distributed deep deterministic policy gradient (P2D3PG)
algorithm is proposed to maximize the cache hit rates of devices in the MEC
networks. Specifically, we consider the fact that content popularities are
dynamic, complicated and unobservable, and formulate the maximization of cache
hit rates on devices as distributed problems under the constraints of privacy
preservation. In particular, we convert the distributed optimizations into
distributed model-free Markov decision process problems and then introduce a
privacy-preserving federated learning method for popularity prediction.
Subsequently, a P2D3PG algorithm is developed based on distributed
reinforcement learning to solve the distributed problems. Simulation results
demonstrate the superiority of the proposed approach in improving EC hit rate
over the baseline methods while preserving user privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shengheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Chong Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yongming Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1&quot;&gt;Tony Q. S. Quek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.10394">
<title>Deep Learning for HDR Imaging: State-of-the-Art and Future Trends. (arXiv:2110.10394v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.10394</link>
<description rdf:parseType="Literal">&lt;p&gt;High dynamic range (HDR) imaging is a technique that allows an extensive
dynamic range of exposures, which is important in image processing, computer
graphics, and computer vision. In recent years, there has been a significant
advancement in HDR imaging using deep learning (DL). This study conducts a
comprehensive and insightful survey and analysis of recent developments in deep
HDR imaging methodologies. We hierarchically and structurally group existing
deep HDR imaging methods into five categories based on (1) number/domain of
input exposures, (2) number of learning tasks, (3) novel sensor data, (4) novel
learning strategies, and (5) applications. Importantly, we provide a
constructive discussion on each category regarding its potential and
challenges. Moreover, we review some crucial aspects of deep HDR imaging, such
as datasets and evaluation metrics. Finally, we highlight some open problems
and point out future research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yoon_K/0/1/0/all/0/1&quot;&gt;Kuk-Jin Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.10572">
<title>Estimation &amp; Recognition under Perspective of Random-Fuzzy Dual Interpretation of Unknown Quantity: with Demonstration of IMM Filter. (arXiv:2110.10572v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2110.10572</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is to consider the problems of estimation and recognition from the
perspective of sigma-max inference (probability-possibility inference), with a
focus on discovering whether some of the unknown quantities involved could be
more faithfully modeled as fuzzy uncertainty. Two related key issues are
addressed: 1) the random-fuzzy dual interpretation of unknown quantity being
estimated; 2) the principle of selecting sigma-max operator for practical
problems, such as estimation and recognition. Our perspective, conceived from
definitions of randomness and fuzziness, is that continuous unknown quantity
involved in estimation with inaccurate prior should be more appropriately
modeled as randomness and handled by sigma inference; whereas discrete unknown
quantity involved in recognition with insufficient (and inaccurate) prior could
be better modeled as fuzziness and handled by max inference. The philosophy was
demonstrated by an updated version of the well-known interacting multiple model
(IMM) filter, for which the jump Markovian System is reformulated as a hybrid
uncertainty system, with continuous state evolution modeled as usual as
model-conditioned stochastic system and discrete mode transitions modeled as
fuzzy system by a possibility (instead of probability) transition matrix, and
hypotheses mixing is conducted by using the operation of &quot;max&quot; instead of
&quot;sigma&quot;. For our example of maneuvering target tracking using simulated data
from both a short-range fire control radar and a long-range surveillance radar,
the updated IMM filter shows significant improvement over the classic IMM
filter, due to its peculiarity of hard decision of system model and a faster
response to the transition of discrete mode.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mei_W/0/1/0/all/0/1&quot;&gt;Wei Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yunfeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Limin Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.11061">
<title>Polyadic Sets and Homomorphism Counting. (arXiv:2110.11061v2 [math.CT] UPDATED)</title>
<link>http://arxiv.org/abs/2110.11061</link>
<description rdf:parseType="Literal">&lt;p&gt;A classical result due to Lovasz (1967) shows that the isomorphism type of a
graph is determined by homomorphism counts. That is, graphs G and H are
isomorphic whenever the number of homomorphisms from K to G is the same as the
number of homomorphisms from K to H for all graphs K. Variants of this result,
for various classes of finite structures, have been exploited in a wide range
of research fields, including graph theory and finite model theory.
&lt;/p&gt;
&lt;p&gt;We provide a categorical approach to homomorphism counting based on the
concept of polyadic (finite) set. The latter is a special case of the notion of
polyadic space introduced by Joyal (1971) and related, via duality, to Boolean
hyperdoctrines in categorical logic. We also obtain new homomorphism counting
results applicable to a number of infinite structures, such as finitely
branching trees and profinite algebras.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Reggio_L/0/1/0/all/0/1&quot;&gt;Luca Reggio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.11283">
<title>The Effect of Wearing a Face Mask on Face Image Quality. (arXiv:2110.11283v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.11283</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the COVID-19 situation, face masks have become a main part of our
daily life. Wearing mouth-and-nose protection has been made a mandate in many
public places, to prevent the spread of the COVID-19 virus. However, face masks
affect the performance of face recognition, since a large area of the face is
covered. The effect of wearing a face mask on the different components of the
face recognition system in a collaborative environment is a problem that is
still to be fully studied. This work studies, for the first time, the effect of
wearing a face mask on face image quality by utilising state-of-the-art face
image quality assessment methods of different natures. This aims at providing
better understanding on the effect of face masks on the operation of face
recognition as a whole system. In addition, we further studied the effect of
simulated masks on face image utility in comparison to real face masks. We
discuss the correlation between the mask effect on face image quality and that
on the face verification performance by automatic systems and human experts,
indicating a consistent trend between both factors. The evaluation is conducted
on the database containing (1) no-masked faces, (2) real face masks, and (3)
simulated face masks, by synthetically generating digital facial masks on
no-masked faces. Finally, a visual interpretation of the face areas
contributing to the quality score of a selected set of quality assessment
methods is provided to give a deeper insight into the difference of network
decisions in masked and non-masked faces, among other variations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1&quot;&gt;Biying Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1&quot;&gt;Florian Kirchbuchner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1&quot;&gt;Naser Damer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.11661">
<title>UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place Solution. (arXiv:2110.11661v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.11661</link>
<description rdf:parseType="Literal">&lt;p&gt;In this report, we introduce our (pretty straightforard) two-step
&quot;detect-then-match&quot; video instance segmentation method. The first step performs
instance segmentation for each frame to get a large number of instance mask
proposals. The second step is to do inter-frame instance mask matching with the
help of optical flow. We demonstrate that with high quality mask proposals, a
simple matching mechanism is good enough for tracking. Our approach achieves
the first place in the UVO 2021 Video-based Open-World Segmentation Challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yuming Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Wen Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yang Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1&quot;&gt;Vincent Lepetit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.12246">
<title>Parametric Variational Linear Units (PVLUs) in Deep Convolutional Networks. (arXiv:2110.12246v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.12246</link>
<description rdf:parseType="Literal">&lt;p&gt;The Rectified Linear Unit is currently a state-of-the-art activation function
in deep convolutional neural networks. To combat ReLU&apos;s dying neuron problem,
we propose the Parametric Variational Linear Unit (PVLU), which adds a
sinusoidal function with trainable coefficients to ReLU. Along with introducing
nonlinearity and non-zero gradients across the entire real domain, PVLU acts as
a mechanism of fine-tuning when implemented in the context of transfer
learning. On a simple, non-transfer sequential CNN, PVLU substitution allowed
for relative error decreases of 16.3% and 11.3% (without and with data
augmentation) on CIFAR-100. PVLU is also tested on transfer learning models.
The VGG-16 and VGG-19 models experience relative error reductions of 9.5% and
10.7% on CIFAR-10, respectively, after the substitution of ReLU with PVLU. When
training on Gaussian-filtered CIFAR-10 images, similar improvements are noted
for the VGG models. Most notably, fine-tuning using PVLU allows for relative
error reductions up to and exceeding 10% for near state-of-the-art residual
neural network architectures on the CIFAR datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Aarush Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_S/0/1/0/all/0/1&quot;&gt;Shikhar Ahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.12616">
<title>Lower bounds on quantum query complexity for symmetric functions. (arXiv:2110.12616v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2110.12616</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the main reasons for query model&apos;s prominence in quantum complexity is
the presence of concrete lower bounding techniques: polynomial method and
adversary method. There have been considerable efforts to not just give lower
bounds using these methods but even to compare and relate them. We explore the
value of these bounds on quantum query complexity for the class of symmetric
functions, arguably one of the most natural and basic set of Boolean functions.
We show (using the recently introduced spectral sensitivity) that both these
bounds (positive adversary and approximate degree) give the same value for
every total symmetric Boolean function. We also look at the quantum query
complexity of Gap Majority, a partial symmetric function. It has gained
importance recently in regard to understanding the composition of randomized
query complexity. We characterize the quantum query complexity of Gap Majority
and show a lower bound on noisy randomized query complexity (Ben-David and
Blais, FOCS 2020) in terms of quantum query complexity. In addition, we study
how large certificate complexity and block sensitivity can be as compared to
sensitivity (even up to constant factors) for symmetric functions. We show
tight separations, i.e., give upper bound on possible separations and construct
functions achieving the same.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mittal_R/0/1/0/all/0/1&quot;&gt;Rajat Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nair_S/0/1/0/all/0/1&quot;&gt;Sanjay S Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Patro_S/0/1/0/all/0/1&quot;&gt;Sunayana Patro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.13067">
<title>Evolutionary Optimization of High-Coverage Budgeted Classifiers. (arXiv:2110.13067v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2110.13067</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifiers are often utilized in time-constrained settings where labels must
be assigned to inputs quickly. To address these scenarios, budgeted multi-stage
classifiers (MSC) process inputs through a sequence of partial feature
acquisition and evaluation steps with early-exit options until a confident
prediction can be made. This allows for fast evaluation that can prevent
expensive, unnecessary feature acquisition in time-critical instances. However,
performance of MSCs is highly sensitive to several design aspects -- making
optimization of these systems an important but difficult problem.
&lt;/p&gt;
&lt;p&gt;To approximate an initially intractable combinatorial problem, current
approaches to MSC configuration rely on well-behaved surrogate loss functions
accounting for two primary objectives (processing cost, error). These
approaches have proven useful in many scenarios but are limited by analytic
constraints (convexity, smoothness, etc.) and do not manage additional
performance objectives. Notably, such methods do not explicitly account for an
important aspect of real-time detection systems -- the ratio of &quot;accepted&quot;
predictions satisfying some confidence criterion imposed by a risk-averse
monitor.
&lt;/p&gt;
&lt;p&gt;This paper proposes a problem-specific genetic algorithm, EMSCO, that
incorporates a terminal reject option for indecisive predictions and treats MSC
design as an evolutionary optimization problem with distinct objectives
(accuracy, cost, coverage). The algorithm&apos;s design emphasizes Pareto efficiency
while respecting a notion of aggregated performance via a unique scalarization.
Experiments are conducted to demonstrate EMSCO&apos;s ability to find global optima
in a variety of Theta(k^n) solution spaces, and multiple experiments show EMSCO
is competitive with alternative budgeted approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_N/0/1/0/all/0/1&quot;&gt;Nolan H. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fulp_E/0/1/0/all/0/1&quot;&gt;Errin W. Fulp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.13746">
<title>H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion. (arXiv:2110.13746v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.13746</link>
<description rdf:parseType="Literal">&lt;p&gt;We present neural radiance fields for rendering and temporal (4D)
reconstruction of humans in motion (H-NeRF), as captured by a sparse set of
cameras or even from a monocular video. Our approach combines ideas from neural
scene representation, novel-view synthesis, and implicit statistical geometric
human representations, coupled using novel loss functions. Instead of learning
a radiance field with a uniform occupancy prior, we constrain it by a
structured implicit human body model, represented using signed distance
functions. This allows us to robustly fuse information from sparse views and
generalize well beyond the poses or views observed in training. Moreover, we
apply geometric constraints to co-learn the structure of the observed subject
-- including both body and clothing -- and to regularize the radiance field to
geometrically plausible solutions. Extensive experiments on multiple datasets
demonstrate the robustness and the accuracy of our approach, its generalization
capabilities significantly outside a small training set of poses and views, and
statistical extrapolation beyond the observed shape.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongyi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alldieck_T/0/1/0/all/0/1&quot;&gt;Thiemo Alldieck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sminchisescu_C/0/1/0/all/0/1&quot;&gt;Cristian Sminchisescu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14115">
<title>Metrics of research impact in astronomy: Predicting later impact from metrics measured 10-15 years after the PhD. (arXiv:2110.14115v3 [astro-ph.IM] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14115</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper calibrates how metrics derivable from the SAO/NASA Astrophysics
Data System can be used to estimate the future impact of astronomy research
careers and thereby to inform decisions on resource allocation such as job
hires and tenure decisions. Three metrics are used, citations of refereed
papers, citations of all publications normalized by the numbers of co-authors,
and citations of all first-author papers. Each is individually calibrated as an
impact predictor in the book Kormendy (2020), &quot;Metrics of Research Impact in
Astronomy&quot; (Astron Soc Pac Conference Series Monograph 8, San Francisco). How
this is done is reviewed in the first half of this paper. Then, I show that
averaging results from three metrics produces more accurate predictions.
Average prediction machines are constructed for different cohorts of 1990-2007
PhDs and used to postdict 2017 impact from metrics measured 10, 12, and 15
years after the PhD. The time span over which prediction is made ranges from 0
years for 2007 PhDs to 17 years for 1990 PhDs using metrics measured 10 years
after the PhD. Calibration is based on perceived 2017 impact as voted by 22
experienced astronomers for 510 faculty members at 17 highly-ranked university
astronomy departments world-wide. Prediction machinery reproduces voted impact
estimates with an RMS uncertainty of 1/8 of the dynamic range for people in the
study sample. The aim of this work is to lend some of the rigor that is
normally used in scientific research to the difficult and subjective job of
judging people&apos;s careers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Kormendy_J/0/1/0/all/0/1&quot;&gt;John Kormendy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14124">
<title>A novel decompostion-based multiobjective evolutionary algorithm with an application to engineering optimal design problems. (arXiv:2110.14124v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14124</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world optimization problems such as engineering design can be
eventually modeled as the corresponding multiobjective optimization problems
(MOPs) which must be solved to obtain approximate Pareto optimal fronts.
Multiobjective evolutionary algorithm based on decomposition (MOEA/D) has been
regarded as a very promising approach for solving MOPs. Recent studies have
shown that MOEA/D with uniform weight vectors is well-suited to MOPs with
regular Pareto optimal fronts, but its performance in terms of diversity
deteriorates on MOPs with irregular Pareto optimal fronts such as highly
nonlinear and convex. In this way, the solution set obtained by the algorithm
can not provide more reasonable choices for decision makers. In order to
efficiently overcome this drawback, in this paper, we propose an improved
MOEA/D algorithm by virtue of the well-known Pascoletti-Serafini scalarization
method and a new strategy of multi-reference points. Specifically, this
strategy consists of the setting and adaptation of reference points generated
by the techniques of equidistant partition and projection. For performance
assessment, the proposed algorithm is compared with existing four
state-of-the-art multiobjective evolutionary algorithms on both benchmark test
problems with various types of Pareto optimal fronts and two real-world MOPs
including the hatch cover design and the rocket injector design in engineering
optimization. According to the experimental results, the proposed algorithm
exhibits better diversity performance than that of the other compared
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Weitian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xinmin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14270">
<title>Counterfactual Shapley Additive Explanations. (arXiv:2110.14270v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14270</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature attributions are a common paradigm for model explanations due to
their simplicity in assigning a single numeric score for each input feature to
a model. In the actionable recourse setting, wherein the goal of the
explanations is to improve outcomes for model consumers, it is often unclear
how feature attributions should be correctly used. With this work, we aim to
strengthen and clarify the link between actionable recourse and feature
attributions. Concretely, we propose a variant of SHAP, CoSHAP, that uses
counterfactual generation techniques to produce a background dataset for use
within the marginal (a.k.a. interventional) Shapley value framework. We
motivate the need within the actionable recourse setting for careful
consideration of background datasets when using Shapley values for feature
attributions, alongside the requirement for monotonicity, with numerous
synthetic examples. Moreover, we demonstrate the efficacy of CoSHAP by
proposing and justifying a quantitative score for feature attributions,
counterfactual-ability, showing that as measured by this metric, CoSHAP is
superior to existing methods when evaluated on public datasets using monotone
tree ensembles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albini_E/0/1/0/all/0/1&quot;&gt;Emanuele Albini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1&quot;&gt;Jason Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1&quot;&gt;Danial Dervovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1&quot;&gt;Daniele Magazzeni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14389">
<title>Charon: Load-Aware Load-Balancing in P4. (arXiv:2110.14389v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14389</link>
<description rdf:parseType="Literal">&lt;p&gt;Load-Balancers play an important role in data centers as they distribute
network flows across application servers and guarantee per-connection
consistency. It is hard however to make fair load balancing decisions so that
all resources are efficiently occupied yet not overloaded. Tracking connection
states allows to infer server load states and make informed decisions, but at
the cost of additional memory space consumption. This makes it hard to
implement on programmable hardware, which has constrained memory but offers
line-rate performance. This paper presents Charon, a stateless load-aware load
balancer that has line-rate performance implemented in P4-NetFPGA. Charon
passively collects load states from application servers and employs the
power-of-2-choices scheme to make data-driven load balancing decisions and
improve resource utilization. Perconnection consistency is preserved
statelessly by encoding server ID in a covert channel. The prototype design and
implementation details are described in this paper. Simulation results show
performance gains in terms of load distribution fairness, quality of service,
throughput and processing latency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_C/0/1/0/all/0/1&quot;&gt;Carmine Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desmouceaux_Y/0/1/0/all/0/1&quot;&gt;Yoann Desmouceaux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Townsley_M/0/1/0/all/0/1&quot;&gt;Mark Townsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clausen_T/0/1/0/all/0/1&quot;&gt;Thomas Heide Clausen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14864">
<title>Selective Sampling for Online Best-arm Identification. (arXiv:2110.14864v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14864</link>
<description rdf:parseType="Literal">&lt;p&gt;This work considers the problem of selective-sampling for best-arm
identification. Given a set of potential options
$\mathcal{Z}\subset\mathbb{R}^d$, a learner aims to compute with probability
greater than $1-\delta$, $\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$
where $\theta_{\ast}$ is unknown. At each time step, a potential measurement
$x_t\in \mathcal{X}\subset\mathbb{R}^d$ is drawn IID and the learner can either
choose to take the measurement, in which case they observe a noisy measurement
of $x^{\top}\theta_{\ast}$, or to abstain from taking the measurement and wait
for a potentially more informative point to arrive in the stream. Hence the
learner faces a fundamental trade-off between the number of labeled samples
they take and when they have collected enough evidence to declare the best arm
and stop sampling. The main results of this work precisely characterize this
trade-off between labeled samples and stopping time and provide an algorithm
that nearly-optimally achieves the minimal label complexity given a desired
stopping time. In addition, we show that the optimal decision rule has a simple
geometric form based on deciding whether a point is in an ellipse or not.
Finally, our framework is general enough to capture binary classification
improving upon previous works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camilleri_R/0/1/0/all/0/1&quot;&gt;Romain Camilleri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zhihan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1&quot;&gt;Maryam Fazel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_L/0/1/0/all/0/1&quot;&gt;Lalit Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1&quot;&gt;Kevin Jamieson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14875">
<title>Finding a Concise, Precise, and Exhaustive Set of Near Bi-Cliques in Dynamic Graphs. (arXiv:2110.14875v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14875</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of tasks on dynamic graphs, including anomaly detection, community
detection, compression, and graph understanding, have been formulated as
problems of identifying constituent (near) bi-cliques (i.e., complete bipartite
graphs). Even when we restrict our attention to maximal ones, there can be
exponentially many near bi-cliques, and thus finding all of them is practically
impossible for large graphs. Then, two questions naturally arise: (Q1) What is
a &quot;good&quot; set of near bi-cliques? That is, given a set of near bi-cliques in the
input dynamic graph, how should we evaluate its quality? (Q2) Given a large
dynamic graph, how can we rapidly identify a high-quality set of near
bi-cliques in it? Regarding Q1, we measure how concisely, precisely, and
exhaustively a given set of near bi-cliques describes the input dynamic graph.
We combine these three perspectives systematically on the Minimum Description
Length principle. Regarding Q2, we propose CutNPeel, a fast search algorithm
for a high-quality set of near bi-cliques. By adaptively re-partitioning the
input graph, CutNPeel reduces the search space and at the same time improves
the search quality. Our experiments using six real-world dynamic graphs
demonstrate that CutNPeel is (a) High-quality: providing near bi-cliques of up
to 51.2% better quality than its state-of-the-art competitors, (b) Fast: up to
68.8x faster than the next-best competitor, and (c) Scalable: scaling to graphs
with 134 million edges. We also show successful applications of CutNPeel to
graph compression and pattern discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_H/0/1/0/all/0/1&quot;&gt;Hyeonjeong Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1&quot;&gt;Taehyung Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Neil Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1&quot;&gt;Kijung Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14890">
<title>SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs. (arXiv:2110.14890v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14890</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) capture knowledge in the form of head--relation--tail
triples and are a crucial component in many AI systems. There are two important
reasoning tasks on KGs: (1) single-hop knowledge graph completion, which
involves predicting individual links in the KG; and (2), multi-hop reasoning,
where the goal is to predict which KG entities satisfy a given logical query.
Embedding-based methods solve both tasks by first computing an embedding for
each entity and relation, then using them to form predictions. However,
existing scalable KG embedding frameworks only support single-hop knowledge
graph completion and cannot be applied to the more challenging multi-hop
reasoning task. Here we present Scalable Multi-hOp REasoning (SMORE), the first
general framework for both single-hop and multi-hop reasoning in KGs. Using a
single machine SMORE can perform multi-hop reasoning in Freebase KG (86M
entities, 338M edges), which is 1,500x larger than previously considered KGs.
The key to SMORE&apos;s runtime performance is a novel bidirectional rejection
sampling that achieves a square root reduction of the complexity of online
training data generation. Furthermore, SMORE exploits asynchronous scheduling,
overlapping CPU-based data sampling, GPU-based embedding computation, and
frequent CPU--GPU IO. SMORE increases throughput (i.e., training speed) over
prior multi-hop KG frameworks by 2.2x with minimal GPU memory requirements (2GB
for training 400-dim embeddings on 86M-node Freebase) and achieves near linear
speed-up with the number of GPUs. Moreover, on the simpler single-hop knowledge
graph completion task SMORE achieves comparable or even better runtime
performance to state-of-the-art frameworks on both single GPU and multi-GPU
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Hongyu Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Hanjun Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Bo Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Denny Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1&quot;&gt;Dale Schuurmans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14940">
<title>FocusFace: Multi-task Contrastive Learning for Masked Face Recognition. (arXiv:2110.14940v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14940</link>
<description rdf:parseType="Literal">&lt;p&gt;SARS-CoV-2 has presented direct and indirect challenges to the scientific
community. One of the most prominent indirect challenges advents from the
mandatory use of face masks in a large number of countries. Face recognition
methods struggle to perform identity verification with similar accuracy on
masked and unmasked individuals. It has been shown that the performance of
these methods drops considerably in the presence of face masks, especially if
the reference image is unmasked. We propose FocusFace, a multi-task
architecture that uses contrastive learning to be able to accurately perform
masked face recognition. The proposed architecture is designed to be trained
from scratch or to work on top of state-of-the-art face recognition methods
without sacrificing the capabilities of a existing models in conventional face
recognition tasks. We also explore different approaches to design the
contrastive learning module. Results are presented in terms of masked-masked
(M-M) and unmasked-masked (U-M) face verification performance. For both
settings, the results are on par with published methods, but for M-M
specifically, the proposed method was able to outperform all the solutions that
it was compared to. We further show that when using our method on top of
already existing methods the training computational costs decrease
significantly while retaining similar performances. The implementation and the
trained models are available at GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neto_P/0/1/0/all/0/1&quot;&gt;Pedro C. Neto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1&quot;&gt;Fadi Boutros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Ribeiro Pinto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1&quot;&gt;Naser Damer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sequeira_A/0/1/0/all/0/1&quot;&gt;Ana F. Sequeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_J/0/1/0/all/0/1&quot;&gt;Jaime S. Cardoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15084">
<title>Using Non-Linear Causal Models to Study Aerosol-Cloud Interactions in the Southeast Pacific. (arXiv:2110.15084v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15084</link>
<description rdf:parseType="Literal">&lt;p&gt;Aerosol-cloud interactions include a myriad of effects that all begin when
aerosol enters a cloud and acts as cloud condensation nuclei (CCN). An increase
in CCN results in a decrease in the mean cloud droplet size (r$_{e}$). The
smaller droplet size leads to brighter, more expansive, and longer lasting
clouds that reflect more incoming sunlight, thus cooling the earth. Globally,
aerosol-cloud interactions cool the Earth, however the strength of the effect
is heterogeneous over different meteorological regimes. Understanding how
aerosol-cloud interactions evolve as a function of the local environment can
help us better understand sources of error in our Earth system models, which
currently fail to reproduce the observed relationships. In this work we use
recent non-linear, causal machine learning methods to study the heterogeneous
effects of aerosols on cloud droplet radius.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jesson_A/0/1/0/all/0/1&quot;&gt;Andrew Jesson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Manshausen_P/0/1/0/all/0/1&quot;&gt;Peter Manshausen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Douglas_A/0/1/0/all/0/1&quot;&gt;Alyson Douglas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Watson_Parris_D/0/1/0/all/0/1&quot;&gt;Duncan Watson-Parris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gal_Y/0/1/0/all/0/1&quot;&gt;Yarin Gal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Stier_P/0/1/0/all/0/1&quot;&gt;Philip Stier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15122">
<title>CAFE: Catastrophic Data Leakage in Vertical Federated Learning. (arXiv:2110.15122v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15122</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies show that private training data can be leaked through the
gradients sharing mechanism deployed in distributed machine learning systems,
such as federated learning (FL). Increasing batch size to complicate data
recovery is often viewed as a promising defense strategy against data leakage.
In this paper, we revisit this defense premise and propose an advanced data
leakage attack with theoretical justification to efficiently recover batch data
from the shared aggregated gradients. We name our proposed method as
catastrophic data leakage in vertical federated learning (CAFE). Comparing to
existing data leakage attacks, our extensive experimental results on vertical
FL settings demonstrate the effectiveness of CAFE to perform large-batch data
leakage attack with improved data recovery quality. We also propose a practical
countermeasure to mitigate CAFE. Our results suggest that private data
participated in standard FL, especially the vertical case, have a high risk of
being leaked from the training gradients. Our analysis implies unprecedented
and practical data leakage risks in those learning settings. The code of our
work is available at https://github.com/DeRafael/CAFE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xiao Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1&quot;&gt;Chia-Yi Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chia-Mu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15412">
<title>Stochastic Mirror Descent: Convergence Analysis and Adaptive Variants via the Mirror Stochastic Polyak Stepsize. (arXiv:2110.15412v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15412</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the convergence of stochastic mirror descent (SMD) in
relatively smooth and smooth convex optimization. In relatively smooth convex
optimization we provide new convergence guarantees for SMD with a constant
stepsize. For smooth convex optimization we propose a new adaptive stepsize
scheme -- the mirror stochastic Polyak stepsize (mSPS). Notably, our
convergence results in both settings do not make bounded gradient assumptions
or bounded variance assumptions, and we show convergence to a neighborhood that
vanishes under interpolation. mSPS generalizes the recently proposed stochastic
Polyak stepsize (SPS) (Loizou et al., 2021) to mirror descent and remains both
practical and efficient for modern machine learning applications while
inheriting the benefits of mirror descent. We complement our results with
experiments across various supervised learning tasks and different instances of
SMD, demonstrating the effectiveness of mSPS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+DOrazio_R/0/1/0/all/0/1&quot;&gt;Ryan D&amp;#x27;Orazio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1&quot;&gt;Nicolas Loizou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Laradji_I/0/1/0/all/0/1&quot;&gt;Issam Laradji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mitliagkas_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15444">
<title>10 Security and Privacy Problems in Self-Supervised Learning. (arXiv:2110.15444v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15444</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning has achieved revolutionary progress in the past
several years and is commonly believed to be a promising approach for
general-purpose AI. In particular, self-supervised learning aims to pre-train
an encoder using a large amount of unlabeled data. The pre-trained encoder is
like an &quot;operating system&quot; of the AI ecosystem. Specifically, the encoder can
be used as a feature extractor for many downstream tasks with little or no
labeled training data. Existing studies on self-supervised learning mainly
focused on pre-training a better encoder to improve its performance on
downstream tasks in non-adversarial settings, leaving its security and privacy
in adversarial settings largely unexplored. A security or privacy issue of a
pre-trained encoder leads to a single point of failure for the AI ecosystem. In
this book chapter, we discuss 10 basic security and privacy problems for the
pre-trained encoders in self-supervised learning, including six confidentiality
problems, three integrity problems, and one availability problem. For each
problem, we discuss potential opportunities and challenges. We hope our book
chapter will inspire future research on the security and privacy of
self-supervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jinyuan Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongbin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1&quot;&gt;Neil Zhenqiang Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15715">
<title>An Effective Image Restorer: Denoising and Luminance Adjustment for Low-photon-count Imaging. (arXiv:2110.15715v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15715</link>
<description rdf:parseType="Literal">&lt;p&gt;Imaging under photon-scarce situations introduces challenges to many
applications as the captured images are with low signal-to-noise ratio and poor
luminance. In this paper, we investigate the raw image restoration under
low-photon-count conditions by simulating the imaging of quanta image sensor
(QIS). We develop a lightweight framework, which consists of a multi-level
pyramid denoising network (MPDNet) and a luminance adjustment (LA) module to
achieve separate denoising and luminance enhancement. The main component of our
framework is the multi-skip attention residual block (MARB), which integrates
multi-scale feature fusion and attention mechanism for better feature
representation. Our MPDNet adopts the idea of Laplacian pyramid to learn the
small-scale noise map and larger-scale high-frequency details at different
levels, and feature extractions are conducted on the multi-scale input images
to encode richer contextual information. Our LA module enhances the luminance
of the denoised image by estimating its illumination, which can better avoid
color distortion. Extensive experimental results have demonstrated that our
image restorer can achieve superior performance on the degraded images with
various photon levels by suppressing noise and recovering luminance and color
effectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shansi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lam_E/0/1/0/all/0/1&quot;&gt;Edmund Y. Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15720">
<title>Weakly Supervised Concept Map Generation through Task-Guided Graph Translation. (arXiv:2110.15720v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15720</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed the rapid development of concept map generation
techniques due to their advantages in providing well-structured summarization
of knowledge from free texts. Traditional unsupervised methods do not generate
task-oriented concept maps, whereas deep generative models require large
amounts of training data. In this work, we present GT-D2G (Graph Translation
based Document-To-Graph), an automatic concept map generation framework that
leverages generalized NLP pipelines to derive semantic-rich initial graphs, and
translates them into more concise structures under the weak supervision of
document labels. The quality and interpretability of such concept maps are
validated through human evaluation on three real-world corpora, and their
utility in the downstream task is further demonstrated in the controlled
experiments with scarce document labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiaying Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1&quot;&gt;Xiangjue Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Carl Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00082">
<title>PiDRAM: A Holistic End-to-end FPGA-based Framework for Processing-in-DRAM. (arXiv:2111.00082v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00082</link>
<description rdf:parseType="Literal">&lt;p&gt;Processing-using-memory (PuM) techniques leverage the analog operation of
memory cells to perform computation. Several recent works have demonstrated PuM
techniques in off-the-shelf DRAM devices. Since DRAM is the dominant memory
technology as main memory in current computing systems, these PuM techniques
represent an opportunity for alleviating the data movement bottleneck at very
low cost. However, system integration of PuM techniques imposes non-trivial
challenges that are yet to be solved. Design space exploration of potential
solutions to the PuM integration challenges requires appropriate tools to
develop necessary hardware and software components. Unfortunately, current
specialized DRAM-testing platforms, or system simulators do not provide the
flexibility and/or the holistic system view that is necessary to deal with PuM
integration challenges.
&lt;/p&gt;
&lt;p&gt;We design and develop PiDRAM, the first flexible end-to-end framework that
enables system integration studies and evaluation of real PuM techniques.
PiDRAM provides software and hardware components to rapidly integrate PuM
techniques across the whole system software and hardware stack (e.g., necessary
modifications in the operating system, memory controller). We implement PiDRAM
on an FPGA-based platform along with an open-source RISC-V system. Using
PiDRAM, we implement and evaluate two state-of-the-art PuM techniques: in-DRAM
(i) copy and initialization, (ii) true random number generation. Our results
show that the in-memory copy and initialization techniques can improve the
performance of bulk copy operations by 12.6x and bulk initialization operations
by 14.6x on a real system. Implementing the true random number generator
requires only 190 lines of Verilog and 74 lines of C code using PiDRAM&apos;s
software and hardware components.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olgun_A/0/1/0/all/0/1&quot;&gt;Ataberk Olgun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luna_J/0/1/0/all/0/1&quot;&gt;Juan G&amp;#xf3;mez Luna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanellopoulos_K/0/1/0/all/0/1&quot;&gt;Konstantinos Kanellopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salami_B/0/1/0/all/0/1&quot;&gt;Behzad Salami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_H/0/1/0/all/0/1&quot;&gt;Hasan Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ergin_O/0/1/0/all/0/1&quot;&gt;O&amp;#x11f;uz Ergin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1&quot;&gt;Onur Mutlu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00116">
<title>Visual Explanations for Convolutional Neural Networks via Latent Traversal of Generative Adversarial Networks. (arXiv:2111.00116v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00116</link>
<description rdf:parseType="Literal">&lt;p&gt;Lack of explainability in artificial intelligence, specifically deep neural
networks, remains a bottleneck for implementing models in practice. Popular
techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)
provide a coarse map of salient features in an image, which rarely tells the
whole story of what a convolutional neural network (CNN) learned. Using
COVID-19 chest X-rays, we present a method for interpreting what a CNN has
learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework
disentangles lung structure from COVID-19 features. Using this GAN, we can
visualize the transition of a pair of COVID negative lungs in a chest
radiograph to a COVID positive pair by interpolating in the latent space of the
GAN, which provides fine-grained visualization of how the CNN responds to
varying features within the lungs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dravid_A/0/1/0/all/0/1&quot;&gt;Amil Dravid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsaggelos_A/0/1/0/all/0/1&quot;&gt;Aggelos K. Katsaggelos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00429">
<title>Enhancing Top-N Item Recommendations by Peer Collaboration. (arXiv:2111.00429v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00429</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNN) have achieved great success in the recommender
systems (RS) domain. However, to achieve remarkable performance, DNN-based
recommender models often require numerous parameters, which inevitably bring
redundant neurons and weights, a phenomenon referred to as
over-parameterization. In this paper, we plan to exploit such redundancy
phenomena to improve the performance of RS. Specifically, we propose PCRec, a
top-N item \underline{rec}ommendation framework that leverages collaborative
training of two DNN-based recommender models with the same network structure,
termed \underline{p}eer \underline{c}ollaboration. PCRec can reactivate and
strengthen the unimportant (redundant) weights during training, which achieves
higher prediction accuracy but maintains its original inference efficiency. To
realize this, we first introduce two criteria to identify the importance of
weights of a given recommender model. Then, we rejuvenate the unimportant
weights by transplanting outside information (i.e., weights) from its peer
network. After such an operation and retraining, the original recommender model
is endowed with more representation capacity by possessing more functional
model parameters. To show its generality, we instantiate PCRec by using three
well-known recommender models. We conduct extensive experiments on three
real-world datasets, and show that PCRec yields significantly better
recommendations than its counterpart with the same model (parameter) size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1&quot;&gt;Fajie Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzoglou_A/0/1/0/all/0/1&quot;&gt;Alexandros Karatzoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00598">
<title>Recognizing Families In the Wild (RFIW): The 5th Edition. (arXiv:2111.00598v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00598</link>
<description rdf:parseType="Literal">&lt;p&gt;Recognizing Families In the Wild (RFIW), held as a data challenge in
conjunction with the 16th IEEE International Conference on Automatic Face and
Gesture Recognition (FG), is a large-scale, multi-track visual kinship
recognition evaluation. This is our fifth edition of RFIW, for which we
continue the effort to attract scholars, bring together professionals, publish
new work, and discuss prospects. In this paper, we summarize submissions for
the three tasks of this year&apos;s RFIW: specifically, we review the results for
kinship verification, tri-subject verification, and family member search and
retrieval. We take a look at the RFIW problem, as well as share current efforts
and make recommendations for promising future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;Joseph P. Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1&quot;&gt;Can Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_M/0/1/0/all/0/1&quot;&gt;Ming Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turk_M/0/1/0/all/0/1&quot;&gt;Matthew A. Turk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yun Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00660">
<title>Evaluation of Human and Machine Face Detection using a Novel Distinctive Human Appearance Dataset. (arXiv:2111.00660v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00660</link>
<description rdf:parseType="Literal">&lt;p&gt;Face detection is a long-standing challenge in the field of computer vision,
with the ultimate goal being to accurately localize human faces in an
unconstrained environment. There are significant technical hurdles in making
these systems accurate due to confounding factors related to pose, image
resolution, illumination, occlusion, and viewpoint [44]. That being said, with
recent developments in machine learning, face-detection systems have achieved
extraordinary accuracy, largely built on data-driven deep-learning models [70].
Though encouraging, a critical aspect that limits face-detection performance
and social responsibility of deployed systems is the inherent diversity of
human appearance. Every human appearance reflects something unique about a
person, including their heritage, identity, experiences, and visible
manifestations of self-expression. However, there are questions about how well
face-detection systems perform when faced with varying face size and shape,
skin color, body modification, and body ornamentation. Towards this goal, we
collected the Distinctive Human Appearance dataset, an image set that
represents appearances with low frequency and that tend to be undersampled in
face datasets. Then, we evaluated current state-of-the-art face-detection
models in their ability to detect faces in these images. The evaluation results
show that face-detection algorithms do not generalize well to these diverse
appearances. Evaluating and characterizing the state of current face-detection
models will accelerate research and development towards creating fairer and
more accurate face-detection systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurkan_N/0/1/0/all/0/1&quot;&gt;Necdet Gurkan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suchow_J/0/1/0/all/0/1&quot;&gt;Jordan W. Suchow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00674">
<title>Distilling Object Detectors with Feature Richness. (arXiv:2111.00674v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00674</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, large-scale deep models have achieved great success, but the
huge computational complexity and massive storage requirements make it a great
challenge to deploy them in resource-limited devices. As a model compression
and acceleration method, knowledge distillation effectively improves the
performance of small models by transferring the dark knowledge from the teacher
detector. However, most of the existing distillation-based detection methods
mainly imitating features near bounding boxes, which suffer from two
limitations. First, they ignore the beneficial features outside the bounding
boxes. Second, these methods imitate some features which are mistakenly
regarded as the background by the teacher detector. To address the above
issues, we propose a novel Feature-Richness Score (FRS) method to choose
important features that improve generalized detectability during distilling.
The proposed method effectively retrieves the important features outside the
bounding boxes and removes the detrimental features within the bounding boxes.
Extensive experiments show that our methods achieve excellent performance on
both anchor-based and anchor-free detectors. For example, RetinaNet with
ResNet-50 achieves 39.7% in mAP on the COCO2017 dataset, which even surpasses
the ResNet-101 based teacher detector 38.9% by 0.8%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1&quot;&gt;Zhixing Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Rui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Ming Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xishan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shaoli Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianshi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yunji Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00772">
<title>AdaPool: Exponential Adaptive Pooling for Information-Retaining Downsampling. (arXiv:2111.00772v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00772</link>
<description rdf:parseType="Literal">&lt;p&gt;Pooling layers are essential building blocks of Convolutional Neural Networks
(CNNs) that reduce computational overhead and increase the receptive fields of
proceeding convolutional operations. They aim to produce downsampled volumes
that closely resemble the input volume while, ideally, also being
computationally and memory efficient. It is a challenge to meet both
requirements jointly. To this end, we propose an adaptive and exponentially
weighted pooling method named adaPool. Our proposed method uses a parameterized
fusion of two sets of pooling kernels that are based on the exponent of the
Dice-Sorensen coefficient and the exponential maximum, respectively. A key
property of adaPool is its bidirectional nature. In contrast to common pooling
methods, weights can be used to upsample a downsampled activation map. We term
this method adaUnPool. We demonstrate how adaPool improves the preservation of
detail through a range of tasks including image and video classification and
object detection. We then evaluate adaUnPool on image and video frame
super-resolution and frame interpolation tasks. For benchmarking, we introduce
Inter4K, a novel high-quality, high frame-rate video dataset. Our combined
experiments demonstrate that adaPool systematically achieves better results
across tasks and backbone architectures, while introducing a minor additional
computational and memory overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stergiou_A/0/1/0/all/0/1&quot;&gt;Alexandros Stergiou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poppe_R/0/1/0/all/0/1&quot;&gt;Ronald Poppe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00801">
<title>Livestock Monitoring with Transformer. (arXiv:2111.00801v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00801</link>
<description rdf:parseType="Literal">&lt;p&gt;Tracking the behaviour of livestock enables early detection and thus
prevention of contagious diseases in modern animal farms. Apart from economic
gains, this would reduce the amount of antibiotics used in livestock farming
which otherwise enters the human diet exasperating the epidemic of antibiotic
resistance - a leading cause of death. We could use standard video cameras,
available in most modern farms, to monitor livestock. However, most computer
vision algorithms perform poorly on this task, primarily because, (i) animals
bred in farms look identical, lacking any obvious spatial signature, (ii) none
of the existing trackers are robust for long duration, and (iii) real-world
conditions such as changing illumination, frequent occlusion, varying camera
angles, and sizes of the animals make it hard for models to generalize. Given
these challenges, we develop an end-to-end behaviour monitoring system for
group-housed pigs to perform simultaneous instance level segmentation,
tracking, action recognition and re-identification (STAR) tasks. We present
starformer, the first end-to-end multiple-object livestock monitoring framework
that learns instance-level embeddings for grouped pigs through the use of
transformer architecture. For benchmarking, we present Pigtrace, a carefully
curated dataset comprising video sequences with instance level bounding box,
segmentation, tracking and activity classification of pigs in real indoor
farming environment. Using simultaneous optimization on STAR tasks we show that
starformer outperforms popular baseline models trained for individual tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tangirala_B/0/1/0/all/0/1&quot;&gt;Bhavesh Tangirala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhandari_I/0/1/0/all/0/1&quot;&gt;Ishan Bhandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laszlo_D/0/1/0/all/0/1&quot;&gt;Daniel Laszlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1&quot;&gt;Deepak K. Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_R/0/1/0/all/0/1&quot;&gt;Rajat M. Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arya_D/0/1/0/all/0/1&quot;&gt;Devanshu Arya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00826">
<title>Teaching Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence through the Lens of Reproducibility. (arXiv:2111.00826v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00826</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we explain the setup for a technical, graduate-level course on
Fairness, Accountability, Confidentiality and Transparency in Artificial
Intelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI
concepts through the lens of reproducibility. The focal point of the course is
a group project based on reproducing existing FACT-AI algorithms from top AI
conferences, and writing a report about their experiences. In the first
iteration of the course, we created an open source repository with the code
implementations from the group projects. In the second iteration, we encouraged
students to submit their group projects to the Machine Learning Reproducibility
Challenge, which resulted in 9 reports from our course being accepted to the
challenge. We reflect on our experience teaching the course over two academic
years, where one year coincided with a global pandemic, and propose guidelines
for teaching FACT-AI through reproducibility in graduate-level AI programs. We
hope this can be a useful resource for instructors to set up similar courses at
their universities in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1&quot;&gt;Ana Lucic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1&quot;&gt;Maurits Bleeker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jullien_S/0/1/0/all/0/1&quot;&gt;Sami Jullien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhargav_S/0/1/0/all/0/1&quot;&gt;Samarth Bhargav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00856">
<title>Large-Scale Deep Learning Optimizations: A Comprehensive Survey. (arXiv:2111.00856v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00856</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning have achieved promising results on a wide spectrum of AI
applications. Larger datasets and models consistently yield better performance.
However, we generally spend longer training time on more computation and
communication. In this survey, we aim to provide a clear sketch about the
optimizations for large-scale deep learning with regard to the model accuracy
and model efficiency. We investigate algorithms that are most commonly used for
optimizing, elaborate the debatable topic of generalization gap arises in
large-batch training, and review the SOTA strategies in addressing the
communication overhead and reducing the memory footprints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaoxin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1&quot;&gt;Fuzhao Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiaozhe Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yang You&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00868">
<title>A mathematical model of the vowel space. (arXiv:2111.00868v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00868</link>
<description rdf:parseType="Literal">&lt;p&gt;The articulatory-acoustic relationship is many-to-one and non linear and this
is a great limitation for studying speech production. A simplification is
proposed to set a bijection between the vowel space (f1, f2) and the parametric
space of different vocal tract models. The generic area function model is based
on mixtures of cosines allowing the generation of main vowels with two
formulas. Then the mixture function is transformed into a coordination function
able to deal with articulatory parameters. This is shown that the coordination
function acts similarly with the Fant&apos;s model and with the 4-Tube DRM derived
from the generic model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthommier_F/0/1/0/all/0/1&quot;&gt;Fr&amp;#xe9;d&amp;#xe9;ric Berthommier&lt;/a&gt; (GIPSA-PCMD)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00905">
<title>Smart Fashion: A Review of AI Applications in the Fashion &amp; Apparel Industry. (arXiv:2111.00905v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00905</link>
<description rdf:parseType="Literal">&lt;p&gt;The fashion industry is on the verge of an unprecedented change. The
implementation of machine learning, computer vision, and artificial
intelligence (AI) in fashion applications is opening lots of new opportunities
for this industry. This paper provides a comprehensive survey on this matter,
categorizing more than 580 related articles into 22 well-defined
fashion-related tasks. Such structured task-based multi-label classification of
fashion research articles provides researchers with explicit research
directions and facilitates their access to the related studies, improving the
visibility of studies simultaneously. For each task, a time chart is provided
to analyze the progress through the years. Furthermore, we provide a list of 86
public fashion datasets accompanied by a list of suggested applications and
additional information for each.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_S/0/1/0/all/0/1&quot;&gt;Seyed Omid Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalhor_A/0/1/0/all/0/1&quot;&gt;Ahmad Kalhor&lt;/a&gt; (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00929">
<title>Bounds all around: training energy-based models with bidirectional bounds. (arXiv:2111.00929v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00929</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy-based models (EBMs) provide an elegant framework for density
estimation, but they are notoriously difficult to train. Recent work has
established links to generative adversarial networks, where the EBM is trained
through a minimax game with a variational value function. We propose a
bidirectional bound on the EBM log-likelihood, such that we maximize a lower
bound and minimize an upper bound when solving the minimax game. We link one
bound to a gradient penalty that stabilizes training, thereby providing
grounding for best engineering practice. To evaluate the bounds we develop a
new and efficient estimator of the Jacobi-determinant of the EBM generator. We
demonstrate that these developments significantly stabilize training and yield
high-quality density estimation and sample generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_C/0/1/0/all/0/1&quot;&gt;Cong Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00947">
<title>Nested Multiple Instance Learning with Attention Mechanisms. (arXiv:2111.00947v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00947</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a type of weakly supervised learning
where multiple instances of data with unknown labels are sorted into bags.
Since knowledge about the individual instances is incomplete, labels are
assigned to the bags containing the instances. While this method fits diverse
applications were labelled data is scarce, it lacks depth for solving more
complex scenarios where associations between sets of instances have to be made,
like finding relevant regions of interest in an image or detecting events in a
set of time-series signals. Nested MIL considers labelled bags within bags,
where only the outermost bag is labelled and inner-bags and instances are
represented as latent labels. In addition, we propose using an attention
mechanism to add interpretability, providing awareness into the impact of each
instance to the weak bag label. Experiments in classical image datasets show
that our proposed model provides high accuracy performance as well as spotting
relevant instances on image regions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuster_S/0/1/0/all/0/1&quot;&gt;Saul Fuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eftestol_T/0/1/0/all/0/1&quot;&gt;Trygve Eftest&amp;#xf8;l&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engan_K/0/1/0/all/0/1&quot;&gt;Kjersti Engan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00961">
<title>Robustness of deep learning algorithms in astronomy -- galaxy morphology studies. (arXiv:2111.00961v2 [astro-ph.GA] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00961</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models are being increasingly adopted in wide array of
scientific domains, especially to handle high-dimensionality and volume of the
scientific data. However, these models tend to be brittle due to their
complexity and overparametrization, especially to the inadvertent adversarial
perturbations that can appear due to common image processing such as
compression or blurring that are often seen with real scientific data. It is
crucial to understand this brittleness and develop models robust to these
adversarial perturbations. To this end, we study the effect of observational
noise from the exposure time, as well as the worst case scenario of a one-pixel
attack as a proxy for compression or telescope errors on performance of
ResNet18 trained to distinguish between galaxies of different morphologies in
LSST mock data. We also explore how domain adaptation techniques can help
improve model robustness in case of this type of naturally occurring attacks
and help scientists build more trustworthy and stable models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ciprijanovic_A/0/1/0/all/0/1&quot;&gt;A. &amp;#x106;iprijanovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Kafkes_D/0/1/0/all/0/1&quot;&gt;D. Kafkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Perdue_G/0/1/0/all/0/1&quot;&gt;G. N. Perdue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pedro_K/0/1/0/all/0/1&quot;&gt;K. Pedro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Snyder_G/0/1/0/all/0/1&quot;&gt;G. Snyder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Sanchez_F/0/1/0/all/0/1&quot;&gt;F. J. S&amp;#xe1;nchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Madireddy_S/0/1/0/all/0/1&quot;&gt;S. Madireddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Wild_S/0/1/0/all/0/1&quot;&gt;S. M. Wild&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1&quot;&gt;B. Nord&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00962">
<title>RefineGAN: Universally Generating Waveform Better than Ground Truth with Highly Accurate Pitch and Intensity Responses. (arXiv:2111.00962v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00962</link>
<description rdf:parseType="Literal">&lt;p&gt;Most GAN(Generative Adversarial Network)-based approaches towards
high-fidelity waveform generation heavily rely on discriminators to improve
their performance. However, the over-use of this GAN method introduces much
uncertainty into the generation process and often result in mismatches of pitch
and intensity, which is fatal when it comes to sensitive using cases such as
singing voice synthesis(SVS). To address this problem, we propose RefineGAN, a
high-fidelity neural vocoder with faster-than-real-time generation capability,
and focused on the robustness, pitch and intensity accuracy, and full-band
audio generation. We employed a pitch-guided refine architecture with a
multi-scale spectrogram-based loss function to help stabilize the training
process and maintain the robustness of the neural vocoder while using the
GAN-based training method. Audio generated using this method shows a better
performance in subjective tests when compared with the ground-truth audio. This
result shows that the fidelity is even improved during the waveform
reconstruction by eliminating defects produced by the speaker and the recording
procedure. Moreover, a further study shows that models trained on a specified
type of data can perform on totally unseen language and unseen speaker
identically well. Generated sample pairs are provided on
https://timedomain-tech.github.io/refinegan/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shengyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenxiao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jing Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00995">
<title>Sign-to-Speech Model for Sign Language Understanding: A Case Study of Nigerian Sign Language. (arXiv:2111.00995v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2111.00995</link>
<description rdf:parseType="Literal">&lt;p&gt;Through this paper, we seek to reduce the communication barrier between the
hearing-impaired community and the larger society who are usually not familiar
with sign language in the sub-Saharan region of Africa with the largest
occurrences of hearing disability cases, while using Nigeria as a case study.
The dataset is a pioneer dataset for the Nigerian Sign Language and was created
in collaboration with relevant stakeholders. We pre-processed the data in
readiness for two different object detection models and a classification model
and employed diverse evaluation metrics to gauge model performance on
sign-language to text conversion tasks. Finally, we convert the predicted sign
texts to speech and deploy the best performing model in a lightweight
application that works in real-time and achieves impressive results converting
sign words/phrases to text and subsequently, into speech.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolawole_S/0/1/0/all/0/1&quot;&gt;Steven Kolawole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osakuade_O/0/1/0/all/0/1&quot;&gt;Opeyemi Osakuade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_N/0/1/0/all/0/1&quot;&gt;Nayan Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olorisade_B/0/1/0/all/0/1&quot;&gt;Babatunde Kazeem Olorisade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.00459">
<title>Graph Neural Network based scheduling : Improved throughput under a generalized interference model. (arXiv:2111.00459v1 [eess.SY] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2111.00459</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a Graph Convolutional Neural Networks (GCN) based
scheduling algorithm for adhoc networks. In particular, we consider a
generalized interference model called the $k$-tolerant conflict graph model and
design an efficient approximation for the well-known Max-Weight scheduling
algorithm. A notable feature of this work is that the proposed method do not
require labelled data set (NP-hard to compute) for training the neural network.
Instead, we design a loss function that utilises the existing greedy approaches
and trains a GCN that improves the performance of greedy approaches. Our
extensive numerical experiments illustrate that using our GCN approach, we can
significantly ($4$-$20$ percent) improve the performance of the conventional
greedy approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ramakrishnan_S/0/1/0/all/0/1&quot;&gt;S. Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mandalapu_J/0/1/0/all/0/1&quot;&gt;Jaswanthi Mandalapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Peruru_S/0/1/0/all/0/1&quot;&gt;Subrahmanya Swamy Peruru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jain_B/0/1/0/all/0/1&quot;&gt;Bhavesh Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Altman_E/0/1/0/all/0/1&quot;&gt;Eitan Altman&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>